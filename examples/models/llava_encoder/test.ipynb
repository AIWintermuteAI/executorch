{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/passes/_quant_patterns_and_replacements.py:106: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @impl_abstract(\"quantized_decomposed::embedding_byte.out\")\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/passes/_quant_patterns_and_replacements.py:153: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @impl_abstract(\"quantized_decomposed::embedding_byte.dtype_out\")\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/passes/_quant_patterns_and_replacements.py:228: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @impl_abstract(\"quantized_decomposed::embedding_4bit.out\")\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/passes/_quant_patterns_and_replacements.py:281: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @impl_abstract(\"quantized_decomposed::embedding_4bit.dtype_out\")\n"
     ]
    }
   ],
   "source": [
    "from export import export_image_encoder, export_text_model, export_token_embedding\n",
    "\n",
    "from model import LlavaModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.40it/s]\n",
      "[INFO 2024-07-12 17:15:24,914 sdpa_with_kv_cache.py:24] Loading custom ops library: /Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/examples/models/llama2/custom_ops/libcustom_ops_aot_lib.dylib\n"
     ]
    }
   ],
   "source": [
    "llava_model = LlavaModel()\n",
    "llava = llava_model.get_eager_model()\n",
    "\n",
    "llava = llava.to(torch.float32)  # overflow error with fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_before_image, resized, prompt_after_image = llava_model.get_example_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefill_logits = llava.prefill(prompt_before_image, resized, prompt_after_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.4072,  0.7952, -0.3502,  ...,  2.0938,  3.0346,  1.7648],\n",
      "         [-9.5823, -5.0563, -1.2308,  ..., -6.2960, -8.3478, -7.7177],\n",
      "         [-5.5127, -6.3697,  8.1133,  ..., -3.5720, -1.9828, -2.7889],\n",
      "         ...,\n",
      "         [-5.6315, -2.3222,  8.8651,  ..., -1.3108, -3.9976, -2.9413],\n",
      "         [-3.1874, -1.6479,  7.5750,  ...,  0.6132, -0.3697,  1.1412],\n",
      "         [-1.1888, -1.4724,  9.7332,  ...,  1.5810,  1.8806,  1.8634]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(prefill_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_unlift.py:59: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer\n",
      "  getattr_node = gm.graph.get_attr(lifted_node)\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_0 target lifted_tensor_0 lifted_tensor_0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_1 target lifted_tensor_1 lifted_tensor_1 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_2 target lifted_tensor_2 lifted_tensor_2 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "image_encoder_ep = export_image_encoder(llava, resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = llava.prefill_embedding(prompt_before_image, resized, prompt_after_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-07-12 15:36:44,734 export_llama_lib.py:417] Applying quantizers: []\n",
      "[INFO 2024-07-12 15:36:44,749 sdpa_with_kv_cache.py:24] Loading custom ops library: /Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/examples/models/llama2/custom_ops/libcustom_ops_aot_lib.dylib\n",
      "[INFO 2024-07-12 15:36:44,915 __init__.py:24] Skipping import of cpp extensions\n",
      "[INFO 2024-07-12 15:36:45,382 config.py:58] PyTorch version 2.5.0.dev20240618 available.\n",
      "[INFO 2024-07-12 15:36:45,385 config.py:95] TensorFlow version 2.16.1 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear: layers.0.attention.wq, in=4096, out=4096\n",
      "linear: layers.0.attention.wk, in=4096, out=4096\n",
      "linear: layers.0.attention.wv, in=4096, out=4096\n",
      "linear: layers.0.attention.wo, in=4096, out=4096\n",
      "linear: layers.0.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.0.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.0.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.1.attention.wq, in=4096, out=4096\n",
      "linear: layers.1.attention.wk, in=4096, out=4096\n",
      "linear: layers.1.attention.wv, in=4096, out=4096\n",
      "linear: layers.1.attention.wo, in=4096, out=4096\n",
      "linear: layers.1.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.1.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.1.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.2.attention.wq, in=4096, out=4096\n",
      "linear: layers.2.attention.wk, in=4096, out=4096\n",
      "linear: layers.2.attention.wv, in=4096, out=4096\n",
      "linear: layers.2.attention.wo, in=4096, out=4096\n",
      "linear: layers.2.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.2.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.2.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.3.attention.wq, in=4096, out=4096\n",
      "linear: layers.3.attention.wk, in=4096, out=4096\n",
      "linear: layers.3.attention.wv, in=4096, out=4096\n",
      "linear: layers.3.attention.wo, in=4096, out=4096\n",
      "linear: layers.3.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.3.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.3.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.4.attention.wq, in=4096, out=4096\n",
      "linear: layers.4.attention.wk, in=4096, out=4096\n",
      "linear: layers.4.attention.wv, in=4096, out=4096\n",
      "linear: layers.4.attention.wo, in=4096, out=4096\n",
      "linear: layers.4.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.4.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.4.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.5.attention.wq, in=4096, out=4096\n",
      "linear: layers.5.attention.wk, in=4096, out=4096\n",
      "linear: layers.5.attention.wv, in=4096, out=4096\n",
      "linear: layers.5.attention.wo, in=4096, out=4096\n",
      "linear: layers.5.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.5.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.5.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.6.attention.wq, in=4096, out=4096\n",
      "linear: layers.6.attention.wk, in=4096, out=4096\n",
      "linear: layers.6.attention.wv, in=4096, out=4096\n",
      "linear: layers.6.attention.wo, in=4096, out=4096\n",
      "linear: layers.6.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.6.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.6.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.7.attention.wq, in=4096, out=4096\n",
      "linear: layers.7.attention.wk, in=4096, out=4096\n",
      "linear: layers.7.attention.wv, in=4096, out=4096\n",
      "linear: layers.7.attention.wo, in=4096, out=4096\n",
      "linear: layers.7.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.7.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.7.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.8.attention.wq, in=4096, out=4096\n",
      "linear: layers.8.attention.wk, in=4096, out=4096\n",
      "linear: layers.8.attention.wv, in=4096, out=4096\n",
      "linear: layers.8.attention.wo, in=4096, out=4096\n",
      "linear: layers.8.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.8.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.8.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.9.attention.wq, in=4096, out=4096\n",
      "linear: layers.9.attention.wk, in=4096, out=4096\n",
      "linear: layers.9.attention.wv, in=4096, out=4096\n",
      "linear: layers.9.attention.wo, in=4096, out=4096\n",
      "linear: layers.9.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.9.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.9.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.10.attention.wq, in=4096, out=4096\n",
      "linear: layers.10.attention.wk, in=4096, out=4096\n",
      "linear: layers.10.attention.wv, in=4096, out=4096\n",
      "linear: layers.10.attention.wo, in=4096, out=4096\n",
      "linear: layers.10.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.10.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.10.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.11.attention.wq, in=4096, out=4096\n",
      "linear: layers.11.attention.wk, in=4096, out=4096\n",
      "linear: layers.11.attention.wv, in=4096, out=4096\n",
      "linear: layers.11.attention.wo, in=4096, out=4096\n",
      "linear: layers.11.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.11.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.11.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.12.attention.wq, in=4096, out=4096\n",
      "linear: layers.12.attention.wk, in=4096, out=4096\n",
      "linear: layers.12.attention.wv, in=4096, out=4096\n",
      "linear: layers.12.attention.wo, in=4096, out=4096\n",
      "linear: layers.12.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.12.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.12.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.13.attention.wq, in=4096, out=4096\n",
      "linear: layers.13.attention.wk, in=4096, out=4096\n",
      "linear: layers.13.attention.wv, in=4096, out=4096\n",
      "linear: layers.13.attention.wo, in=4096, out=4096\n",
      "linear: layers.13.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.13.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.13.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.14.attention.wq, in=4096, out=4096\n",
      "linear: layers.14.attention.wk, in=4096, out=4096\n",
      "linear: layers.14.attention.wv, in=4096, out=4096\n",
      "linear: layers.14.attention.wo, in=4096, out=4096\n",
      "linear: layers.14.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.14.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.14.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.15.attention.wq, in=4096, out=4096\n",
      "linear: layers.15.attention.wk, in=4096, out=4096\n",
      "linear: layers.15.attention.wv, in=4096, out=4096\n",
      "linear: layers.15.attention.wo, in=4096, out=4096\n",
      "linear: layers.15.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.15.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.15.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.16.attention.wq, in=4096, out=4096\n",
      "linear: layers.16.attention.wk, in=4096, out=4096\n",
      "linear: layers.16.attention.wv, in=4096, out=4096\n",
      "linear: layers.16.attention.wo, in=4096, out=4096\n",
      "linear: layers.16.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.16.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.16.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.17.attention.wq, in=4096, out=4096\n",
      "linear: layers.17.attention.wk, in=4096, out=4096\n",
      "linear: layers.17.attention.wv, in=4096, out=4096\n",
      "linear: layers.17.attention.wo, in=4096, out=4096\n",
      "linear: layers.17.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.17.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.17.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.18.attention.wq, in=4096, out=4096\n",
      "linear: layers.18.attention.wk, in=4096, out=4096\n",
      "linear: layers.18.attention.wv, in=4096, out=4096\n",
      "linear: layers.18.attention.wo, in=4096, out=4096\n",
      "linear: layers.18.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.18.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.18.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.19.attention.wq, in=4096, out=4096\n",
      "linear: layers.19.attention.wk, in=4096, out=4096\n",
      "linear: layers.19.attention.wv, in=4096, out=4096\n",
      "linear: layers.19.attention.wo, in=4096, out=4096\n",
      "linear: layers.19.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.19.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.19.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.20.attention.wq, in=4096, out=4096\n",
      "linear: layers.20.attention.wk, in=4096, out=4096\n",
      "linear: layers.20.attention.wv, in=4096, out=4096\n",
      "linear: layers.20.attention.wo, in=4096, out=4096\n",
      "linear: layers.20.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.20.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.20.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.21.attention.wq, in=4096, out=4096\n",
      "linear: layers.21.attention.wk, in=4096, out=4096\n",
      "linear: layers.21.attention.wv, in=4096, out=4096\n",
      "linear: layers.21.attention.wo, in=4096, out=4096\n",
      "linear: layers.21.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.21.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.21.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.22.attention.wq, in=4096, out=4096\n",
      "linear: layers.22.attention.wk, in=4096, out=4096\n",
      "linear: layers.22.attention.wv, in=4096, out=4096\n",
      "linear: layers.22.attention.wo, in=4096, out=4096\n",
      "linear: layers.22.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.22.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.22.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.23.attention.wq, in=4096, out=4096\n",
      "linear: layers.23.attention.wk, in=4096, out=4096\n",
      "linear: layers.23.attention.wv, in=4096, out=4096\n",
      "linear: layers.23.attention.wo, in=4096, out=4096\n",
      "linear: layers.23.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.23.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.23.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.24.attention.wq, in=4096, out=4096\n",
      "linear: layers.24.attention.wk, in=4096, out=4096\n",
      "linear: layers.24.attention.wv, in=4096, out=4096\n",
      "linear: layers.24.attention.wo, in=4096, out=4096\n",
      "linear: layers.24.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.24.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.24.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.25.attention.wq, in=4096, out=4096\n",
      "linear: layers.25.attention.wk, in=4096, out=4096\n",
      "linear: layers.25.attention.wv, in=4096, out=4096\n",
      "linear: layers.25.attention.wo, in=4096, out=4096\n",
      "linear: layers.25.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.25.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.25.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.26.attention.wq, in=4096, out=4096\n",
      "linear: layers.26.attention.wk, in=4096, out=4096\n",
      "linear: layers.26.attention.wv, in=4096, out=4096\n",
      "linear: layers.26.attention.wo, in=4096, out=4096\n",
      "linear: layers.26.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.26.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.26.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.27.attention.wq, in=4096, out=4096\n",
      "linear: layers.27.attention.wk, in=4096, out=4096\n",
      "linear: layers.27.attention.wv, in=4096, out=4096\n",
      "linear: layers.27.attention.wo, in=4096, out=4096\n",
      "linear: layers.27.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.27.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.27.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.28.attention.wq, in=4096, out=4096\n",
      "linear: layers.28.attention.wk, in=4096, out=4096\n",
      "linear: layers.28.attention.wv, in=4096, out=4096\n",
      "linear: layers.28.attention.wo, in=4096, out=4096\n",
      "linear: layers.28.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.28.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.28.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.29.attention.wq, in=4096, out=4096\n",
      "linear: layers.29.attention.wk, in=4096, out=4096\n",
      "linear: layers.29.attention.wv, in=4096, out=4096\n",
      "linear: layers.29.attention.wo, in=4096, out=4096\n",
      "linear: layers.29.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.29.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.29.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.30.attention.wq, in=4096, out=4096\n",
      "linear: layers.30.attention.wk, in=4096, out=4096\n",
      "linear: layers.30.attention.wv, in=4096, out=4096\n",
      "linear: layers.30.attention.wo, in=4096, out=4096\n",
      "linear: layers.30.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.30.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.30.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.31.attention.wq, in=4096, out=4096\n",
      "linear: layers.31.attention.wk, in=4096, out=4096\n",
      "linear: layers.31.attention.wv, in=4096, out=4096\n",
      "linear: layers.31.attention.wo, in=4096, out=4096\n",
      "linear: layers.31.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.31.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.31.feed_forward.w3, in=4096, out=11008\n",
      "linear: output, in=4096, out=32000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "        Encountered duplicated inputs that are mutated in the graph you are trying to export.\n        This functionality is currently not supported. If needed, please file a github issue.\n\n        fw_metadata=ViewAndMutationMeta(input_info=[InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=False, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False)], output_info=[OutputAliasInfo(output_type=<OutputType.non_alias: 1>, raw_type=<class 'torch._subclasses.functional_tensor.FunctionalTensor'>, base_idx=None, dynamic_dims={1}, requires_grad=False, functional_tensor=None)], num_intermediate_bases=0, keep_input_mutations=False, traced_tangents=[], subclass_inp_meta=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903], subclass_fw_graph_out_meta=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128], subclass_tangent_meta=[], is_train=False, traced_tangent_metas=None, num_symints_saved_for_bw=None, grad_enabled_mutation=None, deterministic=None, static_parameter_indices=[], tokens={}, indices_of_inputs_that_requires_grad_with_mutations_in_bw=[])\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text_model_ep \u001b[39m=\u001b[39m export_text_model(llava, embeddings)\n",
      "File \u001b[0;32m~/CLionProjects/executorch/examples/models/llava_encoder/export.py:83\u001b[0m, in \u001b[0;36mexport_text_model\u001b[0;34m(llava, embeddings)\u001b[0m\n\u001b[1;32m     75\u001b[0m quant_transform \u001b[39m=\u001b[39m get_quant_weight_transform(args, dtype_override, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m pt2e_quant_params, quantizers, quant_dtype \u001b[39m=\u001b[39m get_quantizer_and_quant_params(args)\n\u001b[1;32m     78\u001b[0m manager \u001b[39m=\u001b[39m (\n\u001b[1;32m     79\u001b[0m     text_model_em\n\u001b[1;32m     80\u001b[0m     \u001b[39m.\u001b[39;49mset_output_dir(\u001b[39m\"\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     81\u001b[0m     \u001b[39m.\u001b[39;49mto_dtype(dtype_override)\n\u001b[1;32m     82\u001b[0m     \u001b[39m.\u001b[39;49msource_transform([replace_sdpa_with_custom_op, quant_transform])\n\u001b[0;32m---> 83\u001b[0m     \u001b[39m.\u001b[39;49mcapture_pre_autograd_graph()\n\u001b[1;32m     84\u001b[0m     \u001b[39m.\u001b[39mpt2e_quantize(quantizers)\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     88\u001b[0m     text_model_ep \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexport\u001b[39m.\u001b[39mexport(manager\u001b[39m.\u001b[39mpre_autograd_graph_module, manager\u001b[39m.\u001b[39mexample_inputs, dynamic_shapes\u001b[39m=\u001b[39mmanager\u001b[39m.\u001b[39m_get_dynamic_shape())\n",
      "File \u001b[0;32m~/CLionProjects/executorch/examples/models/llava_encoder/export.py:48\u001b[0m, in \u001b[0;36mLlavaEdgeManager.capture_pre_autograd_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m# 1. torch.nn.attention.sdpa_kernel([SDPBackend.MATH]) is for bypassing the dynamo error when tracing\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# 2. torch.no_grad() is for getting rid of the dropout (not sure why training ops will show up)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mattention\u001b[39m.\u001b[39msdpa_kernel([SDPBackend\u001b[39m.\u001b[39mMATH]), torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexport_program \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mexport\u001b[39m.\u001b[39;49mexport(\n\u001b[1;32m     49\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexample_inputs, dynamic_shapes\u001b[39m=\u001b[39;49mdynamic_shape, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_autograd_graph_module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexport_program\u001b[39m.\u001b[39mmodule()\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/__init__.py:174\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mod, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m    170\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    171\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected `mod` to be an instance of `torch.nn.Module`, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(mod)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m _export(\n\u001b[1;32m    175\u001b[0m     mod,\n\u001b[1;32m    176\u001b[0m     args,\n\u001b[1;32m    177\u001b[0m     kwargs,\n\u001b[1;32m    178\u001b[0m     dynamic_shapes,\n\u001b[1;32m    179\u001b[0m     strict\u001b[39m=\u001b[39;49mstrict,\n\u001b[1;32m    180\u001b[0m     preserve_module_call_signature\u001b[39m=\u001b[39;49mpreserve_module_call_signature,\n\u001b[1;32m    181\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    182\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_trace.py:991\u001b[0m, in \u001b[0;36m_log_export_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m     error_type \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m t\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m    985\u001b[0m     log_export_usage(\n\u001b[1;32m    986\u001b[0m         event\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexport.error\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    987\u001b[0m         \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39merror_type,\n\u001b[1;32m    988\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    989\u001b[0m         flags\u001b[39m=\u001b[39m_EXPORT_FLAGS,\n\u001b[1;32m    990\u001b[0m     )\n\u001b[0;32m--> 991\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    992\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     _EXPORT_FLAGS \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_trace.py:974\u001b[0m, in \u001b[0;36m_log_export_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    973\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 974\u001b[0m     ep \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    975\u001b[0m     end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    976\u001b[0m     log_export_usage(\n\u001b[1;32m    977\u001b[0m         event\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexport.time\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    978\u001b[0m         metrics\u001b[39m=\u001b[39mend \u001b[39m-\u001b[39m start,\n\u001b[1;32m    979\u001b[0m         flags\u001b[39m=\u001b[39m_EXPORT_FLAGS,\n\u001b[1;32m    980\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mget_ep_stats(ep),\n\u001b[1;32m    981\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/exported_program.py:91\u001b[0m, in \u001b[0;36m_disable_prexisiting_fake_mode.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     90\u001b[0m     \u001b[39mwith\u001b[39;00m maybe_disable_fake_tensor_mode():\n\u001b[0;32m---> 91\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_trace.py:1507\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, pre_dispatch, _allow_complex_guards_as_runtime_asserts, _disable_forced_specializations, _is_torch_jit_trace)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[39m# Call the appropriate export function based on the strictness of tracing.\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m export_func \u001b[39m=\u001b[39m _strict_export \u001b[39mif\u001b[39;00m strict \u001b[39melse\u001b[39;00m _non_strict_export\n\u001b[0;32m-> 1507\u001b[0m export_artifact \u001b[39m=\u001b[39m export_func(\n\u001b[1;32m   1508\u001b[0m     mod,\n\u001b[1;32m   1509\u001b[0m     args,\n\u001b[1;32m   1510\u001b[0m     kwargs,\n\u001b[1;32m   1511\u001b[0m     dynamic_shapes,\n\u001b[1;32m   1512\u001b[0m     preserve_module_call_signature,\n\u001b[1;32m   1513\u001b[0m     pre_dispatch,\n\u001b[1;32m   1514\u001b[0m     original_state_dict,\n\u001b[1;32m   1515\u001b[0m     orig_in_spec,\n\u001b[1;32m   1516\u001b[0m     _allow_complex_guards_as_runtime_asserts,\n\u001b[1;32m   1517\u001b[0m     _disable_forced_specializations,\n\u001b[1;32m   1518\u001b[0m     _is_torch_jit_trace,\n\u001b[1;32m   1519\u001b[0m )\n\u001b[1;32m   1521\u001b[0m \u001b[39m# Decompose here for readability.\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m gm \u001b[39m=\u001b[39m export_artifact\u001b[39m.\u001b[39maten\u001b[39m.\u001b[39mgm\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_trace.py:1366\u001b[0m, in \u001b[0;36m_non_strict_export\u001b[0;34m(mod, args, kwargs, dynamic_shapes, preserve_module_call_signature, pre_dispatch, original_state_dict, orig_in_spec, _allow_complex_guards_as_runtime_asserts, _disable_forced_specializations, _is_torch_jit_trace)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[39mwith\u001b[39;00m fake_mode:\n\u001b[1;32m   1359\u001b[0m     \u001b[39mwith\u001b[39;00m _fakify_script_objects(mod, fake_args, fake_kwargs, fake_mode) \u001b[39mas\u001b[39;00m (\n\u001b[1;32m   1360\u001b[0m         patched_mod,\n\u001b[1;32m   1361\u001b[0m         new_fake_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1364\u001b[0m         map_fake_to_real,\n\u001b[1;32m   1365\u001b[0m     ):\n\u001b[0;32m-> 1366\u001b[0m         aten_export_artifact \u001b[39m=\u001b[39m _export_to_aten_ir(\n\u001b[1;32m   1367\u001b[0m             patched_mod,\n\u001b[1;32m   1368\u001b[0m             new_fake_args,\n\u001b[1;32m   1369\u001b[0m             new_fake_kwargs,\n\u001b[1;32m   1370\u001b[0m             fake_params_buffers,\n\u001b[1;32m   1371\u001b[0m             new_fake_constant_attrs,\n\u001b[1;32m   1372\u001b[0m             pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m   1373\u001b[0m             transform\u001b[39m=\u001b[39;49m_tuplify_outputs,\n\u001b[1;32m   1374\u001b[0m             _is_torch_jit_trace\u001b[39m=\u001b[39;49m_is_torch_jit_trace,\n\u001b[1;32m   1375\u001b[0m         )\n\u001b[1;32m   1376\u001b[0m         \u001b[39m# aten_export_artifact.constants contains only fake script objects, we need to map them back\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m         aten_export_artifact\u001b[39m.\u001b[39mconstants \u001b[39m=\u001b[39m {\n\u001b[1;32m   1378\u001b[0m             fqn: map_fake_to_real[obj] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, FakeScriptObject) \u001b[39melse\u001b[39;00m obj\n\u001b[1;32m   1379\u001b[0m             \u001b[39mfor\u001b[39;00m fqn, obj \u001b[39min\u001b[39;00m aten_export_artifact\u001b[39m.\u001b[39mconstants\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1380\u001b[0m         }\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_trace.py:623\u001b[0m, in \u001b[0;36m_export_to_aten_ir\u001b[0;34m(mod, fake_args, fake_kwargs, fake_params_buffers, constant_attrs, transform, pre_dispatch, _is_torch_jit_trace)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39m# This _reparametrize_module makes sure inputs and module.params/buffers have the same fake_mode,\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[39m# otherwise aot_export_module will error out because it sees a mix of fake_modes.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[39m# And we want aot_export_module to use the fake_tensor mode in dynamo to keep the pipeline easy to reason about.\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mstateless\u001b[39m.\u001b[39m_reparametrize_module(\n\u001b[1;32m    617\u001b[0m     mod,\n\u001b[1;32m    618\u001b[0m     fake_params_buffers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m     stack_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    622\u001b[0m ), grad_safe_guard, _ignore_backend_decomps(), _compiling_state_context():  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m     gm, graph_signature \u001b[39m=\u001b[39m transform(aot_export_module)(\n\u001b[1;32m    624\u001b[0m         mod,\n\u001b[1;32m    625\u001b[0m         fake_args,\n\u001b[1;32m    626\u001b[0m         trace_joint\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    627\u001b[0m         pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    628\u001b[0m         kwargs\u001b[39m=\u001b[39;49mfake_kwargs,\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[39m# TODO unfortunately preserving graph-level metadata is not\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[39m# working well with aot_export. So we manually copy it.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39m# (The node-level meta is addressed above.)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(mod, torch\u001b[39m.\u001b[39mfx\u001b[39m.\u001b[39mGraphModule) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(mod, \u001b[39m\"\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_trace.py:1317\u001b[0m, in \u001b[0;36m_non_strict_export.<locals>._tuplify_outputs.<locals>._aot_export_non_strict\u001b[0;34m(mod, args, kwargs, **flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m new_preserved_call_signatures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1312\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_export_root.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m preserve_module_call_signature\n\u001b[1;32m   1313\u001b[0m ]\n\u001b[1;32m   1314\u001b[0m \u001b[39mwith\u001b[39;00m _wrap_submodules(\n\u001b[1;32m   1315\u001b[0m     wrapped_mod, new_preserved_call_signatures, module_call_specs\n\u001b[1;32m   1316\u001b[0m ):\n\u001b[0;32m-> 1317\u001b[0m     gm, sig \u001b[39m=\u001b[39m aot_export(wrapped_mod, args, kwargs\u001b[39m=\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mflags)\n\u001b[1;32m   1318\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mExported program from AOTAutograd:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, gm)\n\u001b[1;32m   1320\u001b[0m sig\u001b[39m.\u001b[39mparameters \u001b[39m=\u001b[39m pytree\u001b[39m.\u001b[39mtree_map(_strip_root, sig\u001b[39m.\u001b[39mparameters)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:1148\u001b[0m, in \u001b[0;36maot_export_module\u001b[0;34m(mod, args, decompositions, trace_joint, output_loss_index, pre_dispatch, kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m full_args\u001b[39m.\u001b[39mextend(args)\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m ctx():\n\u001b[0;32m-> 1148\u001b[0m     fx_g, metadata, in_spec, out_spec \u001b[39m=\u001b[39m _aot_export_function(\n\u001b[1;32m   1149\u001b[0m         fn_to_trace,\n\u001b[1;32m   1150\u001b[0m         full_args,\n\u001b[1;32m   1151\u001b[0m         decompositions\u001b[39m=\u001b[39;49mdecompositions,\n\u001b[1;32m   1152\u001b[0m         num_params_buffers\u001b[39m=\u001b[39;49mparams_len,\n\u001b[1;32m   1153\u001b[0m         no_tangents\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1154\u001b[0m         pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m   1155\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m   1156\u001b[0m     )\n\u001b[1;32m   1157\u001b[0m \u001b[39mif\u001b[39;00m trace_joint:\n\u001b[1;32m   1159\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mflattened_joint\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[1;32m   1160\u001b[0m         \u001b[39m# The idea here is that the joint graph that AOTAutograd creates has some strict properties:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m         \u001b[39m# (1) It accepts two arguments (primals, tangents), and pytree_flattens them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[39m# This function \"fixes\" both of the above by removing any tangent inputs,\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m         \u001b[39m# and removing pytrees from the original FX graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:1367\u001b[0m, in \u001b[0;36m_aot_export_function\u001b[0;34m(func, args, num_params_buffers, decompositions, no_tangents, pre_dispatch, kwargs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[39m# The export use case doesn't care about several bits of AOTConfig\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[39m# (1) compilers (we just export the graph)\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m \u001b[39m# (2) partitioners (export is only full graph, user can partition themselves)\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m aot_config \u001b[39m=\u001b[39m AOTConfig(\n\u001b[1;32m   1349\u001b[0m     fw_compiler\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1350\u001b[0m     bw_compiler\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     pre_dispatch\u001b[39m=\u001b[39mpre_dispatch,\n\u001b[1;32m   1365\u001b[0m )\n\u001b[0;32m-> 1367\u001b[0m fx_g, meta \u001b[39m=\u001b[39m create_aot_dispatcher_function(\n\u001b[1;32m   1368\u001b[0m     flat_fn,\n\u001b[1;32m   1369\u001b[0m     flat_args,\n\u001b[1;32m   1370\u001b[0m     aot_config,\n\u001b[1;32m   1371\u001b[0m )\n\u001b[1;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m fx_g, meta, in_spec, out_spec\u001b[39m.\u001b[39mspec\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_dynamo/utils.py:231\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m (dynamo_timed)\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    230\u001b[0m     t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 231\u001b[0m     r \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    232\u001b[0m     time_spent \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    233\u001b[0m compilation_time_metrics[key]\u001b[39m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:696\u001b[0m, in \u001b[0;36mcreate_aot_dispatcher_function\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[39mreturn\u001b[39;00m aot_dispatch_base\n\u001b[1;32m    694\u001b[0m compiler_fn \u001b[39m=\u001b[39m choose_dispatcher(needs_autograd, aot_config)\n\u001b[0;32m--> 696\u001b[0m compiled_fn, fw_metadata \u001b[39m=\u001b[39m compiler_fn(\n\u001b[1;32m    697\u001b[0m     flat_fn, fake_flat_args, aot_config, fw_metadata\u001b[39m=\u001b[39;49mfw_metadata\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fn, fw_metadata\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:90\u001b[0m, in \u001b[0;36maot_dispatch_export\u001b[0;34m(flat_fn, flat_args, aot_config, fw_metadata, needs_autograd)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maot_dispatch_export\u001b[39m(\n\u001b[1;32m     82\u001b[0m     flat_fn: Callable,\n\u001b[1;32m     83\u001b[0m     flat_args: List[Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     needs_autograd: \u001b[39mbool\u001b[39m,\n\u001b[1;32m     88\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DispatchReturn:\n\u001b[1;32m     89\u001b[0m     wrappers \u001b[39m=\u001b[39m _create_wrappers_for_dispatch(needs_autograd)\n\u001b[0;32m---> 90\u001b[0m     flat_fn, flat_args, fw_metadata \u001b[39m=\u001b[39m pre_compile(\n\u001b[1;32m     91\u001b[0m         wrappers,\n\u001b[1;32m     92\u001b[0m         flat_fn,\n\u001b[1;32m     93\u001b[0m         flat_args,\n\u001b[1;32m     94\u001b[0m         aot_config,\n\u001b[1;32m     95\u001b[0m         fw_metadata\u001b[39m=\u001b[39;49mfw_metadata,\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m needs_autograd \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m aot_config\u001b[39m.\u001b[39mpre_dispatch:\n\u001b[1;32m     98\u001b[0m         graph, _, _ \u001b[39m=\u001b[39m aot_dispatch_autograd_graph(\n\u001b[1;32m     99\u001b[0m             flat_fn, flat_args, aot_config, fw_metadata\u001b[39m=\u001b[39mfw_metadata\n\u001b[1;32m    100\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1957\u001b[0m, in \u001b[0;36mpre_compile\u001b[0;34m(wrappers, flat_fn, flat_args, aot_config, fw_metadata)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[39mRuns a sequence of wrappers on the given function and arguments.\u001b[39;00m\n\u001b[1;32m   1954\u001b[0m \u001b[39mMutates wrappers in place.\u001b[39;00m\n\u001b[1;32m   1955\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1956\u001b[0m \u001b[39mfor\u001b[39;00m wrapper \u001b[39min\u001b[39;00m wrappers:\n\u001b[0;32m-> 1957\u001b[0m     flat_fn, flat_args, fw_metadata \u001b[39m=\u001b[39m wrapper\u001b[39m.\u001b[39;49mpre_compile(\n\u001b[1;32m   1958\u001b[0m         flat_fn, flat_args, aot_config, fw_metadata\u001b[39m=\u001b[39;49mfw_metadata\n\u001b[1;32m   1959\u001b[0m     )\n\u001b[1;32m   1960\u001b[0m \u001b[39mreturn\u001b[39;00m flat_fn, flat_args, fw_metadata\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:753\u001b[0m, in \u001b[0;36mAOTDedupeWrapper.pre_compile\u001b[0;34m(self, flat_fn, flat_args, aot_config, fw_metadata)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39m# export path: ban duplicate inputs for now, add later if requested.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mif\u001b[39;00m aot_config\u001b[39m.\u001b[39mis_export:\n\u001b[0;32m--> 753\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    754\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[39mEncountered duplicated inputs that are mutated in the graph you are trying to export.\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[39mThis functionality is currently not supported. If needed, please file a github issue.\u001b[39m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[39mfw_metadata=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(fw_metadata)\u001b[39m}\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    762\u001b[0m \u001b[39m# Strategy 2: Duplicate specialize.\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39m# In Haskell types, suppose you have:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[39m#   ]\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[39m#   keep_arg_mask = [True, True, False, True]\u001b[39;00m\n\u001b[1;32m    799\u001b[0m seen_args: Dict[Tensor, \u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mRuntimeError\u001b[0m:         Encountered duplicated inputs that are mutated in the graph you are trying to export.\n        This functionality is currently not supported. If needed, please file a github issue.\n\n        fw_metadata=ViewAndMutationMeta(input_info=[InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=True, mutates_metadata=False, mutations_hidden_from_autograd=False, mutations_under_no_grad_or_inference_mode=True, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False), InputAliasInfo(is_leaf=False, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=True, keep_input_mutations=False), InputAliasInfo(is_leaf=True, mutates_data=False, mutates_metadata=False, mutations_hidden_from_autograd=True, mutations_under_no_grad_or_inference_mode=False, mutation_inductor_storage_resize=False, mutates_storage_metadata=False, requires_grad=False, keep_input_mutations=False)], output_info=[OutputAliasInfo(output_type=<OutputType.non_alias: 1>, raw_type=<class 'torch._subclasses.functional_tensor.FunctionalTensor'>, base_idx=None, dynamic_dims={1}, requires_grad=False, functional_tensor=None)], num_intermediate_bases=0, keep_input_mutations=False, traced_tangents=[], subclass_inp_meta=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903], subclass_fw_graph_out_meta=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128], subclass_tangent_meta=[], is_train=False, traced_tangent_metas=None, num_symints_saved_for_bw=None, grad_enabled_mutation=None, deterministic=None, static_parameter_indices=[], tokens={}, indices_of_inputs_that_requires_grad_with_mutations_in_bw=[])\n            "
     ]
    }
   ],
   "source": [
    "text_model_ep = export_text_model(llava, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-07-12 11:06:25,263 sdpa_with_kv_cache.py:24] Loading custom ops library: /Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/examples/models/llama2/custom_ops/libcustom_ops_aot_lib.dylib\n",
      "[INFO 2024-07-12 11:06:25,335 __init__.py:24] Skipping import of cpp extensions\n",
      "[INFO 2024-07-12 11:06:25,963 config.py:58] PyTorch version 2.5.0.dev20240618 available.\n",
      "[INFO 2024-07-12 11:06:25,965 config.py:95] TensorFlow version 2.16.1 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear: layers.0.attention.wq, in=4096, out=4096\n",
      "linear: layers.0.attention.wk, in=4096, out=4096\n",
      "linear: layers.0.attention.wv, in=4096, out=4096\n",
      "linear: layers.0.attention.wo, in=4096, out=4096\n",
      "linear: layers.0.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.0.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.0.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.1.attention.wq, in=4096, out=4096\n",
      "linear: layers.1.attention.wk, in=4096, out=4096\n",
      "linear: layers.1.attention.wv, in=4096, out=4096\n",
      "linear: layers.1.attention.wo, in=4096, out=4096\n",
      "linear: layers.1.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.1.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.1.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.2.attention.wq, in=4096, out=4096\n",
      "linear: layers.2.attention.wk, in=4096, out=4096\n",
      "linear: layers.2.attention.wv, in=4096, out=4096\n",
      "linear: layers.2.attention.wo, in=4096, out=4096\n",
      "linear: layers.2.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.2.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.2.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.3.attention.wq, in=4096, out=4096\n",
      "linear: layers.3.attention.wk, in=4096, out=4096\n",
      "linear: layers.3.attention.wv, in=4096, out=4096\n",
      "linear: layers.3.attention.wo, in=4096, out=4096\n",
      "linear: layers.3.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.3.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.3.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.4.attention.wq, in=4096, out=4096\n",
      "linear: layers.4.attention.wk, in=4096, out=4096\n",
      "linear: layers.4.attention.wv, in=4096, out=4096\n",
      "linear: layers.4.attention.wo, in=4096, out=4096\n",
      "linear: layers.4.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.4.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.4.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.5.attention.wq, in=4096, out=4096\n",
      "linear: layers.5.attention.wk, in=4096, out=4096\n",
      "linear: layers.5.attention.wv, in=4096, out=4096\n",
      "linear: layers.5.attention.wo, in=4096, out=4096\n",
      "linear: layers.5.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.5.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.5.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.6.attention.wq, in=4096, out=4096\n",
      "linear: layers.6.attention.wk, in=4096, out=4096\n",
      "linear: layers.6.attention.wv, in=4096, out=4096\n",
      "linear: layers.6.attention.wo, in=4096, out=4096\n",
      "linear: layers.6.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.6.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.6.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.7.attention.wq, in=4096, out=4096\n",
      "linear: layers.7.attention.wk, in=4096, out=4096\n",
      "linear: layers.7.attention.wv, in=4096, out=4096\n",
      "linear: layers.7.attention.wo, in=4096, out=4096\n",
      "linear: layers.7.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.7.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.7.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.8.attention.wq, in=4096, out=4096\n",
      "linear: layers.8.attention.wk, in=4096, out=4096\n",
      "linear: layers.8.attention.wv, in=4096, out=4096\n",
      "linear: layers.8.attention.wo, in=4096, out=4096\n",
      "linear: layers.8.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.8.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.8.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.9.attention.wq, in=4096, out=4096\n",
      "linear: layers.9.attention.wk, in=4096, out=4096\n",
      "linear: layers.9.attention.wv, in=4096, out=4096\n",
      "linear: layers.9.attention.wo, in=4096, out=4096\n",
      "linear: layers.9.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.9.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.9.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.10.attention.wq, in=4096, out=4096\n",
      "linear: layers.10.attention.wk, in=4096, out=4096\n",
      "linear: layers.10.attention.wv, in=4096, out=4096\n",
      "linear: layers.10.attention.wo, in=4096, out=4096\n",
      "linear: layers.10.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.10.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.10.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.11.attention.wq, in=4096, out=4096\n",
      "linear: layers.11.attention.wk, in=4096, out=4096\n",
      "linear: layers.11.attention.wv, in=4096, out=4096\n",
      "linear: layers.11.attention.wo, in=4096, out=4096\n",
      "linear: layers.11.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.11.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.11.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.12.attention.wq, in=4096, out=4096\n",
      "linear: layers.12.attention.wk, in=4096, out=4096\n",
      "linear: layers.12.attention.wv, in=4096, out=4096\n",
      "linear: layers.12.attention.wo, in=4096, out=4096\n",
      "linear: layers.12.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.12.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.12.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.13.attention.wq, in=4096, out=4096\n",
      "linear: layers.13.attention.wk, in=4096, out=4096\n",
      "linear: layers.13.attention.wv, in=4096, out=4096\n",
      "linear: layers.13.attention.wo, in=4096, out=4096\n",
      "linear: layers.13.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.13.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.13.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.14.attention.wq, in=4096, out=4096\n",
      "linear: layers.14.attention.wk, in=4096, out=4096\n",
      "linear: layers.14.attention.wv, in=4096, out=4096\n",
      "linear: layers.14.attention.wo, in=4096, out=4096\n",
      "linear: layers.14.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.14.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.14.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.15.attention.wq, in=4096, out=4096\n",
      "linear: layers.15.attention.wk, in=4096, out=4096\n",
      "linear: layers.15.attention.wv, in=4096, out=4096\n",
      "linear: layers.15.attention.wo, in=4096, out=4096\n",
      "linear: layers.15.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.15.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.15.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.16.attention.wq, in=4096, out=4096\n",
      "linear: layers.16.attention.wk, in=4096, out=4096\n",
      "linear: layers.16.attention.wv, in=4096, out=4096\n",
      "linear: layers.16.attention.wo, in=4096, out=4096\n",
      "linear: layers.16.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.16.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.16.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.17.attention.wq, in=4096, out=4096\n",
      "linear: layers.17.attention.wk, in=4096, out=4096\n",
      "linear: layers.17.attention.wv, in=4096, out=4096\n",
      "linear: layers.17.attention.wo, in=4096, out=4096\n",
      "linear: layers.17.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.17.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.17.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.18.attention.wq, in=4096, out=4096\n",
      "linear: layers.18.attention.wk, in=4096, out=4096\n",
      "linear: layers.18.attention.wv, in=4096, out=4096\n",
      "linear: layers.18.attention.wo, in=4096, out=4096\n",
      "linear: layers.18.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.18.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.18.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.19.attention.wq, in=4096, out=4096\n",
      "linear: layers.19.attention.wk, in=4096, out=4096\n",
      "linear: layers.19.attention.wv, in=4096, out=4096\n",
      "linear: layers.19.attention.wo, in=4096, out=4096\n",
      "linear: layers.19.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.19.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.19.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.20.attention.wq, in=4096, out=4096\n",
      "linear: layers.20.attention.wk, in=4096, out=4096\n",
      "linear: layers.20.attention.wv, in=4096, out=4096\n",
      "linear: layers.20.attention.wo, in=4096, out=4096\n",
      "linear: layers.20.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.20.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.20.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.21.attention.wq, in=4096, out=4096\n",
      "linear: layers.21.attention.wk, in=4096, out=4096\n",
      "linear: layers.21.attention.wv, in=4096, out=4096\n",
      "linear: layers.21.attention.wo, in=4096, out=4096\n",
      "linear: layers.21.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.21.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.21.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.22.attention.wq, in=4096, out=4096\n",
      "linear: layers.22.attention.wk, in=4096, out=4096\n",
      "linear: layers.22.attention.wv, in=4096, out=4096\n",
      "linear: layers.22.attention.wo, in=4096, out=4096\n",
      "linear: layers.22.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.22.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.22.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.23.attention.wq, in=4096, out=4096\n",
      "linear: layers.23.attention.wk, in=4096, out=4096\n",
      "linear: layers.23.attention.wv, in=4096, out=4096\n",
      "linear: layers.23.attention.wo, in=4096, out=4096\n",
      "linear: layers.23.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.23.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.23.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.24.attention.wq, in=4096, out=4096\n",
      "linear: layers.24.attention.wk, in=4096, out=4096\n",
      "linear: layers.24.attention.wv, in=4096, out=4096\n",
      "linear: layers.24.attention.wo, in=4096, out=4096\n",
      "linear: layers.24.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.24.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.24.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.25.attention.wq, in=4096, out=4096\n",
      "linear: layers.25.attention.wk, in=4096, out=4096\n",
      "linear: layers.25.attention.wv, in=4096, out=4096\n",
      "linear: layers.25.attention.wo, in=4096, out=4096\n",
      "linear: layers.25.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.25.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.25.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.26.attention.wq, in=4096, out=4096\n",
      "linear: layers.26.attention.wk, in=4096, out=4096\n",
      "linear: layers.26.attention.wv, in=4096, out=4096\n",
      "linear: layers.26.attention.wo, in=4096, out=4096\n",
      "linear: layers.26.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.26.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.26.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.27.attention.wq, in=4096, out=4096\n",
      "linear: layers.27.attention.wk, in=4096, out=4096\n",
      "linear: layers.27.attention.wv, in=4096, out=4096\n",
      "linear: layers.27.attention.wo, in=4096, out=4096\n",
      "linear: layers.27.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.27.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.27.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.28.attention.wq, in=4096, out=4096\n",
      "linear: layers.28.attention.wk, in=4096, out=4096\n",
      "linear: layers.28.attention.wv, in=4096, out=4096\n",
      "linear: layers.28.attention.wo, in=4096, out=4096\n",
      "linear: layers.28.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.28.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.28.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.29.attention.wq, in=4096, out=4096\n",
      "linear: layers.29.attention.wk, in=4096, out=4096\n",
      "linear: layers.29.attention.wv, in=4096, out=4096\n",
      "linear: layers.29.attention.wo, in=4096, out=4096\n",
      "linear: layers.29.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.29.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.29.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.30.attention.wq, in=4096, out=4096\n",
      "linear: layers.30.attention.wk, in=4096, out=4096\n",
      "linear: layers.30.attention.wv, in=4096, out=4096\n",
      "linear: layers.30.attention.wo, in=4096, out=4096\n",
      "linear: layers.30.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.30.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.30.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.31.attention.wq, in=4096, out=4096\n",
      "linear: layers.31.attention.wk, in=4096, out=4096\n",
      "linear: layers.31.attention.wv, in=4096, out=4096\n",
      "linear: layers.31.attention.wo, in=4096, out=4096\n",
      "linear: layers.31.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.31.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.31.feed_forward.w3, in=4096, out=11008\n",
      "linear: output, in=4096, out=32000\n"
     ]
    }
   ],
   "source": [
    "from executorch.examples.models.llama2.export_llama_lib import build_args_parser\n",
    "from executorch.examples.models.llama2.source_transformation.sdpa import replace_sdpa_with_custom_op\n",
    "from executorch.examples.models.llama2.source_transformation.quantize import get_quant_weight_transform\n",
    "from executorch.examples.models.llama2.builder import DType\n",
    "\n",
    "llava_text_model = llava.text_model\n",
    "\n",
    "dtype_override = DType.fp32\n",
    "parser = build_args_parser()\n",
    "args = parser.parse_args(['-X', '-qmode', '8da4w', '--group_size', '128', '--embedding-quantize', '4,32'])\n",
    "quant_transform = get_quant_weight_transform(args, dtype_override, False)\n",
    "source_transforms = [replace_sdpa_with_custom_op, quant_transform]\n",
    "\n",
    "for transform in source_transforms:\n",
    "    llava_text_model = transform(llava_text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.4072,  0.7952, -0.3502,  ...,  2.0938,  3.0346,  1.7648],\n",
      "         [-9.5823, -5.0563, -1.2308,  ..., -6.2960, -8.3478, -7.7177],\n",
      "         [-5.5127, -6.3697,  8.1133,  ..., -3.5720, -1.9828, -2.7889],\n",
      "         ...,\n",
      "         [-5.6315, -2.3222,  8.8651,  ..., -1.3108, -3.9976, -2.9413],\n",
      "         [-3.1874, -1.6479,  7.5750,  ...,  0.6132, -0.3697,  1.1412],\n",
      "         [-1.1888, -1.4724,  9.7332,  ...,  1.5810,  1.8806,  1.8634]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llava_text_model = llava.text_model\n",
    "ref = llava_text_model(embeddings, torch.tensor([0]))\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 1.4072,  0.7952, -0.3502,  ...,  2.0938,  3.0346,  1.7648],\n",
      "         [-9.5823, -5.0563, -1.2308,  ..., -6.2960, -8.3478, -7.7177],\n",
      "         [-5.5127, -6.3697,  8.1133,  ..., -3.5720, -1.9828, -2.7889],\n",
      "         ...,\n",
      "         [-5.6315, -2.3222,  8.8651,  ..., -1.3108, -3.9975, -2.9413],\n",
      "         [-3.1874, -1.6479,  7.5750,  ...,  0.6132, -0.3697,  1.1412],\n",
      "         [-1.1888, -1.4724,  9.7332,  ...,  1.5810,  1.8806,  1.8634]]],\n",
      "       grad_fn=<UnsafeViewBackward0>),)\n"
     ]
    }
   ],
   "source": [
    "print(llava.prefill_ref(prompt_before_image, resized, prompt_after_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = torch.export.Dim(\"token_dim\", min=1, max=llava.text_model_args.max_seq_len - 1)\n",
    "pos_dim = 1\n",
    "text_model_dynamic_shapes = ({1: dim}, {0: pos_dim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "\n",
    "from executorch.examples.models.llama2.source_transformation.sdpa import replace_sdpa_with_custom_op\n",
    "from executorch.examples.models.llava_encoder.model import get_prompt\n",
    "from llava.constants import (\n",
    "    IMAGE_TOKEN_INDEX,\n",
    ")\n",
    "\n",
    "from llava.mm_utils import get_model_name_from_path, tokenizer_image_token\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch import nn\n",
    "from torch.export import Dim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms._functional_tensor import resize\n",
    "\n",
    "from transformers import LlamaForCausalLM\n",
    "\n",
    "model_name = get_model_name_from_path(\"liuhaotian/llava-v1.5-7b\")\n",
    "prompt = get_prompt(\"What are the things I should be cautious about when I visit here?\", False, model_name)\n",
    "input_ids = (\n",
    "    tokenizer_image_token(\n",
    "        prompt, llava_model.tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\"\n",
    "    )\n",
    "    .unsqueeze(0)\n",
    "    .cpu()\n",
    ")\n",
    "index = torch.where(input_ids == IMAGE_TOKEN_INDEX)[1]\n",
    "prompt_before_image = input_ids[:, :index]\n",
    "# print(prompt_before_image.shape)\n",
    "prompt_after_image = input_ids[:, index + 1 :]\n",
    "# print(prompt_after_image.shape)\n",
    "imagr = torchvision.io.read_image(\"./view.jpg\")\n",
    "ratio = max(imagr.shape[1], imagr.shape[2]) / llava_model.image_processor.crop_size[\"height\"]\n",
    "output_size = (int(imagr.shape[1] / ratio), int(imagr.shape[2] / ratio))\n",
    "resized = torchvision.transforms.Resize(size=output_size)(imagr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: <image>\n",
      "What are the things I should be cautious about when I visit here? ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x312060950>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(torchvision.transforms.ToPILImage()(resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_model.model.generate(\n",
    "    input_ids,\n",
    "    images=resized,\n",
    "    image_sizes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.eval.run_llava import load_images, process_images\n",
    "from llava.model.builder import load_pretrained_model\n",
    "\n",
    "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
    "tokenizer, model, image_processor, context_len = (\n",
    "    load_pretrained_model(\n",
    "        model_path=model_path,\n",
    "        model_base=None,\n",
    "        model_name=get_model_name_from_path(model_path),\n",
    "        device_map=\"cpu\",\n",
    "        device=\"cpu\",\n",
    "    )\n",
    ")\n",
    "img = load_images([\"view.jpg\"])\n",
    "img_tensor = process_images(img, image_processor, model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3116b2410>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torchvision.transforms.ToPILImage()(img_tensor.squeeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = llava.image_preprocess(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x311750cd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torchvision.transforms.ToPILImage()(preprocessed.squeeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0045, -0.0038,  0.0017,  ..., -0.0088,  0.0025, -0.0025],\n",
      "         [-0.0112, -0.0129, -0.0121,  ...,  0.0090,  0.0118, -0.0081],\n",
      "         [ 0.0195, -0.0058,  0.0061,  ...,  0.0171, -0.0052, -0.0212],\n",
      "         ...,\n",
      "         [-0.0187, -0.0017,  0.0177,  ...,  0.0238,  0.0052,  0.0101],\n",
      "         [ 0.0066, -0.0161,  0.0117,  ..., -0.0103,  0.0148,  0.0073],\n",
      "         [ 0.0039,  0.0015,  0.0055,  ..., -0.0042,  0.0151,  0.0024]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "position_ids = torch.arange(0, input_ids.shape[1], dtype=torch.long, device=input_ids.device)\n",
    "_, _, _, _, inputs_embeds, _ = llava_model.model.prepare_inputs_labels_for_multimodal(\n",
    "    input_ids, \n",
    "    position_ids=position_ids, \n",
    "    attention_mask=None, \n",
    "    past_key_values=None, \n",
    "    labels=None,\n",
    "    images=preprocessed, \n",
    "    image_sizes=[preprocessed.size],\n",
    ")\n",
    "print(inputs_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LlavaLlamaForCausalLM.forward() got an unexpected keyword argument 'cache_position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llava_model\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(input_ids, images\u001b[39m=\u001b[39;49mpreprocessed, image_sizes\u001b[39m=\u001b[39;49m[preprocessed\u001b[39m.\u001b[39;49msize], do_sample\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, temperature\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, top_p\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, num_beams\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, use_cache\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/CLionProjects/executorch/examples/third-party/LLaVA/llava/model/language_model/llava_llama.py:137\u001b[0m, in \u001b[0;36mLlavaLlamaForCausalLM.generate\u001b[0;34m(self, inputs, images, image_sizes, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model()\u001b[39m.\u001b[39membed_tokens(inputs)\n\u001b[0;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    138\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    139\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    140\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    141\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    142\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/transformers/generation/utils.py:1544\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   1527\u001b[0m         input_ids,\n\u001b[1;32m   1528\u001b[0m         candidate_generator\u001b[39m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1541\u001b[0m     )\n\u001b[1;32m   1542\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1543\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1544\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1545\u001b[0m         input_ids,\n\u001b[1;32m   1546\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mprepared_logits_processor,\n\u001b[1;32m   1547\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mprepared_stopping_criteria,\n\u001b[1;32m   1548\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1549\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1550\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1551\u001b[0m         output_logits\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_logits,\n\u001b[1;32m   1552\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1553\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1554\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1555\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1556\u001b[0m     )\n\u001b[1;32m   1558\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1559\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/transformers/generation/utils.py:2404\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2401\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2403\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2404\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2405\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2406\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2407\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2408\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2409\u001b[0m )\n\u001b[1;32m   2411\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2412\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1657\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1657\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1675\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m   1666\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks\n\u001b[1;32m   1667\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[39mor\u001b[39;00m _global_forward_pre_hooks\n\u001b[1;32m   1674\u001b[0m ):\n\u001b[0;32m-> 1675\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1677\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1678\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: LlavaLlamaForCausalLM.forward() got an unexpected keyword argument 'cache_position'"
     ]
    }
   ],
   "source": [
    "llava_model.model.generate(input_ids, images=preprocessed, image_sizes=[preprocessed.size], do_sample=False, temperature=0.0, top_p=None, num_beams=1, max_new_tokens=50, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 634, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(inputs_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_inputs_embeds = llava.prefill_embedding(prompt_before_image, resized, prompt_after_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 634, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(actual_inputs_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(inputs_embeds, actual_inputs_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_prefill_logits = llava.prefill_ref(prompt_before_image, resized, prompt_after_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.4072,  0.7952, -0.3502,  ...,  2.0938,  3.0346,  1.7648],\n",
      "         [-9.5823, -5.0563, -1.2308,  ..., -6.2960, -8.3478, -7.7177],\n",
      "         [-5.5127, -6.3697,  8.1133,  ..., -3.5720, -1.9828, -2.7889],\n",
      "         ...,\n",
      "         [-5.6315, -2.3222,  8.8651,  ..., -1.3108, -3.9975, -2.9413],\n",
      "         [-3.1874, -1.6479,  7.5750,  ...,  0.6132, -0.3697,  1.1412],\n",
      "         [-1.1888, -1.4724,  9.7332,  ...,  1.5810,  1.8806,  1.8634]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(ref_prefill_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(ref_prefill_logits, prefill_logits, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.choose_qparams_per_token_asymmetric.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.quantize_per_token.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.dequantize_per_token.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.dequantize_per_channel_group.default to be one such op.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.nn.attention import SDPBackend\n",
    "\n",
    "with torch.nn.attention.sdpa_kernel([SDPBackend.MATH]), torch.no_grad():\n",
    "    text_export_program = torch.export.export(\n",
    "        llava_text_model, \n",
    "        (embeddings, torch.tensor([0], dtype=torch.int64)), \n",
    "        dynamic_shapes=text_model_dynamic_shapes, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "text_export_program.module()(embeddings, torch.tensor([0], dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_unlift.py:59: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer\n",
      "  getattr_node = gm.graph.get_attr(lifted_node)\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_0 target lifted_tensor_0 lifted_tensor_0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_1 target lifted_tensor_1 lifted_tensor_1 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_2 target lifted_tensor_2 lifted_tensor_2 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n"
     ]
    }
   ],
   "source": [
    "from executorch.examples.models.llama2.builder import LlamaEdgeManager, DType\n",
    "from executorch.examples.models.llama2.export_llama_lib import WeightType\n",
    "from executorch.extension.llm.export.partitioner_lib import get_xnnpack_partitioner\n",
    "from executorch.examples.models.llama2.source_transformation.sdpa import replace_sdpa_with_custom_op\n",
    "from executorch.examples.models.llama2.source_transformation.quantize import get_quant_weight_transform\n",
    "from executorch.examples.models.llama2.export_llama_lib import build_args_parser, get_quantizer_and_quant_params\n",
    "from torch.ao.quantization.quantizer.xnnpack_quantizer import (\n",
    "    get_symmetric_quantization_config,\n",
    "    XNNPACKQuantizer,\n",
    ")\n",
    "\n",
    "class LlavaImageEncoder(torch.nn.Module):\n",
    "    \"\"\" Takes images and prompts and encode them into embeddings. Result will be sent to the text model LlavaTextModel.\"\"\"\n",
    "    def __init__(self, llava):\n",
    "        super().__init__()\n",
    "        self.llava = llava\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.llava.image_embedding(image)\n",
    "    \n",
    "    \n",
    "height = Dim(\"height\", min=1, max=336)\n",
    "width = Dim(\"width\", min=28, max=336)\n",
    "image_dynamic_shapes = [{1: height, 2: width}]\n",
    "\n",
    "llava_image_encode = LlavaImageEncoder(llava)\n",
    "\n",
    "# quantizer\n",
    "linear_quantizer = XNNPACKQuantizer()\n",
    "operator_config_dynamic = get_symmetric_quantization_config(\n",
    "    is_per_channel=True, is_dynamic=True\n",
    ")\n",
    "linear_quantizer.set_global(operator_config_dynamic)\n",
    "image_encoder_ep = LlavaEdgeManager(\n",
    "    model=llava_image_encode,\n",
    "    modelname=\"llava_image_encoder\",\n",
    "    weight_type=WeightType.LLAMA,\n",
    "    dtype=DType.fp32,\n",
    "    use_kv_cache=True,\n",
    "    use_sdpa_with_kv_cache=True,\n",
    "    example_inputs=(resized,),\n",
    "    dynamic_shapes=image_dynamic_shapes,\n",
    ").capture_pre_autograd_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-07-10 16:26:15,832 xnnpack_partitioner.py:920] Found 257 subgraphs to be partitioned.\n",
      "[INFO 2024-07-10 16:27:18,848 builder.py:276] Required memory for activation in bytes: [0, 173387968]\n"
     ]
    }
   ],
   "source": [
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\n",
    "executorch_program = image_encoder_ep.to_backend([XnnpackPartitioner()]).to_executorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-07-10 16:29:13,677 utils.py:115] Saved exported program to llava_image_encoder.pte\n"
     ]
    }
   ],
   "source": [
    "executorch_program.save_to_pte(\"llava_image_encoder.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = torch.nn.Embedding(llava.model_.config.vocab_size, llava.model_.config.hidden_size, llava.model_.config.pad_token_id)\n",
    "embed.load_state_dict(llava.model_.get_model().embed_tokens.state_dict(), strict=True, assign=True)\n",
    "embed = embed.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dim_1 = Dim(\"token_dim_1\", min=2, max=3518)\n",
    "dynamic_shapes = [{1: token_dim_1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    token_embedding_ep = torch.export.export(embed, (prompt_before_image,), dynamic_shapes=dynamic_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.exir import to_edge, EdgeCompileConfig\n",
    "\n",
    "embedding_program = to_edge(token_embedding_ep).to_executorch()\n",
    "with open(\"llava_embedding.pte\", \"wb\") as f:\n",
    "    embedding_program.write_to_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[program.cpp:130] InternalConsistency verification requested but not available\n"
     ]
    }
   ],
   "source": [
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "\n",
    "m = _load_for_executorch(\"llava_embedding.pte\")\n",
    "embed1 = m.forward((torch.tensor([[1]], dtype=torch.int64), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = llava.prefill_embedding(prompt_before_image, resized, prompt_after_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-07-11 17:10:43,764 export_llama_lib.py:417] Applying quantizers: []\n",
      "[INFO 2024-07-11 17:10:43,767 sdpa_with_kv_cache.py:24] Loading custom ops library: /Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/examples/models/llama2/custom_ops/libcustom_ops_aot_lib.dylib\n",
      "[INFO 2024-07-11 17:10:43,842 __init__.py:24] Skipping import of cpp extensions\n",
      "[INFO 2024-07-11 17:10:44,474 config.py:58] PyTorch version 2.5.0.dev20240618 available.\n",
      "[INFO 2024-07-11 17:10:44,475 config.py:95] TensorFlow version 2.16.1 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear: layers.0.attention.wq, in=4096, out=4096\n",
      "linear: layers.0.attention.wk, in=4096, out=4096\n",
      "linear: layers.0.attention.wv, in=4096, out=4096\n",
      "linear: layers.0.attention.wo, in=4096, out=4096\n",
      "linear: layers.0.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.0.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.0.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.1.attention.wq, in=4096, out=4096\n",
      "linear: layers.1.attention.wk, in=4096, out=4096\n",
      "linear: layers.1.attention.wv, in=4096, out=4096\n",
      "linear: layers.1.attention.wo, in=4096, out=4096\n",
      "linear: layers.1.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.1.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.1.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.2.attention.wq, in=4096, out=4096\n",
      "linear: layers.2.attention.wk, in=4096, out=4096\n",
      "linear: layers.2.attention.wv, in=4096, out=4096\n",
      "linear: layers.2.attention.wo, in=4096, out=4096\n",
      "linear: layers.2.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.2.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.2.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.3.attention.wq, in=4096, out=4096\n",
      "linear: layers.3.attention.wk, in=4096, out=4096\n",
      "linear: layers.3.attention.wv, in=4096, out=4096\n",
      "linear: layers.3.attention.wo, in=4096, out=4096\n",
      "linear: layers.3.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.3.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.3.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.4.attention.wq, in=4096, out=4096\n",
      "linear: layers.4.attention.wk, in=4096, out=4096\n",
      "linear: layers.4.attention.wv, in=4096, out=4096\n",
      "linear: layers.4.attention.wo, in=4096, out=4096\n",
      "linear: layers.4.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.4.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.4.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.5.attention.wq, in=4096, out=4096\n",
      "linear: layers.5.attention.wk, in=4096, out=4096\n",
      "linear: layers.5.attention.wv, in=4096, out=4096\n",
      "linear: layers.5.attention.wo, in=4096, out=4096\n",
      "linear: layers.5.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.5.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.5.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.6.attention.wq, in=4096, out=4096\n",
      "linear: layers.6.attention.wk, in=4096, out=4096\n",
      "linear: layers.6.attention.wv, in=4096, out=4096\n",
      "linear: layers.6.attention.wo, in=4096, out=4096\n",
      "linear: layers.6.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.6.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.6.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.7.attention.wq, in=4096, out=4096\n",
      "linear: layers.7.attention.wk, in=4096, out=4096\n",
      "linear: layers.7.attention.wv, in=4096, out=4096\n",
      "linear: layers.7.attention.wo, in=4096, out=4096\n",
      "linear: layers.7.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.7.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.7.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.8.attention.wq, in=4096, out=4096\n",
      "linear: layers.8.attention.wk, in=4096, out=4096\n",
      "linear: layers.8.attention.wv, in=4096, out=4096\n",
      "linear: layers.8.attention.wo, in=4096, out=4096\n",
      "linear: layers.8.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.8.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.8.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.9.attention.wq, in=4096, out=4096\n",
      "linear: layers.9.attention.wk, in=4096, out=4096\n",
      "linear: layers.9.attention.wv, in=4096, out=4096\n",
      "linear: layers.9.attention.wo, in=4096, out=4096\n",
      "linear: layers.9.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.9.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.9.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.10.attention.wq, in=4096, out=4096\n",
      "linear: layers.10.attention.wk, in=4096, out=4096\n",
      "linear: layers.10.attention.wv, in=4096, out=4096\n",
      "linear: layers.10.attention.wo, in=4096, out=4096\n",
      "linear: layers.10.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.10.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.10.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.11.attention.wq, in=4096, out=4096\n",
      "linear: layers.11.attention.wk, in=4096, out=4096\n",
      "linear: layers.11.attention.wv, in=4096, out=4096\n",
      "linear: layers.11.attention.wo, in=4096, out=4096\n",
      "linear: layers.11.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.11.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.11.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.12.attention.wq, in=4096, out=4096\n",
      "linear: layers.12.attention.wk, in=4096, out=4096\n",
      "linear: layers.12.attention.wv, in=4096, out=4096\n",
      "linear: layers.12.attention.wo, in=4096, out=4096\n",
      "linear: layers.12.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.12.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.12.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.13.attention.wq, in=4096, out=4096\n",
      "linear: layers.13.attention.wk, in=4096, out=4096\n",
      "linear: layers.13.attention.wv, in=4096, out=4096\n",
      "linear: layers.13.attention.wo, in=4096, out=4096\n",
      "linear: layers.13.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.13.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.13.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.14.attention.wq, in=4096, out=4096\n",
      "linear: layers.14.attention.wk, in=4096, out=4096\n",
      "linear: layers.14.attention.wv, in=4096, out=4096\n",
      "linear: layers.14.attention.wo, in=4096, out=4096\n",
      "linear: layers.14.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.14.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.14.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.15.attention.wq, in=4096, out=4096\n",
      "linear: layers.15.attention.wk, in=4096, out=4096\n",
      "linear: layers.15.attention.wv, in=4096, out=4096\n",
      "linear: layers.15.attention.wo, in=4096, out=4096\n",
      "linear: layers.15.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.15.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.15.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.16.attention.wq, in=4096, out=4096\n",
      "linear: layers.16.attention.wk, in=4096, out=4096\n",
      "linear: layers.16.attention.wv, in=4096, out=4096\n",
      "linear: layers.16.attention.wo, in=4096, out=4096\n",
      "linear: layers.16.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.16.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.16.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.17.attention.wq, in=4096, out=4096\n",
      "linear: layers.17.attention.wk, in=4096, out=4096\n",
      "linear: layers.17.attention.wv, in=4096, out=4096\n",
      "linear: layers.17.attention.wo, in=4096, out=4096\n",
      "linear: layers.17.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.17.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.17.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.18.attention.wq, in=4096, out=4096\n",
      "linear: layers.18.attention.wk, in=4096, out=4096\n",
      "linear: layers.18.attention.wv, in=4096, out=4096\n",
      "linear: layers.18.attention.wo, in=4096, out=4096\n",
      "linear: layers.18.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.18.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.18.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.19.attention.wq, in=4096, out=4096\n",
      "linear: layers.19.attention.wk, in=4096, out=4096\n",
      "linear: layers.19.attention.wv, in=4096, out=4096\n",
      "linear: layers.19.attention.wo, in=4096, out=4096\n",
      "linear: layers.19.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.19.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.19.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.20.attention.wq, in=4096, out=4096\n",
      "linear: layers.20.attention.wk, in=4096, out=4096\n",
      "linear: layers.20.attention.wv, in=4096, out=4096\n",
      "linear: layers.20.attention.wo, in=4096, out=4096\n",
      "linear: layers.20.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.20.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.20.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.21.attention.wq, in=4096, out=4096\n",
      "linear: layers.21.attention.wk, in=4096, out=4096\n",
      "linear: layers.21.attention.wv, in=4096, out=4096\n",
      "linear: layers.21.attention.wo, in=4096, out=4096\n",
      "linear: layers.21.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.21.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.21.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.22.attention.wq, in=4096, out=4096\n",
      "linear: layers.22.attention.wk, in=4096, out=4096\n",
      "linear: layers.22.attention.wv, in=4096, out=4096\n",
      "linear: layers.22.attention.wo, in=4096, out=4096\n",
      "linear: layers.22.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.22.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.22.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.23.attention.wq, in=4096, out=4096\n",
      "linear: layers.23.attention.wk, in=4096, out=4096\n",
      "linear: layers.23.attention.wv, in=4096, out=4096\n",
      "linear: layers.23.attention.wo, in=4096, out=4096\n",
      "linear: layers.23.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.23.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.23.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.24.attention.wq, in=4096, out=4096\n",
      "linear: layers.24.attention.wk, in=4096, out=4096\n",
      "linear: layers.24.attention.wv, in=4096, out=4096\n",
      "linear: layers.24.attention.wo, in=4096, out=4096\n",
      "linear: layers.24.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.24.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.24.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.25.attention.wq, in=4096, out=4096\n",
      "linear: layers.25.attention.wk, in=4096, out=4096\n",
      "linear: layers.25.attention.wv, in=4096, out=4096\n",
      "linear: layers.25.attention.wo, in=4096, out=4096\n",
      "linear: layers.25.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.25.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.25.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.26.attention.wq, in=4096, out=4096\n",
      "linear: layers.26.attention.wk, in=4096, out=4096\n",
      "linear: layers.26.attention.wv, in=4096, out=4096\n",
      "linear: layers.26.attention.wo, in=4096, out=4096\n",
      "linear: layers.26.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.26.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.26.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.27.attention.wq, in=4096, out=4096\n",
      "linear: layers.27.attention.wk, in=4096, out=4096\n",
      "linear: layers.27.attention.wv, in=4096, out=4096\n",
      "linear: layers.27.attention.wo, in=4096, out=4096\n",
      "linear: layers.27.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.27.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.27.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.28.attention.wq, in=4096, out=4096\n",
      "linear: layers.28.attention.wk, in=4096, out=4096\n",
      "linear: layers.28.attention.wv, in=4096, out=4096\n",
      "linear: layers.28.attention.wo, in=4096, out=4096\n",
      "linear: layers.28.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.28.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.28.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.29.attention.wq, in=4096, out=4096\n",
      "linear: layers.29.attention.wk, in=4096, out=4096\n",
      "linear: layers.29.attention.wv, in=4096, out=4096\n",
      "linear: layers.29.attention.wo, in=4096, out=4096\n",
      "linear: layers.29.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.29.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.29.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.30.attention.wq, in=4096, out=4096\n",
      "linear: layers.30.attention.wk, in=4096, out=4096\n",
      "linear: layers.30.attention.wv, in=4096, out=4096\n",
      "linear: layers.30.attention.wo, in=4096, out=4096\n",
      "linear: layers.30.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.30.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.30.feed_forward.w3, in=4096, out=11008\n",
      "linear: layers.31.attention.wq, in=4096, out=4096\n",
      "linear: layers.31.attention.wk, in=4096, out=4096\n",
      "linear: layers.31.attention.wv, in=4096, out=4096\n",
      "linear: layers.31.attention.wo, in=4096, out=4096\n",
      "linear: layers.31.feed_forward.w1, in=4096, out=11008\n",
      "linear: layers.31.feed_forward.w2, in=11008, out=4096\n",
      "linear: layers.31.feed_forward.w3, in=4096, out=11008\n",
      "linear: output, in=4096, out=32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 17:11:17.782000 8283245568 torch/_export/__init__.py:92] +============================+\n",
      "W0711 17:11:17.787000 8283245568 torch/_export/__init__.py:93] |     !!!   WARNING   !!!    |\n",
      "W0711 17:11:17.788000 8283245568 torch/_export/__init__.py:94] +============================+\n",
      "W0711 17:11:17.788000 8283245568 torch/_export/__init__.py:95] capture_pre_autograd_graph() is deprecated and doesn't provide any function guarantee moving forward.\n",
      "W0711 17:11:17.788000 8283245568 torch/_export/__init__.py:96] Please switch to use torch.export instead.\n",
      "[INFO 2024-07-11 17:11:34,950 builder.py:179] Using pt2e [] to quantizing the model...\n",
      "[INFO 2024-07-11 17:11:34,950 builder.py:199] No quantizer provided, passing...\n"
     ]
    }
   ],
   "source": [
    "from executorch.examples.models.llama2.builder import LlamaEdgeManager, DType\n",
    "from executorch.examples.models.llama2.export_llama_lib import WeightType\n",
    "from executorch.extension.llm.export.partitioner_lib import get_xnnpack_partitioner\n",
    "from executorch.examples.models.llama2.source_transformation.sdpa import replace_sdpa_with_custom_op\n",
    "from executorch.examples.models.llama2.source_transformation.quantize import get_quant_weight_transform\n",
    "from executorch.examples.models.llama2.export_llama_lib import build_args_parser, get_quantizer_and_quant_params\n",
    "\n",
    "\n",
    "llava_text_model = llava.text_model\n",
    "\n",
    "dim = torch.export.Dim(\"token_dim\", min=1, max=llava.text_model_args.max_seq_len - 1)\n",
    "pos_dim = 1\n",
    "text_model_dynamic_shapes = ({1: dim}, {0: pos_dim})\n",
    "\n",
    "class LlavaEdgeManager(LlamaEdgeManager):\n",
    "    def __init__(self, model, modelname, weight_type, dtype, use_kv_cache, use_sdpa_with_kv_cache, example_inputs):\n",
    "        super().__init__(model, modelname, weight_type, dtype, use_kv_cache, use_sdpa_with_kv_cache, example_inputs)\n",
    "    \n",
    "    def _get_dynamic_shape(self) -> torch.Any:\n",
    "        return text_model_dynamic_shapes\n",
    "    \n",
    "text_model_em = LlavaEdgeManager(\n",
    "    model=llava_text_model,\n",
    "    modelname=\"llava_text_model\",\n",
    "    weight_type=WeightType.LLAMA,\n",
    "    dtype=DType.fp32,\n",
    "    use_kv_cache=True,\n",
    "    use_sdpa_with_kv_cache=True,\n",
    "    example_inputs=(embeddings, torch.tensor([0], dtype=torch.int64))\n",
    ")\n",
    "\n",
    "dtype_override = DType.fp32\n",
    "parser = build_args_parser()\n",
    "args = parser.parse_args(['-X', '-qmode', '8da4w', '--group_size', '128', '--embedding-quantize', '4,32'])\n",
    "quant_transform = get_quant_weight_transform(args, dtype_override, False)\n",
    "pt2e_quant_params, quantizers, quant_dtype = get_quantizer_and_quant_params(args)\n",
    "\n",
    "manager = (\n",
    "    text_model_em\n",
    "    .set_output_dir(\"./\")\n",
    "    .to_dtype(dtype_override)\n",
    "    .source_transform([replace_sdpa_with_custom_op, quant_transform])\n",
    "    .capture_pre_autograd_graph()\n",
    "    .pt2e_quantize(quantizers)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.choose_qparams_per_token_asymmetric.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.quantize_per_token.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.dequantize_per_token.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.dequantize_per_channel_group.default to be one such op.\n",
      "  warnings.warn(\n",
      "[INFO 2024-07-11 00:33:07,322 xnnpack_partitioner.py:560] Found 225 subgraphs to be partitioned.\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036] Ignored guard u363 < 2048 == True, this could result in accuracy problems\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036] Stack (most recent call last):\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"<frozen runpy>\", line 88, in _run_code\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     app.launch_new_instance()\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     app.start()\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.io_loop.start()\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.asyncio_loop.run_forever()\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._run_once()\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     handle._run()\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._context.run(self._callback, *self._args)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await self.process_one()\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await dispatch(*args)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await result\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await super().execute_request(stream, ident, parent)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     reply_content = await reply_content\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = shell.run_cell(\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().run_cell(*args, **kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = self._run_cell(\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = runner(coro)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     coro.send(None)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     if await self.run_code(code, result, async_=asy):\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/ipykernel_81074/3857086709.py\", line 7, in <module>\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     executorch_program = manager.export_to_edge().to_backend([XnnpackDynamicallyQuantizedPartitioner()]).to_executorch().save_to_pte(\"llava_text_model.pte\")\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/examples/models/llama2/builder.py\", line 244, in to_backend\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.edge_manager = self.edge_manager.to_backend(partitioner)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/program/_program.py\", line 1165, in to_backend\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     new_edge_programs[name] = to_backend(program, partitioner)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/functools.py\", line 909, in wrapper\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return dispatch(args[0].__class__)(*args, **kw)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/backend/backend_api.py\", line 384, in _\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     tagged_graph_module = _partition_and_lower(\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/backend/backend_api.py\", line 316, in _partition_and_lower\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = ExportPass()(tagged_graph_module)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/passes/infra/pass_base.py\", line 41, in __call__\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = self.call(graph_module)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 572, in call\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = self.call_submodule(graph_module, tuple(inputs))\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 658, in call_submodule\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = super().call_submodule(graph_module, inputs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 535, in call_submodule\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     interpreter.run(*inputs_data)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 146, in run\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.env[node] = self.run_node(node)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 375, in run_node\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().run_node(n)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 203, in run_node\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 636, in call_function\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().call_function(target, args, kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 330, in call_function\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.callback.call_operator(\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 466, in call_operator\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self._fx(\"call_function\", op, args, kwargs, meta)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 397, in _fx\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res_data = getattr(self.interpreter, kind)(target, args_data, kwargs_data)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 275, in call_function\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return target(*args, **kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_ops.py\", line 670, in __call__\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self_._op(*args, **kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return fn(*args, **kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.dispatch(func, types, args, kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1757, in _dispatch_impl\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     r = func(*args, **kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_ops.py\", line 670, in __call__\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self_._op(*args, **kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 435, in expect_true\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.shape_env.defer_runtime_assert(\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return fn(*args, **kwargs)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5360, in defer_runtime_assert\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._check_frozen(expr, sympy.true)\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5036, in _check_frozen\n",
      "W0711 00:35:28.550000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036] Ignored guard u363 >= 0 == True, this could result in accuracy problems\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036] Stack (most recent call last):\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"<frozen runpy>\", line 88, in _run_code\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     app.launch_new_instance()\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     app.start()\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.io_loop.start()\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.asyncio_loop.run_forever()\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._run_once()\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     handle._run()\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._context.run(self._callback, *self._args)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await self.process_one()\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await dispatch(*args)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await result\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await super().execute_request(stream, ident, parent)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     reply_content = await reply_content\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = shell.run_cell(\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().run_cell(*args, **kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = self._run_cell(\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = runner(coro)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     coro.send(None)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     if await self.run_code(code, result, async_=asy):\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/ipykernel_81074/3857086709.py\", line 7, in <module>\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     executorch_program = manager.export_to_edge().to_backend([XnnpackDynamicallyQuantizedPartitioner()]).to_executorch().save_to_pte(\"llava_text_model.pte\")\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/examples/models/llama2/builder.py\", line 244, in to_backend\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.edge_manager = self.edge_manager.to_backend(partitioner)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/program/_program.py\", line 1165, in to_backend\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     new_edge_programs[name] = to_backend(program, partitioner)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/functools.py\", line 909, in wrapper\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return dispatch(args[0].__class__)(*args, **kw)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/backend/backend_api.py\", line 384, in _\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     tagged_graph_module = _partition_and_lower(\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/backend/backend_api.py\", line 316, in _partition_and_lower\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = ExportPass()(tagged_graph_module)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/passes/infra/pass_base.py\", line 41, in __call__\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = self.call(graph_module)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 572, in call\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = self.call_submodule(graph_module, tuple(inputs))\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 658, in call_submodule\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = super().call_submodule(graph_module, inputs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 535, in call_submodule\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     interpreter.run(*inputs_data)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 146, in run\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.env[node] = self.run_node(node)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 375, in run_node\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().run_node(n)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 203, in run_node\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 636, in call_function\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().call_function(target, args, kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 330, in call_function\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.callback.call_operator(\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 466, in call_operator\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self._fx(\"call_function\", op, args, kwargs, meta)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 397, in _fx\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res_data = getattr(self.interpreter, kind)(target, args_data, kwargs_data)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 275, in call_function\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return target(*args, **kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_ops.py\", line 670, in __call__\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self_._op(*args, **kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return fn(*args, **kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.dispatch(func, types, args, kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1757, in _dispatch_impl\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     r = func(*args, **kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_ops.py\", line 670, in __call__\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self_._op(*args, **kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 435, in expect_true\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.shape_env.defer_runtime_assert(\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return fn(*args, **kwargs)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5360, in defer_runtime_assert\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._check_frozen(expr, sympy.true)\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5036, in _check_frozen\n",
      "W0711 00:35:28.555000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036] Ignored guard u396 < 2048 == True, this could result in accuracy problems\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036] Stack (most recent call last):\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"<frozen runpy>\", line 88, in _run_code\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     app.launch_new_instance()\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     app.start()\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.io_loop.start()\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.asyncio_loop.run_forever()\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._run_once()\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     handle._run()\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._context.run(self._callback, *self._args)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await self.process_one()\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await dispatch(*args)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await result\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await super().execute_request(stream, ident, parent)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     reply_content = await reply_content\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = shell.run_cell(\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().run_cell(*args, **kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = self._run_cell(\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = runner(coro)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     coro.send(None)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     if await self.run_code(code, result, async_=asy):\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/ipykernel_81074/3857086709.py\", line 7, in <module>\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     executorch_program = manager.export_to_edge().to_backend([XnnpackDynamicallyQuantizedPartitioner()]).to_executorch().save_to_pte(\"llava_text_model.pte\")\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/examples/models/llama2/builder.py\", line 263, in to_executorch\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.export_program = self.edge_manager.to_executorch(\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/program/_program.py\", line 1195, in to_executorch\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     new_gm_res = p(new_gm)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/passes/infra/pass_base.py\", line 41, in __call__\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = self.call(graph_module)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 572, in call\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = self.call_submodule(graph_module, tuple(inputs))\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 658, in call_submodule\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = super().call_submodule(graph_module, inputs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 535, in call_submodule\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     interpreter.run(*inputs_data)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 146, in run\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.env[node] = self.run_node(node)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 375, in run_node\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().run_node(n)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 203, in run_node\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 636, in call_function\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().call_function(target, args, kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 330, in call_function\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.callback.call_operator(\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/passes/spec_prop_pass.py\", line 96, in call_operator\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     meta[\"spec\"] = pytree.tree_map(make_spec, op(*args_data, **kwargs_data))\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_ops.py\", line 670, in __call__\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self_._op(*args, **kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return fn(*args, **kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.dispatch(func, types, args, kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1757, in _dispatch_impl\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     r = func(*args, **kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_ops.py\", line 670, in __call__\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self_._op(*args, **kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 435, in expect_true\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.shape_env.defer_runtime_assert(\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return fn(*args, **kwargs)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5360, in defer_runtime_assert\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._check_frozen(expr, sympy.true)\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5036, in _check_frozen\n",
      "W0711 00:35:31.302000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036] Ignored guard u396 >= 0 == True, this could result in accuracy problems\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036] Stack (most recent call last):\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"<frozen runpy>\", line 88, in _run_code\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     app.launch_new_instance()\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     app.start()\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.io_loop.start()\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.asyncio_loop.run_forever()\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._run_once()\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     handle._run()\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._context.run(self._callback, *self._args)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await self.process_one()\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await dispatch(*args)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await result\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     await super().execute_request(stream, ident, parent)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     reply_content = await reply_content\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = shell.run_cell(\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().run_cell(*args, **kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = self._run_cell(\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = runner(coro)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     coro.send(None)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     if await self.run_code(code, result, async_=asy):\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/ipykernel_81074/3857086709.py\", line 7, in <module>\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     executorch_program = manager.export_to_edge().to_backend([XnnpackDynamicallyQuantizedPartitioner()]).to_executorch().save_to_pte(\"llava_text_model.pte\")\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/examples/models/llama2/builder.py\", line 263, in to_executorch\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.export_program = self.edge_manager.to_executorch(\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/program/_program.py\", line 1195, in to_executorch\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     new_gm_res = p(new_gm)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/passes/infra/pass_base.py\", line 41, in __call__\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = self.call(graph_module)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 572, in call\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     result = self.call_submodule(graph_module, tuple(inputs))\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 658, in call_submodule\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     res = super().call_submodule(graph_module, inputs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 535, in call_submodule\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     interpreter.run(*inputs_data)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 146, in run\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self.env[node] = self.run_node(node)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 375, in run_node\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().run_node(n)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 203, in run_node\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 636, in call_function\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return super().call_function(target, args, kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/pass_base.py\", line 330, in call_function\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.callback.call_operator(\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/passes/spec_prop_pass.py\", line 96, in call_operator\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     meta[\"spec\"] = pytree.tree_map(make_spec, op(*args_data, **kwargs_data))\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_ops.py\", line 670, in __call__\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self_._op(*args, **kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return fn(*args, **kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.dispatch(func, types, args, kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1757, in _dispatch_impl\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     r = func(*args, **kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_ops.py\", line 670, in __call__\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self_._op(*args, **kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 435, in expect_true\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return self.shape_env.defer_runtime_assert(\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     return fn(*args, **kwargs)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5360, in defer_runtime_assert\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     self._check_frozen(expr, sympy.true)\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]   File \"/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5036, in _check_frozen\n",
      "W0711 00:35:31.306000 8283245568 torch/fx/experimental/symbolic_shapes.py:5036]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/emit/_emitter.py:1480: UserWarning: Mutation on a buffer in the model is detected. ExecuTorch assumes buffers that are mutated in the graph have a meaningless initial state, only the shape and dtype will be serialized.\n",
      "  warnings.warn(\n",
      "[INFO 2024-07-11 00:35:37,570 builder.py:276] Required memory for activation in bytes: [0, 3519399424]\n",
      "[INFO 2024-07-11 00:35:46,990 utils.py:115] Saved exported program to llava_text_model.pte\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir import to_edge, EdgeCompileConfig\n",
    "\n",
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import (\n",
    "        XnnpackDynamicallyQuantizedPartitioner,\n",
    "        # XnnpackFloatingPointPartitioner,\n",
    "    )\n",
    "executorch_program = manager.export_to_edge().to_backend([XnnpackDynamicallyQuantizedPartitioner()]).to_executorch().save_to_pte(\"llava_text_model.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.choose_qparams_per_token_asymmetric.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.quantize_per_token.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.dequantize_per_token.default to be one such op.\n",
      "  warnings.warn(\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:362: UserWarning: At pre-dispatch tracing, we will assume that any custom op that is marked with CompositeImplicitAutograd and functional are safe to not decompose. We found quantized_decomposed.dequantize_per_channel_group.default to be one such op.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    text_model_ep = torch.export.export(manager.pre_autograd_graph_module, manager.example_inputs, dynamic_shapes=manager._get_dynamic_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image_encoder_ep = torch.export.export(image_encoder_ep.pre_autograd_graph_module, image_encoder_ep.example_inputs, dynamic_shapes=image_encoder_ep.dynamic_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.exir import to_edge, EdgeCompileConfig\n",
    "\n",
    "edge_ep = to_edge({\n",
    "    \"image_encoder\": image_encoder_ep,\n",
    "    \"token_embedding\": token_embedding_ep,\n",
    "    \"text_model\": text_model_ep,\n",
    "}, compile_config=EdgeCompileConfig(_check_ir_validity=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.exir.dialects._ops import ops as exir_ops\n",
    "\n",
    "SUPPORTED_OPS = [\n",
    "    # exir_ops.edge.aten.div.Tensor,\n",
    "    # exir_ops.edge.aten.add.Tensor,\n",
    "    exir_ops.edge.aten.clamp.default,\n",
    "    # exir_ops.edge.aten.sub.Tensor,\n",
    "    exir_ops.edge.aten.floor.default,\n",
    "    exir_ops.edge.aten.maximum.default,\n",
    "    exir_ops.edge.aten.minimum.default,\n",
    "    # exir_ops.edge.aten.mul.Tensor,\n",
    "    exir_ops.edge.aten.constant_pad_nd.default,\n",
    "    exir_ops.edge.aten.upsample_bilinear2d.default,\n",
    "    exir_ops.edge.aten.mean.dim,\n",
    "    exir_ops.edge.aten.max.dim,\n",
    "    exir_ops.edge.aten.max_pool2d_with_indices.default,\n",
    "    exir_ops.edge.aten.hardtanh.default,\n",
    "    exir_ops.edge.aten.sqrt.default,\n",
    "    exir_ops.edge.aten.ceil.default,\n",
    "    exir_ops.edge.aten.hardswish.default,\n",
    "    exir_ops.edge.aten.neg.default,\n",
    "    exir_ops.edge.aten.pow.Tensor_Scalar,\n",
    "    exir_ops.edge.aten.abs.default,\n",
    "    exir_ops.edge.aten._prelu_kernel.default,\n",
    "    exir_ops.edge.aten.slice_copy.Tensor,\n",
    "    exir_ops.edge.aten.relu.default,\n",
    "    exir_ops.edge.aten.hardtanh.default,\n",
    "    # exir_ops.edge.aten.permute_copy.default,\n",
    "    # exir_ops.edge.aten.sigmoid.default,\n",
    "    # exir_ops.edge.aten._softmax.default,\n",
    "    exir_ops.edge.aten.cat.default,\n",
    "    exir_ops.edge.aten.elu.default,\n",
    "    exir_ops.edge.aten.avg_pool2d.default,\n",
    "    exir_ops.edge.aten.leaky_relu.default,\n",
    "    exir_ops.edge.aten.addmm.default,  # TODO(T163877189) add constraint for addmm\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-07-11 17:36:13,832 xnnpack_partitioner.py:920] Found 94 subgraphs to be partitioned.\n",
      "[INFO 2024-07-11 17:36:40,327 xnnpack_partitioner.py:560] Found 225 subgraphs to be partitioned.\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/emit/_emitter.py:1480: UserWarning: Mutation on a buffer in the model is detected. ExecuTorch assumes buffers that are mutated in the graph have a meaningless initial state, only the shape and dtype will be serialized.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import (\n",
    "        XnnpackDynamicallyQuantizedPartitioner,\n",
    "        XnnpackPartitioner,\n",
    "    )\n",
    "\n",
    "executorch_program = edge_ep.to_backend({\n",
    "    \"image_encoder\": XnnpackPartitioner(\n",
    "        has_dynamic_shapes=True, \n",
    "        supported_ops=SUPPORTED_OPS,\n",
    "        supported_modules=[],\n",
    "        supported_quant_ops=[],\n",
    "    ),\n",
    "    \"text_model\": XnnpackDynamicallyQuantizedPartitioner(),\n",
    "}).to_executorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7075,  0.1415, -0.4763,  ...,  2.1267,  3.0089,  1.9180],\n",
       "         [-9.4110, -5.9685, -1.6051,  ..., -7.2729, -8.0051, -8.1549],\n",
       "         [-6.2976, -8.6725,  7.8711,  ..., -4.0501, -2.9125, -3.2148],\n",
       "         ...,\n",
       "         [-6.9906, -3.1924,  8.7544,  ..., -2.3177, -4.3984, -3.4881],\n",
       "         [-3.4243, -2.6517,  7.4019,  ..., -0.1667, -0.2504,  1.2978],\n",
       "         [-1.5804, -2.4602,  9.7699,  ...,  0.9635,  1.8530,  2.1722]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llava.text_model(embeddings, torch.tensor([0], dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "text_model_ep.module()(embeddings, torch.tensor([0], dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "  %p_llava_vision_tower_vision_tower_vision_model_embeddings_class_embedding : [num_users=1] = placeholder[target=p_llava_vision_tower_vision_tower_vision_model_embeddings_class_embedding]\n",
      "  %p_llava_vision_tower_vision_tower_vision_model_embeddings_patch_embedding_weight : [num_users=1] = placeholder[target=p_llava_vision_tower_vision_tower_vision_model_embeddings_patch_embedding_weight]\n",
      "  %p_llava_vision_tower_vision_tower_vision_model_embeddings_position_embedding_weight : [num_users=1] = placeholder[target=p_llava_vision_tower_vision_tower_vision_model_embeddings_position_embedding_weight]\n",
      "  %p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_weight : [num_users=1] = placeholder[target=p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_weight]\n",
      "  %p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_bias : [num_users=1] = placeholder[target=p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_bias]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_weight]\n",
      "  %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_bias]\n",
      "  %p_getattr_l__self___llava_mm_projector___0___weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_mm_projector___0___weight]\n",
      "  %p_getattr_l__self___llava_mm_projector___2___weight : [num_users=1] = placeholder[target=p_getattr_l__self___llava_mm_projector___2___weight]\n",
      "  %b_llava_vision_tower_vision_tower_vision_model_embeddings_position_ids : [num_users=1] = placeholder[target=b_llava_vision_tower_vision_tower_vision_model_embeddings_position_ids]\n",
      "  %b_lifted_tensor_0 : [num_users=1] = placeholder[target=b_lifted_tensor_0]\n",
      "  %b_lifted_tensor_1 : [num_users=1] = placeholder[target=b_lifted_tensor_1]\n",
      "  %b_lifted_tensor_2 : [num_users=1] = placeholder[target=b_lifted_tensor_2]\n",
      "  %_lifted_tensor_constant4 : [num_users=1] = placeholder[target=_lifted_tensor_constant4]\n",
      "  %_lifted_tensor_constant5 : [num_users=1] = placeholder[target=_lifted_tensor_constant5]\n",
      "  %_lifted_tensor_constant6 : [num_users=1] = placeholder[target=_lifted_tensor_constant6]\n",
      "  %_lifted_tensor_constant7 : [num_users=1] = placeholder[target=_lifted_tensor_constant7]\n",
      "  %_lifted_tensor_constant8 : [num_users=1] = placeholder[target=_lifted_tensor_constant8]\n",
      "  %_lifted_tensor_constant9 : [num_users=1] = placeholder[target=_lifted_tensor_constant9]\n",
      "  %_lifted_tensor_constant10 : [num_users=1] = placeholder[target=_lifted_tensor_constant10]\n",
      "  %_lifted_tensor_constant11 : [num_users=1] = placeholder[target=_lifted_tensor_constant11]\n",
      "  %_lifted_tensor_constant12 : [num_users=1] = placeholder[target=_lifted_tensor_constant12]\n",
      "  %_lifted_tensor_constant13 : [num_users=1] = placeholder[target=_lifted_tensor_constant13]\n",
      "  %_lifted_tensor_constant14 : [num_users=1] = placeholder[target=_lifted_tensor_constant14]\n",
      "  %_lifted_tensor_constant15 : [num_users=1] = placeholder[target=_lifted_tensor_constant15]\n",
      "  %_lifted_tensor_constant16 : [num_users=1] = placeholder[target=_lifted_tensor_constant16]\n",
      "  %_lifted_tensor_constant17 : [num_users=1] = placeholder[target=_lifted_tensor_constant17]\n",
      "  %_lifted_tensor_constant18 : [num_users=1] = placeholder[target=_lifted_tensor_constant18]\n",
      "  %_lifted_tensor_constant19 : [num_users=1] = placeholder[target=_lifted_tensor_constant19]\n",
      "  %_lifted_tensor_constant20 : [num_users=1] = placeholder[target=_lifted_tensor_constant20]\n",
      "  %_lifted_tensor_constant21 : [num_users=1] = placeholder[target=_lifted_tensor_constant21]\n",
      "  %_lifted_tensor_constant22 : [num_users=1] = placeholder[target=_lifted_tensor_constant22]\n",
      "  %_lifted_tensor_constant23 : [num_users=1] = placeholder[target=_lifted_tensor_constant23]\n",
      "  %_lifted_tensor_constant24 : [num_users=1] = placeholder[target=_lifted_tensor_constant24]\n",
      "  %_lifted_tensor_constant25 : [num_users=1] = placeholder[target=_lifted_tensor_constant25]\n",
      "  %_lifted_tensor_constant26 : [num_users=1] = placeholder[target=_lifted_tensor_constant26]\n",
      "  %_lifted_tensor_constant27 : [num_users=1] = placeholder[target=_lifted_tensor_constant27]\n",
      "  %_lifted_tensor_constant28 : [num_users=1] = placeholder[target=_lifted_tensor_constant28]\n",
      "  %_lifted_tensor_constant29 : [num_users=1] = placeholder[target=_lifted_tensor_constant29]\n",
      "  %_lifted_tensor_constant30 : [num_users=1] = placeholder[target=_lifted_tensor_constant30]\n",
      "  %_lifted_tensor_constant31 : [num_users=1] = placeholder[target=_lifted_tensor_constant31]\n",
      "  %_lifted_tensor_constant32 : [num_users=1] = placeholder[target=_lifted_tensor_constant32]\n",
      "  %_lifted_tensor_constant33 : [num_users=1] = placeholder[target=_lifted_tensor_constant33]\n",
      "  %_lifted_tensor_constant34 : [num_users=1] = placeholder[target=_lifted_tensor_constant34]\n",
      "  %_lifted_tensor_constant35 : [num_users=1] = placeholder[target=_lifted_tensor_constant35]\n",
      "  %_lifted_tensor_constant36 : [num_users=1] = placeholder[target=_lifted_tensor_constant36]\n",
      "  %_lifted_tensor_constant37 : [num_users=1] = placeholder[target=_lifted_tensor_constant37]\n",
      "  %_lifted_tensor_constant38 : [num_users=1] = placeholder[target=_lifted_tensor_constant38]\n",
      "  %_lifted_tensor_constant39 : [num_users=1] = placeholder[target=_lifted_tensor_constant39]\n",
      "  %_lifted_tensor_constant40 : [num_users=1] = placeholder[target=_lifted_tensor_constant40]\n",
      "  %_lifted_tensor_constant41 : [num_users=1] = placeholder[target=_lifted_tensor_constant41]\n",
      "  %_lifted_tensor_constant42 : [num_users=1] = placeholder[target=_lifted_tensor_constant42]\n",
      "  %_lifted_tensor_constant43 : [num_users=1] = placeholder[target=_lifted_tensor_constant43]\n",
      "  %_lifted_tensor_constant44 : [num_users=1] = placeholder[target=_lifted_tensor_constant44]\n",
      "  %_lifted_tensor_constant45 : [num_users=1] = placeholder[target=_lifted_tensor_constant45]\n",
      "  %_lifted_tensor_constant46 : [num_users=1] = placeholder[target=_lifted_tensor_constant46]\n",
      "  %_lifted_tensor_constant47 : [num_users=1] = placeholder[target=_lifted_tensor_constant47]\n",
      "  %_lifted_tensor_constant48 : [num_users=1] = placeholder[target=_lifted_tensor_constant48]\n",
      "  %_lifted_tensor_constant49 : [num_users=1] = placeholder[target=_lifted_tensor_constant49]\n",
      "  %_lifted_tensor_constant50 : [num_users=1] = placeholder[target=_lifted_tensor_constant50]\n",
      "  %image : [num_users=3] = placeholder[target=image]\n",
      "  %alloc : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_expand_copy_default : [num_users=1] = call_function[target=torch.ops.aten.expand_copy.out](args = (%p_llava_vision_tower_vision_tower_vision_model_embeddings_class_embedding, [1, 1, -1]), kwargs = {out: %alloc})\n",
      "  %alloc_1 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_1})\n",
      "  %alloc_2 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_1 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_2})\n",
      "  %alloc_3 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_2 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_3})\n",
      "  %alloc_4 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_3 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_4})\n",
      "  %alloc_5 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_4 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_5})\n",
      "  %alloc_6 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_5 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_6})\n",
      "  %alloc_7 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_6 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_7})\n",
      "  %alloc_8 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_7 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_8})\n",
      "  %alloc_9 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_8 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_9})\n",
      "  %alloc_10 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_9 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_10})\n",
      "  %alloc_11 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_10 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_11})\n",
      "  %alloc_12 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_11 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_12})\n",
      "  %alloc_13 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_12 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_13})\n",
      "  %alloc_14 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_13 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_14})\n",
      "  %alloc_15 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_14 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_15})\n",
      "  %alloc_16 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_15 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_16})\n",
      "  %alloc_17 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_16 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_17})\n",
      "  %alloc_18 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_17 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_18})\n",
      "  %alloc_19 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_18 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_19})\n",
      "  %alloc_20 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_19 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_20})\n",
      "  %alloc_21 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_20 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_21})\n",
      "  %alloc_22 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_21 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_22})\n",
      "  %alloc_23 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_22 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_23})\n",
      "  %alloc_24 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_23 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_24})\n",
      "  %alloc_25 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_24 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_25})\n",
      "  %alloc_26 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_25 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_26})\n",
      "  %alloc_27 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_26 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_27})\n",
      "  %alloc_28 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_27 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_28})\n",
      "  %alloc_29 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_28 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_29})\n",
      "  %alloc_30 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_29 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_30})\n",
      "  %alloc_31 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_30 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_31})\n",
      "  %alloc_32 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_31 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_32})\n",
      "  %alloc_33 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_32 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_33})\n",
      "  %alloc_34 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_33 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_34})\n",
      "  %alloc_35 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_34 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_35})\n",
      "  %alloc_36 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_35 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_36})\n",
      "  %alloc_37 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_36 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_37})\n",
      "  %alloc_38 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_37 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_38})\n",
      "  %alloc_39 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_38 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_39})\n",
      "  %alloc_40 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_39 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_40})\n",
      "  %alloc_41 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_40 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_41})\n",
      "  %alloc_42 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_41 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_42})\n",
      "  %alloc_43 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_42 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_43})\n",
      "  %alloc_44 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_43 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_44})\n",
      "  %alloc_45 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_44 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_45})\n",
      "  %alloc_46 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_45 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_46})\n",
      "  %alloc_47 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_46 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_47})\n",
      "  %alloc_48 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_47 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_48})\n",
      "  %alloc_49 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_48 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_49})\n",
      "  %alloc_50 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_49 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_50})\n",
      "  %alloc_51 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_50 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_51})\n",
      "  %alloc_52 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_51 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_52})\n",
      "  %alloc_53 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_52 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_53})\n",
      "  %alloc_54 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_53 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_54})\n",
      "  %alloc_55 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_54 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_55})\n",
      "  %alloc_56 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_55 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_56})\n",
      "  %alloc_57 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_56 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_57})\n",
      "  %alloc_58 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_57 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_58})\n",
      "  %alloc_59 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_58 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_59})\n",
      "  %alloc_60 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_59 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_60})\n",
      "  %alloc_61 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_60 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_61})\n",
      "  %alloc_62 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_61 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_62})\n",
      "  %alloc_63 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_62 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_63})\n",
      "  %alloc_64 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_63 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_64})\n",
      "  %alloc_65 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_64 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_65})\n",
      "  %alloc_66 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_65 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_66})\n",
      "  %alloc_67 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_66 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_67})\n",
      "  %alloc_68 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_67 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_68})\n",
      "  %alloc_69 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_68 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_69})\n",
      "  %alloc_70 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_69 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_70})\n",
      "  %alloc_71 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_70 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_71})\n",
      "  %alloc_72 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_71 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_72})\n",
      "  %alloc_73 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_72 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_73})\n",
      "  %alloc_74 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_73 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_74})\n",
      "  %alloc_75 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_74 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_75})\n",
      "  %alloc_76 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_75 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_76})\n",
      "  %alloc_77 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_76 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_77})\n",
      "  %alloc_78 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_77 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_78})\n",
      "  %alloc_79 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_78 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_79})\n",
      "  %alloc_80 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_79 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_80})\n",
      "  %alloc_81 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_80 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_81})\n",
      "  %alloc_82 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_81 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_82})\n",
      "  %alloc_83 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_82 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_83})\n",
      "  %alloc_84 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_83 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_84})\n",
      "  %alloc_85 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_84 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_85})\n",
      "  %alloc_86 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_85 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_86})\n",
      "  %alloc_87 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_86 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_87})\n",
      "  %alloc_88 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_87 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_88})\n",
      "  %alloc_89 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_88 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_89})\n",
      "  %alloc_90 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_89 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_90})\n",
      "  %alloc_91 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_90 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_91})\n",
      "  %alloc_92 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_91 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_92})\n",
      "  %alloc_93 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_92 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_93})\n",
      "  %alloc_94 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_93 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_94})\n",
      "  %alloc_95 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_94 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_95})\n",
      "  %alloc_96 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_95 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_96})\n",
      "  %alloc_97 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_96 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_97})\n",
      "  %alloc_98 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_97 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_98})\n",
      "  %alloc_99 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_98 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_99})\n",
      "  %alloc_100 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_99 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_100})\n",
      "  %alloc_101 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_100 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_101})\n",
      "  %alloc_102 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_101 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_102})\n",
      "  %alloc_103 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_102 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_103})\n",
      "  %alloc_104 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_103 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_104})\n",
      "  %alloc_105 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_104 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_105})\n",
      "  %alloc_106 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_105 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_106})\n",
      "  %alloc_107 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_106 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_107})\n",
      "  %alloc_108 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_107 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_108})\n",
      "  %alloc_109 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_108 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_109})\n",
      "  %alloc_110 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_109 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_110})\n",
      "  %alloc_111 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_110 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_111})\n",
      "  %alloc_112 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_111 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_112})\n",
      "  %alloc_113 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_112 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_113})\n",
      "  %alloc_114 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_113 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_114})\n",
      "  %alloc_115 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_114 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_115})\n",
      "  %alloc_116 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_115 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_116})\n",
      "  %alloc_117 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_116 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_117})\n",
      "  %alloc_118 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_117 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_118})\n",
      "  %alloc_119 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_118 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_119})\n",
      "  %alloc_120 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_119 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_120})\n",
      "  %alloc_121 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_120 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_121})\n",
      "  %alloc_122 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_121 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_122})\n",
      "  %alloc_123 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_122 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_123})\n",
      "  %alloc_124 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_123 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_124})\n",
      "  %alloc_125 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_124 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_125})\n",
      "  %alloc_126 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_125 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_126})\n",
      "  %alloc_127 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_126 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_127})\n",
      "  %alloc_128 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_127 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_128})\n",
      "  %alloc_129 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_128 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_129})\n",
      "  %alloc_130 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_129 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_130})\n",
      "  %alloc_131 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_130 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_131})\n",
      "  %alloc_132 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_131 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_132})\n",
      "  %alloc_133 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_132 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_weight, [1, 0]), kwargs = {out: %alloc_133})\n",
      "  %alloc_134 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_133 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_weight, [1, 0]), kwargs = {out: %alloc_134})\n",
      "  %alloc_135 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_134 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_weight, [1, 0]), kwargs = {out: %alloc_135})\n",
      "  %alloc_136 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_135 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_weight, [1, 0]), kwargs = {out: %alloc_136})\n",
      "  %alloc_137 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_136 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_weight, [1, 0]), kwargs = {out: %alloc_137})\n",
      "  %alloc_138 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_137 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_weight, [1, 0]), kwargs = {out: %alloc_138})\n",
      "  %alloc_139 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1024, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_138 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_mm_projector___0___weight, [1, 0]), kwargs = {out: %alloc_139})\n",
      "  %alloc_140 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((4096, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_139 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%p_getattr_l__self___llava_mm_projector___2___weight, [1, 0]), kwargs = {out: %alloc_140})\n",
      "  %alloc_141 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 577, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_embedding_default : [num_users=1] = call_function[target=torch.ops.aten.embedding.out](args = (%p_llava_vision_tower_vision_tower_vision_model_embeddings_position_embedding_weight, %b_llava_vision_tower_vision_tower_vision_model_embeddings_position_ids), kwargs = {out: %alloc_141})\n",
      "  %alloc_142 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3,), torch.int64),), kwargs = {})\n",
      "  %aten_clone_default : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%b_lifted_tensor_0,), kwargs = {out: %alloc_142})\n",
      "  %alloc_143 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3,), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_1 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%b_lifted_tensor_1,), kwargs = {out: %alloc_143})\n",
      "  %alloc_144 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3,), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_2 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%b_lifted_tensor_2,), kwargs = {out: %alloc_144})\n",
      "  %sym_size : [num_users=1] = call_function[target=torch.ops.aten.sym_size.int](args = (%image, 1), kwargs = {})\n",
      "  %sym_size_1 : [num_users=1] = call_function[target=torch.ops.aten.sym_size.int](args = (%image, 2), kwargs = {})\n",
      "  %alloc_145 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3,), torch.int64),), kwargs = {})\n",
      "  %aten_alias_copy_default : [num_users=1] = call_function[target=torch.ops.aten.alias_copy.out](args = (%aten_clone_default,), kwargs = {out: %alloc_145})\n",
      "  %aten_view_copy_default : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_1, [-1, 1, 1]), kwargs = {})\n",
      "  %aten_view_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_2, [-1, 1, 1]), kwargs = {})\n",
      "  %aten_view_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%image, [1, 3, %sym_size, %sym_size_1]), kwargs = {})\n",
      "  %alloc_146 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3,), torch.int64),), kwargs = {})\n",
      "  %aten_alias_copy_default_1 : [num_users=1] = call_function[target=torch.ops.aten.alias_copy.out](args = (%aten_alias_copy_default,), kwargs = {out: %alloc_146})\n",
      "  %alloc_147 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 3, s0 + 112, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_constant_pad_nd_default : [num_users=4] = call_function[target=torch.ops.aten.constant_pad_nd.out](args = (%aten_view_copy_default_2, [0, 0, 56, 56], 0.0), kwargs = {out: %alloc_147})\n",
      "  %alloc_148 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3,), torch.int64),), kwargs = {})\n",
      "  %aten_alias_copy_default_2 : [num_users=1] = call_function[target=torch.ops.aten.alias_copy.out](args = (%aten_alias_copy_default_1,), kwargs = {out: %alloc_148})\n",
      "  %sym_size_2 : [num_users=5] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_constant_pad_nd_default, 2), kwargs = {})\n",
      "  %sym_size_3 : [num_users=5] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_constant_pad_nd_default, 3), kwargs = {})\n",
      "  %alloc_149 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3,), torch.uint8),), kwargs = {})\n",
      "  %aten__to_copy_default : [num_users=2] = call_function[target=torch.ops.aten._to_copy.out](args = (%aten_alias_copy_default_2,), kwargs = {out: %alloc_149})\n",
      "  %aten_view_copy_default_3 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%aten_constant_pad_nd_default, [3, %sym_size_2, %sym_size_3]), kwargs = {})\n",
      "  %aten_view_copy_default_4 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%aten_constant_pad_nd_default, [3, %sym_size_2, %sym_size_3]), kwargs = {})\n",
      "  %alloc_150 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_copy_tensor : [num_users=1] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_view_copy_default_3, 1, 0, 56), kwargs = {out: %alloc_150})\n",
      "  %alloc_151 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_view_copy_default_3, 1, -56, 9223372036854775807), kwargs = {out: %alloc_151})\n",
      "  %alloc_152 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_2 : [num_users=1] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_view_copy_default_4, 1, 0, 56), kwargs = {out: %alloc_152})\n",
      "  %aten_view_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten__to_copy_default, [3, 1, 1]), kwargs = {})\n",
      "  %aten_view_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten__to_copy_default, [3, 1, 1]), kwargs = {})\n",
      "  %alloc_153 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_3 : [num_users=2] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_slice_copy_tensor, 2, 0, 9223372036854775807), kwargs = {out: %alloc_153})\n",
      "  %alloc_154 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_4 : [num_users=1] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_slice_copy_tensor_1, 2, 0, 9223372036854775807), kwargs = {out: %alloc_154})\n",
      "  %sym_size_4 : [num_users=1] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_slice_copy_tensor_3, 2), kwargs = {})\n",
      "  %sym_size_5 : [num_users=1] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_slice_copy_tensor_4, 2), kwargs = {})\n",
      "  %alloc_155 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_expand_copy_default_1 : [num_users=1] = call_function[target=torch.ops.aten.expand_copy.out](args = (%aten_view_copy_default_6, [3, 56, %sym_size_4]), kwargs = {out: %alloc_155})\n",
      "  %alloc_156 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_expand_copy_default_2 : [num_users=1] = call_function[target=torch.ops.aten.expand_copy.out](args = (%aten_view_copy_default_7, [3, 56, %sym_size_5]), kwargs = {out: %alloc_156})\n",
      "  %alloc_157 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_copy_default : [num_users=1] = call_function[target=torch.ops.aten.copy.out](args = (%aten_slice_copy_tensor_3, %aten_expand_copy_default_1), kwargs = {out: %alloc_157})\n",
      "  %alloc_158 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%aten_slice_copy_tensor_2, %aten_copy_default, 2, 0, 9223372036854775807), kwargs = {out: %alloc_158})\n",
      "  %alloc_159 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, s0 + 112, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_scatter_default_1 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%aten_view_copy_default_4, %aten_slice_scatter_default, 1, 0, 56), kwargs = {out: %alloc_159})\n",
      "  %aten_view_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_slice_scatter_default_1, [3, %sym_size_2, %sym_size_3]), kwargs = {})\n",
      "  %aten_view_copy_default_10 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%aten_slice_scatter_default_1, [3, %sym_size_2, %sym_size_3]), kwargs = {})\n",
      "  %alloc_160 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_view_copy_default_9, 1, -56, 9223372036854775807), kwargs = {out: %alloc_160})\n",
      "  %alloc_161 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_6 : [num_users=1] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_view_copy_default_10, 1, -56, 9223372036854775807), kwargs = {out: %alloc_161})\n",
      "  %alloc_162 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_7 : [num_users=1] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_slice_copy_tensor_5, 2, 0, 9223372036854775807), kwargs = {out: %alloc_162})\n",
      "  %alloc_163 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_copy_default_1 : [num_users=1] = call_function[target=torch.ops.aten.copy.out](args = (%aten_slice_copy_tensor_7, %aten_expand_copy_default_2), kwargs = {out: %alloc_163})\n",
      "  %alloc_164 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, 56, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_scatter_default_2 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%aten_slice_copy_tensor_6, %aten_copy_default_1, 2, 0, 9223372036854775807), kwargs = {out: %alloc_164})\n",
      "  %alloc_165 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, s0 + 112, s1), torch.uint8),), kwargs = {})\n",
      "  %aten_slice_scatter_default_3 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%aten_view_copy_default_10, %aten_slice_scatter_default_2, 1, -56, 9223372036854775807), kwargs = {out: %alloc_165})\n",
      "  %aten_view_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_slice_scatter_default_3, [3, %sym_size_2, %sym_size_3]), kwargs = {})\n",
      "  %alloc_166 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, s0 + 112, s1), torch.float32),), kwargs = {})\n",
      "  %aten__to_copy_default_1 : [num_users=1] = call_function[target=torch.ops.aten._to_copy.out](args = (%aten_view_copy_default_12,), kwargs = {out: %alloc_166})\n",
      "  %alloc_167 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, s0 + 112, s1), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten__to_copy_default_1, %_lifted_tensor_constant4), kwargs = {out: %alloc_167})\n",
      "  %alloc_168 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, s0 + 112, s1), torch.float32),), kwargs = {})\n",
      "  %aten_sub_tensor : [num_users=1] = call_function[target=torch.ops.aten.sub.out](args = (%aten_mul_tensor, %aten_view_copy_default), kwargs = {out: %alloc_168})\n",
      "  %alloc_169 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((3, s0 + 112, s1), torch.float32),), kwargs = {})\n",
      "  %aten_div_tensor : [num_users=1] = call_function[target=torch.ops.aten.div.out](args = (%aten_sub_tensor, %aten_view_copy_default_1), kwargs = {out: %alloc_169})\n",
      "  %alloc_170 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 3, s0 + 112, s1), torch.float32),), kwargs = {})\n",
      "  %aten_unsqueeze_copy_default : [num_users=1] = call_function[target=torch.ops.aten.unsqueeze_copy.out](args = (%aten_div_tensor, 0), kwargs = {out: %alloc_170})\n",
      "  %alloc_171 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 1024, (s0//14) + 8, (s1//14)), torch.float32),), kwargs = {})\n",
      "  %aten_convolution_default : [num_users=3] = call_function[target=torch.ops.aten.convolution.out](args = (%aten_unsqueeze_copy_default, %p_llava_vision_tower_vision_tower_vision_model_embeddings_patch_embedding_weight, None, [14, 14], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {out: %alloc_171})\n",
      "  %sym_size_6 : [num_users=1] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_convolution_default, 2), kwargs = {})\n",
      "  %sym_size_7 : [num_users=1] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_convolution_default, 3), kwargs = {})\n",
      "  %mul : [num_users=1] = call_function[target=executorch.exir.dialects.backend._ops.executorch_prim.mul.Scalar](args = (%sym_size_6, %sym_size_7), kwargs = {})\n",
      "  %aten_view_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_convolution_default, [1, 1024, %mul]), kwargs = {})\n",
      "  %alloc_172 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)), 1024), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_140 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_13, [0, 2, 1]), kwargs = {out: %alloc_172})\n",
      "  %alloc_173 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_cat_default : [num_users=2] = call_function[target=torch.ops.aten.cat.out](args = ([%aten_expand_copy_default, %aten_permute_copy_default_140], 1), kwargs = {out: %alloc_173})\n",
      "  %alloc_174 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor : [num_users=1] = call_function[target=torch.ops.aten.add.out](args = (%aten_cat_default, %aten_embedding_default), kwargs = {out: %alloc_174})\n",
      "  %sym_size_8 : [num_users=184] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_cat_default, 1), kwargs = {})\n",
      "  %alloc_175 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_176 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_177 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor, [1024], %p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_weight, %p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_bias, 1e-05), kwargs = {out0: %alloc_175, out1: %alloc_176, out2: %alloc_177})\n",
      "  %getitem : [num_users=2] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default, 0), kwargs = {})\n",
      "  %alloc_178 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_179 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_180 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_1 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%getitem, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_178, out1: %alloc_179, out2: %alloc_180})\n",
      "  %getitem_1 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_1, 0), kwargs = {})\n",
      "  %aten_view_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_1, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_1, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_1, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_0 : [num_users=1] = get_attr[target=lowered_module_0]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_16 : [num_users=1] = placeholder[target=aten_view_copy_default_16]\n",
      "      %aten_permute_copy_default_2 : [num_users=1] = placeholder[target=aten_permute_copy_default_2]\n",
      "      %aten_view_copy_default_19 : [num_users=1] = placeholder[target=aten_view_copy_default_19]\n",
      "      %aten_permute_copy_default_4 : [num_users=1] = placeholder[target=aten_permute_copy_default_4]\n",
      "      %aten_view_copy_default_14 : [num_users=1] = placeholder[target=aten_view_copy_default_14]\n",
      "      %aten_permute_copy_default_1 : [num_users=1] = placeholder[target=aten_permute_copy_default_1]\n",
      "      %aten_addmm_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_bias, %aten_view_copy_default_16, %aten_permute_copy_default_2), kwargs = {})\n",
      "      %aten_addmm_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_bias, %aten_view_copy_default_19, %aten_permute_copy_default_4), kwargs = {})\n",
      "      %aten_addmm_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_bias, %aten_view_copy_default_14, %aten_permute_copy_default_1), kwargs = {})\n",
      "      return (aten_addmm_default_1, aten_addmm_default_2, aten_addmm_default)\n",
      "  %executorch_call_delegate : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_0, %aten_view_copy_default_15, %aten_permute_copy_default, %aten_view_copy_default_16, %aten_permute_copy_default_1, %aten_view_copy_default_14, %aten_permute_copy_default_2), kwargs = {})\n",
      "  %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 0), kwargs = {})\n",
      "  %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 1), kwargs = {})\n",
      "  %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 2), kwargs = {})\n",
      "  %aten_view_copy_default_19 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_4, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_2, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_3, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_181 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_19, %_lifted_tensor_constant5), kwargs = {out: %alloc_181})\n",
      "  %sym_size_9 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_19, 1), kwargs = {})\n",
      "  %alloc_182 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_141 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_20, [0, 2, 1, 3]), kwargs = {out: %alloc_182})\n",
      "  %alloc_183 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_142 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_21, [0, 2, 1, 3]), kwargs = {out: %alloc_183})\n",
      "  %aten_view_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_1, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_184 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_3 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_141,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_184})\n",
      "  %alloc_185 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_4 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_142,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_185})\n",
      "  %alloc_186 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_143 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_22, [0, 2, 1, 3]), kwargs = {out: %alloc_186})\n",
      "  %aten_view_copy_default_23 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_3, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_24 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_4, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_187 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_5 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_143,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_187})\n",
      "  %alloc_188 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_144 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_23, [0, 2, 1]), kwargs = {out: %alloc_188})\n",
      "  %aten_view_copy_default_25 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_5, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_189 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_25, %aten_permute_copy_default_144), kwargs = {out: %alloc_189})\n",
      "  %alloc_190 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default, -1, False), kwargs = {out: %alloc_190})\n",
      "  %alloc_191 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_6 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default,), kwargs = {out: %alloc_191})\n",
      "  %alloc_192 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_1 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_6, %aten_view_copy_default_24), kwargs = {out: %alloc_192})\n",
      "  %aten_view_copy_default_26 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_1, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_193 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_145 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_26, [0, 2, 1, 3]), kwargs = {out: %alloc_193})\n",
      "  %alloc_194 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_7 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_145,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_194})\n",
      "  %aten_view_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_7, [%sym_size_9, 1024]), kwargs = {})\n",
      "  %lowered_module_1 : [num_users=1] = get_attr[target=lowered_module_1]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_28 : [num_users=1] = placeholder[target=aten_view_copy_default_28]\n",
      "      %aten_permute_copy_default_9 : [num_users=1] = placeholder[target=aten_permute_copy_default_9]\n",
      "      %aten_addmm_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_bias, %aten_view_copy_default_28, %aten_permute_copy_default_9), kwargs = {})\n",
      "      return (aten_addmm_default_3,)\n",
      "  %executorch_call_delegate_1 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_1, %aten_view_copy_default_28, %aten_permute_copy_default_3), kwargs = {})\n",
      "  %getitem_5 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 0), kwargs = {})\n",
      "  %aten_view_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_5, [1, %sym_size_9, 1024]), kwargs = {})\n",
      "  %alloc_195 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_1 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%getitem, %aten_view_copy_default_29), kwargs = {out: %alloc_195})\n",
      "  %alloc_196 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_197 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_198 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_2 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_1, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_196, out1: %alloc_197, out2: %alloc_198})\n",
      "  %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_2, 0), kwargs = {})\n",
      "  %aten_view_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_6, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_2 : [num_users=1] = get_attr[target=lowered_module_2]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_30 : [num_users=1] = placeholder[target=aten_view_copy_default_30]\n",
      "      %aten_permute_copy_default_10 : [num_users=1] = placeholder[target=aten_permute_copy_default_10]\n",
      "      %aten_addmm_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_bias, %aten_view_copy_default_30, %aten_permute_copy_default_10), kwargs = {})\n",
      "      return (aten_addmm_default_4,)\n",
      "  %executorch_call_delegate_2 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_2, %aten_view_copy_default_30, %aten_permute_copy_default_4), kwargs = {})\n",
      "  %getitem_7 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 0), kwargs = {})\n",
      "  %aten_view_copy_default_31 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_7, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_199 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_31, %_lifted_tensor_constant6), kwargs = {out: %alloc_199})\n",
      "  %sym_size_10 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_31, 1), kwargs = {})\n",
      "  %alloc_200 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_2,), kwargs = {out: %alloc_200})\n",
      "  %alloc_201 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_31, %aten_sigmoid_default), kwargs = {out: %alloc_201})\n",
      "  %aten_view_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_3, [%sym_size_10, 4096]), kwargs = {})\n",
      "  %lowered_module_3 : [num_users=1] = get_attr[target=lowered_module_3]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_32 : [num_users=1] = placeholder[target=aten_view_copy_default_32]\n",
      "      %aten_permute_copy_default_11 : [num_users=1] = placeholder[target=aten_permute_copy_default_11]\n",
      "      %aten_addmm_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_bias, %aten_view_copy_default_32, %aten_permute_copy_default_11), kwargs = {})\n",
      "      return (aten_addmm_default_5,)\n",
      "  %executorch_call_delegate_3 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_3, %aten_view_copy_default_32, %aten_permute_copy_default_5), kwargs = {})\n",
      "  %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 0), kwargs = {})\n",
      "  %aten_view_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_8, [1, %sym_size_10, 1024]), kwargs = {})\n",
      "  %alloc_202 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_2 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_1, %aten_view_copy_default_33), kwargs = {out: %alloc_202})\n",
      "  %alloc_203 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_204 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_205 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_3 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_2, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_203, out1: %alloc_204, out2: %alloc_205})\n",
      "  %getitem_9 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_3, 0), kwargs = {})\n",
      "  %aten_view_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_9, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_9, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_9, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_4 : [num_users=1] = get_attr[target=lowered_module_4]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_36 : [num_users=1] = placeholder[target=aten_view_copy_default_36]\n",
      "      %aten_permute_copy_default_13 : [num_users=1] = placeholder[target=aten_permute_copy_default_13]\n",
      "      %aten_view_copy_default_39 : [num_users=1] = placeholder[target=aten_view_copy_default_39]\n",
      "      %aten_permute_copy_default_15 : [num_users=1] = placeholder[target=aten_permute_copy_default_15]\n",
      "      %aten_view_copy_default_34 : [num_users=1] = placeholder[target=aten_view_copy_default_34]\n",
      "      %aten_permute_copy_default_12 : [num_users=1] = placeholder[target=aten_permute_copy_default_12]\n",
      "      %aten_addmm_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_bias, %aten_view_copy_default_36, %aten_permute_copy_default_13), kwargs = {})\n",
      "      %aten_addmm_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_bias, %aten_view_copy_default_39, %aten_permute_copy_default_15), kwargs = {})\n",
      "      %aten_addmm_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_bias, %aten_view_copy_default_34, %aten_permute_copy_default_12), kwargs = {})\n",
      "      return (aten_addmm_default_7, aten_addmm_default_8, aten_addmm_default_6)\n",
      "  %executorch_call_delegate_4 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_4, %aten_view_copy_default_35, %aten_permute_copy_default_6, %aten_view_copy_default_36, %aten_permute_copy_default_7, %aten_view_copy_default_34, %aten_permute_copy_default_8), kwargs = {})\n",
      "  %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 0), kwargs = {})\n",
      "  %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 1), kwargs = {})\n",
      "  %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 2), kwargs = {})\n",
      "  %aten_view_copy_default_39 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_12, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_10, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_11, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_206 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_4 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_39, %_lifted_tensor_constant7), kwargs = {out: %alloc_206})\n",
      "  %sym_size_11 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_39, 1), kwargs = {})\n",
      "  %alloc_207 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_146 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_40, [0, 2, 1, 3]), kwargs = {out: %alloc_207})\n",
      "  %alloc_208 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_147 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_41, [0, 2, 1, 3]), kwargs = {out: %alloc_208})\n",
      "  %aten_view_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_4, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_209 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_8 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_146,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_209})\n",
      "  %alloc_210 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_9 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_147,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_210})\n",
      "  %alloc_211 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_148 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_42, [0, 2, 1, 3]), kwargs = {out: %alloc_211})\n",
      "  %aten_view_copy_default_43 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_8, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_44 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_9, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_212 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_10 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_148,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_212})\n",
      "  %alloc_213 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_149 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_43, [0, 2, 1]), kwargs = {out: %alloc_213})\n",
      "  %aten_view_copy_default_45 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_10, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_214 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_2 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_45, %aten_permute_copy_default_149), kwargs = {out: %alloc_214})\n",
      "  %alloc_215 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_1 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_2, -1, False), kwargs = {out: %alloc_215})\n",
      "  %alloc_216 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_11 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_1,), kwargs = {out: %alloc_216})\n",
      "  %alloc_217 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_3 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_11, %aten_view_copy_default_44), kwargs = {out: %alloc_217})\n",
      "  %aten_view_copy_default_46 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_3, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_218 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_150 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_46, [0, 2, 1, 3]), kwargs = {out: %alloc_218})\n",
      "  %alloc_219 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_12 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_150,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_219})\n",
      "  %aten_view_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_12, [%sym_size_11, 1024]), kwargs = {})\n",
      "  %lowered_module_5 : [num_users=1] = get_attr[target=lowered_module_5]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_48 : [num_users=1] = placeholder[target=aten_view_copy_default_48]\n",
      "      %aten_permute_copy_default_20 : [num_users=1] = placeholder[target=aten_permute_copy_default_20]\n",
      "      %aten_addmm_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_bias, %aten_view_copy_default_48, %aten_permute_copy_default_20), kwargs = {})\n",
      "      return (aten_addmm_default_9,)\n",
      "  %executorch_call_delegate_5 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_5, %aten_view_copy_default_48, %aten_permute_copy_default_9), kwargs = {})\n",
      "  %getitem_13 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 0), kwargs = {})\n",
      "  %aten_view_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_13, [1, %sym_size_11, 1024]), kwargs = {})\n",
      "  %alloc_220 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_3 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_2, %aten_view_copy_default_49), kwargs = {out: %alloc_220})\n",
      "  %alloc_221 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_222 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_223 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_4 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_3, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_221, out1: %alloc_222, out2: %alloc_223})\n",
      "  %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_4, 0), kwargs = {})\n",
      "  %aten_view_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_14, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_6 : [num_users=1] = get_attr[target=lowered_module_6]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_50 : [num_users=1] = placeholder[target=aten_view_copy_default_50]\n",
      "      %aten_permute_copy_default_21 : [num_users=1] = placeholder[target=aten_permute_copy_default_21]\n",
      "      %aten_addmm_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_bias, %aten_view_copy_default_50, %aten_permute_copy_default_21), kwargs = {})\n",
      "      return (aten_addmm_default_10,)\n",
      "  %executorch_call_delegate_6 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_6, %aten_view_copy_default_50, %aten_permute_copy_default_10), kwargs = {})\n",
      "  %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 0), kwargs = {})\n",
      "  %aten_view_copy_default_51 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_15, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_224 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_5 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_51, %_lifted_tensor_constant8), kwargs = {out: %alloc_224})\n",
      "  %sym_size_12 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_51, 1), kwargs = {})\n",
      "  %alloc_225 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_1 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_5,), kwargs = {out: %alloc_225})\n",
      "  %alloc_226 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_6 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_51, %aten_sigmoid_default_1), kwargs = {out: %alloc_226})\n",
      "  %aten_view_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_6, [%sym_size_12, 4096]), kwargs = {})\n",
      "  %lowered_module_7 : [num_users=1] = get_attr[target=lowered_module_7]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_52 : [num_users=1] = placeholder[target=aten_view_copy_default_52]\n",
      "      %aten_permute_copy_default_22 : [num_users=1] = placeholder[target=aten_permute_copy_default_22]\n",
      "      %aten_addmm_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_bias, %aten_view_copy_default_52, %aten_permute_copy_default_22), kwargs = {})\n",
      "      return (aten_addmm_default_11,)\n",
      "  %executorch_call_delegate_7 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_7, %aten_view_copy_default_52, %aten_permute_copy_default_11), kwargs = {})\n",
      "  %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 0), kwargs = {})\n",
      "  %aten_view_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_16, [1, %sym_size_12, 1024]), kwargs = {})\n",
      "  %alloc_227 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_4 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_3, %aten_view_copy_default_53), kwargs = {out: %alloc_227})\n",
      "  %alloc_228 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_229 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_230 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_5 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_4, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_228, out1: %alloc_229, out2: %alloc_230})\n",
      "  %getitem_17 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_5, 0), kwargs = {})\n",
      "  %aten_view_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_17, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_17, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_17, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_8 : [num_users=1] = get_attr[target=lowered_module_8]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_56 : [num_users=1] = placeholder[target=aten_view_copy_default_56]\n",
      "      %aten_permute_copy_default_24 : [num_users=1] = placeholder[target=aten_permute_copy_default_24]\n",
      "      %aten_view_copy_default_59 : [num_users=1] = placeholder[target=aten_view_copy_default_59]\n",
      "      %aten_permute_copy_default_26 : [num_users=1] = placeholder[target=aten_permute_copy_default_26]\n",
      "      %aten_view_copy_default_54 : [num_users=1] = placeholder[target=aten_view_copy_default_54]\n",
      "      %aten_permute_copy_default_23 : [num_users=1] = placeholder[target=aten_permute_copy_default_23]\n",
      "      %aten_addmm_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_bias, %aten_view_copy_default_56, %aten_permute_copy_default_24), kwargs = {})\n",
      "      %aten_addmm_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_bias, %aten_view_copy_default_59, %aten_permute_copy_default_26), kwargs = {})\n",
      "      %aten_addmm_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_bias, %aten_view_copy_default_54, %aten_permute_copy_default_23), kwargs = {})\n",
      "      return (aten_addmm_default_13, aten_addmm_default_14, aten_addmm_default_12)\n",
      "  %executorch_call_delegate_8 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_8, %aten_view_copy_default_55, %aten_permute_copy_default_12, %aten_view_copy_default_56, %aten_permute_copy_default_13, %aten_view_copy_default_54, %aten_permute_copy_default_14), kwargs = {})\n",
      "  %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 0), kwargs = {})\n",
      "  %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 1), kwargs = {})\n",
      "  %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 2), kwargs = {})\n",
      "  %aten_view_copy_default_59 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_20, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_18, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_19, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_231 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_7 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_59, %_lifted_tensor_constant9), kwargs = {out: %alloc_231})\n",
      "  %sym_size_13 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_59, 1), kwargs = {})\n",
      "  %alloc_232 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_151 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_60, [0, 2, 1, 3]), kwargs = {out: %alloc_232})\n",
      "  %alloc_233 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_152 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_61, [0, 2, 1, 3]), kwargs = {out: %alloc_233})\n",
      "  %aten_view_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_7, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_234 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_13 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_151,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_234})\n",
      "  %alloc_235 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_14 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_152,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_235})\n",
      "  %alloc_236 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_153 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_62, [0, 2, 1, 3]), kwargs = {out: %alloc_236})\n",
      "  %aten_view_copy_default_63 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_13, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_64 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_14, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_237 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_15 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_153,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_237})\n",
      "  %alloc_238 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_154 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_63, [0, 2, 1]), kwargs = {out: %alloc_238})\n",
      "  %aten_view_copy_default_65 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_15, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_239 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_4 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_65, %aten_permute_copy_default_154), kwargs = {out: %alloc_239})\n",
      "  %alloc_240 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_2 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_4, -1, False), kwargs = {out: %alloc_240})\n",
      "  %alloc_241 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_16 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_2,), kwargs = {out: %alloc_241})\n",
      "  %alloc_242 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_5 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_16, %aten_view_copy_default_64), kwargs = {out: %alloc_242})\n",
      "  %aten_view_copy_default_66 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_5, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_243 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_155 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_66, [0, 2, 1, 3]), kwargs = {out: %alloc_243})\n",
      "  %alloc_244 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_17 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_155,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_244})\n",
      "  %aten_view_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_17, [%sym_size_13, 1024]), kwargs = {})\n",
      "  %lowered_module_9 : [num_users=1] = get_attr[target=lowered_module_9]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_68 : [num_users=1] = placeholder[target=aten_view_copy_default_68]\n",
      "      %aten_permute_copy_default_31 : [num_users=1] = placeholder[target=aten_permute_copy_default_31]\n",
      "      %aten_addmm_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_bias, %aten_view_copy_default_68, %aten_permute_copy_default_31), kwargs = {})\n",
      "      return (aten_addmm_default_15,)\n",
      "  %executorch_call_delegate_9 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_9, %aten_view_copy_default_68, %aten_permute_copy_default_15), kwargs = {})\n",
      "  %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 0), kwargs = {})\n",
      "  %aten_view_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_21, [1, %sym_size_13, 1024]), kwargs = {})\n",
      "  %alloc_245 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_5 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_4, %aten_view_copy_default_69), kwargs = {out: %alloc_245})\n",
      "  %alloc_246 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_247 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_248 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_6 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_5, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_246, out1: %alloc_247, out2: %alloc_248})\n",
      "  %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_6, 0), kwargs = {})\n",
      "  %aten_view_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_22, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_10 : [num_users=1] = get_attr[target=lowered_module_10]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_70 : [num_users=1] = placeholder[target=aten_view_copy_default_70]\n",
      "      %aten_permute_copy_default_32 : [num_users=1] = placeholder[target=aten_permute_copy_default_32]\n",
      "      %aten_addmm_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_bias, %aten_view_copy_default_70, %aten_permute_copy_default_32), kwargs = {})\n",
      "      return (aten_addmm_default_16,)\n",
      "  %executorch_call_delegate_10 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_10, %aten_view_copy_default_70, %aten_permute_copy_default_16), kwargs = {})\n",
      "  %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 0), kwargs = {})\n",
      "  %aten_view_copy_default_71 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_23, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_249 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_8 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_71, %_lifted_tensor_constant10), kwargs = {out: %alloc_249})\n",
      "  %sym_size_14 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_71, 1), kwargs = {})\n",
      "  %alloc_250 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_2 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_8,), kwargs = {out: %alloc_250})\n",
      "  %alloc_251 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_9 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_71, %aten_sigmoid_default_2), kwargs = {out: %alloc_251})\n",
      "  %aten_view_copy_default_72 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_9, [%sym_size_14, 4096]), kwargs = {})\n",
      "  %lowered_module_11 : [num_users=1] = get_attr[target=lowered_module_11]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_72 : [num_users=1] = placeholder[target=aten_view_copy_default_72]\n",
      "      %aten_permute_copy_default_33 : [num_users=1] = placeholder[target=aten_permute_copy_default_33]\n",
      "      %aten_addmm_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_bias, %aten_view_copy_default_72, %aten_permute_copy_default_33), kwargs = {})\n",
      "      return (aten_addmm_default_17,)\n",
      "  %executorch_call_delegate_11 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_11, %aten_view_copy_default_72, %aten_permute_copy_default_17), kwargs = {})\n",
      "  %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 0), kwargs = {})\n",
      "  %aten_view_copy_default_73 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_24, [1, %sym_size_14, 1024]), kwargs = {})\n",
      "  %alloc_252 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_6 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_5, %aten_view_copy_default_73), kwargs = {out: %alloc_252})\n",
      "  %alloc_253 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_254 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_255 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_7 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_6, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_253, out1: %alloc_254, out2: %alloc_255})\n",
      "  %getitem_25 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_7, 0), kwargs = {})\n",
      "  %aten_view_copy_default_74 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_25, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_75 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_25, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_76 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_25, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_12 : [num_users=1] = get_attr[target=lowered_module_12]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_76 : [num_users=1] = placeholder[target=aten_view_copy_default_76]\n",
      "      %aten_permute_copy_default_35 : [num_users=1] = placeholder[target=aten_permute_copy_default_35]\n",
      "      %aten_view_copy_default_79 : [num_users=1] = placeholder[target=aten_view_copy_default_79]\n",
      "      %aten_permute_copy_default_37 : [num_users=1] = placeholder[target=aten_permute_copy_default_37]\n",
      "      %aten_view_copy_default_74 : [num_users=1] = placeholder[target=aten_view_copy_default_74]\n",
      "      %aten_permute_copy_default_34 : [num_users=1] = placeholder[target=aten_permute_copy_default_34]\n",
      "      %aten_addmm_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_bias, %aten_view_copy_default_76, %aten_permute_copy_default_35), kwargs = {})\n",
      "      %aten_addmm_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_bias, %aten_view_copy_default_79, %aten_permute_copy_default_37), kwargs = {})\n",
      "      %aten_addmm_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_bias, %aten_view_copy_default_74, %aten_permute_copy_default_34), kwargs = {})\n",
      "      return (aten_addmm_default_19, aten_addmm_default_20, aten_addmm_default_18)\n",
      "  %executorch_call_delegate_12 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_12, %aten_view_copy_default_75, %aten_permute_copy_default_18, %aten_view_copy_default_76, %aten_permute_copy_default_19, %aten_view_copy_default_74, %aten_permute_copy_default_20), kwargs = {})\n",
      "  %getitem_26 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_12, 0), kwargs = {})\n",
      "  %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_12, 1), kwargs = {})\n",
      "  %getitem_28 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_12, 2), kwargs = {})\n",
      "  %aten_view_copy_default_79 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_28, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_80 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_26, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_81 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_27, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_256 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_10 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_79, %_lifted_tensor_constant11), kwargs = {out: %alloc_256})\n",
      "  %sym_size_15 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_79, 1), kwargs = {})\n",
      "  %alloc_257 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_156 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_80, [0, 2, 1, 3]), kwargs = {out: %alloc_257})\n",
      "  %alloc_258 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_157 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_81, [0, 2, 1, 3]), kwargs = {out: %alloc_258})\n",
      "  %aten_view_copy_default_82 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_10, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_259 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_18 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_156,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_259})\n",
      "  %alloc_260 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_19 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_157,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_260})\n",
      "  %alloc_261 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_158 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_82, [0, 2, 1, 3]), kwargs = {out: %alloc_261})\n",
      "  %aten_view_copy_default_83 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_18, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_84 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_19, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_262 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_20 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_158,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_262})\n",
      "  %alloc_263 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_159 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_83, [0, 2, 1]), kwargs = {out: %alloc_263})\n",
      "  %aten_view_copy_default_85 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_20, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_264 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_6 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_85, %aten_permute_copy_default_159), kwargs = {out: %alloc_264})\n",
      "  %alloc_265 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_3 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_6, -1, False), kwargs = {out: %alloc_265})\n",
      "  %alloc_266 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_21 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_3,), kwargs = {out: %alloc_266})\n",
      "  %alloc_267 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_7 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_21, %aten_view_copy_default_84), kwargs = {out: %alloc_267})\n",
      "  %aten_view_copy_default_86 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_7, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_268 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_160 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_86, [0, 2, 1, 3]), kwargs = {out: %alloc_268})\n",
      "  %alloc_269 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_22 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_160,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_269})\n",
      "  %aten_view_copy_default_88 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_22, [%sym_size_15, 1024]), kwargs = {})\n",
      "  %lowered_module_13 : [num_users=1] = get_attr[target=lowered_module_13]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_88 : [num_users=1] = placeholder[target=aten_view_copy_default_88]\n",
      "      %aten_permute_copy_default_42 : [num_users=1] = placeholder[target=aten_permute_copy_default_42]\n",
      "      %aten_addmm_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_bias, %aten_view_copy_default_88, %aten_permute_copy_default_42), kwargs = {})\n",
      "      return (aten_addmm_default_21,)\n",
      "  %executorch_call_delegate_13 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_13, %aten_view_copy_default_88, %aten_permute_copy_default_21), kwargs = {})\n",
      "  %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_13, 0), kwargs = {})\n",
      "  %aten_view_copy_default_89 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_29, [1, %sym_size_15, 1024]), kwargs = {})\n",
      "  %alloc_270 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_7 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_6, %aten_view_copy_default_89), kwargs = {out: %alloc_270})\n",
      "  %alloc_271 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_272 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_273 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_8 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_7, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_271, out1: %alloc_272, out2: %alloc_273})\n",
      "  %getitem_30 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_8, 0), kwargs = {})\n",
      "  %aten_view_copy_default_90 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_30, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_14 : [num_users=1] = get_attr[target=lowered_module_14]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_90 : [num_users=1] = placeholder[target=aten_view_copy_default_90]\n",
      "      %aten_permute_copy_default_43 : [num_users=1] = placeholder[target=aten_permute_copy_default_43]\n",
      "      %aten_addmm_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_bias, %aten_view_copy_default_90, %aten_permute_copy_default_43), kwargs = {})\n",
      "      return (aten_addmm_default_22,)\n",
      "  %executorch_call_delegate_14 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_14, %aten_view_copy_default_90, %aten_permute_copy_default_22), kwargs = {})\n",
      "  %getitem_31 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_14, 0), kwargs = {})\n",
      "  %aten_view_copy_default_91 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_31, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_274 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_11 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_91, %_lifted_tensor_constant12), kwargs = {out: %alloc_274})\n",
      "  %sym_size_16 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_91, 1), kwargs = {})\n",
      "  %alloc_275 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_3 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_11,), kwargs = {out: %alloc_275})\n",
      "  %alloc_276 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_12 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_91, %aten_sigmoid_default_3), kwargs = {out: %alloc_276})\n",
      "  %aten_view_copy_default_92 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_12, [%sym_size_16, 4096]), kwargs = {})\n",
      "  %lowered_module_15 : [num_users=1] = get_attr[target=lowered_module_15]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_92 : [num_users=1] = placeholder[target=aten_view_copy_default_92]\n",
      "      %aten_permute_copy_default_44 : [num_users=1] = placeholder[target=aten_permute_copy_default_44]\n",
      "      %aten_addmm_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_bias, %aten_view_copy_default_92, %aten_permute_copy_default_44), kwargs = {})\n",
      "      return (aten_addmm_default_23,)\n",
      "  %executorch_call_delegate_15 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_15, %aten_view_copy_default_92, %aten_permute_copy_default_23), kwargs = {})\n",
      "  %getitem_32 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_15, 0), kwargs = {})\n",
      "  %aten_view_copy_default_93 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_32, [1, %sym_size_16, 1024]), kwargs = {})\n",
      "  %alloc_277 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_8 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_7, %aten_view_copy_default_93), kwargs = {out: %alloc_277})\n",
      "  %alloc_278 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_279 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_280 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_9 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_8, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_278, out1: %alloc_279, out2: %alloc_280})\n",
      "  %getitem_33 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_9, 0), kwargs = {})\n",
      "  %aten_view_copy_default_94 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_33, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_95 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_33, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_96 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_33, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_16 : [num_users=1] = get_attr[target=lowered_module_16]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_96 : [num_users=1] = placeholder[target=aten_view_copy_default_96]\n",
      "      %aten_permute_copy_default_46 : [num_users=1] = placeholder[target=aten_permute_copy_default_46]\n",
      "      %aten_view_copy_default_99 : [num_users=1] = placeholder[target=aten_view_copy_default_99]\n",
      "      %aten_permute_copy_default_48 : [num_users=1] = placeholder[target=aten_permute_copy_default_48]\n",
      "      %aten_view_copy_default_94 : [num_users=1] = placeholder[target=aten_view_copy_default_94]\n",
      "      %aten_permute_copy_default_45 : [num_users=1] = placeholder[target=aten_permute_copy_default_45]\n",
      "      %aten_addmm_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_bias, %aten_view_copy_default_96, %aten_permute_copy_default_46), kwargs = {})\n",
      "      %aten_addmm_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_bias, %aten_view_copy_default_99, %aten_permute_copy_default_48), kwargs = {})\n",
      "      %aten_addmm_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_bias, %aten_view_copy_default_94, %aten_permute_copy_default_45), kwargs = {})\n",
      "      return (aten_addmm_default_25, aten_addmm_default_26, aten_addmm_default_24)\n",
      "  %executorch_call_delegate_16 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_16, %aten_view_copy_default_95, %aten_permute_copy_default_24, %aten_view_copy_default_96, %aten_permute_copy_default_25, %aten_view_copy_default_94, %aten_permute_copy_default_26), kwargs = {})\n",
      "  %getitem_34 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_16, 0), kwargs = {})\n",
      "  %getitem_35 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_16, 1), kwargs = {})\n",
      "  %getitem_36 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_16, 2), kwargs = {})\n",
      "  %aten_view_copy_default_99 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_36, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_100 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_34, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_101 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_35, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_281 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_13 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_99, %_lifted_tensor_constant13), kwargs = {out: %alloc_281})\n",
      "  %sym_size_17 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_99, 1), kwargs = {})\n",
      "  %alloc_282 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_161 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_100, [0, 2, 1, 3]), kwargs = {out: %alloc_282})\n",
      "  %alloc_283 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_162 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_101, [0, 2, 1, 3]), kwargs = {out: %alloc_283})\n",
      "  %aten_view_copy_default_102 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_13, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_284 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_23 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_161,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_284})\n",
      "  %alloc_285 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_24 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_162,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_285})\n",
      "  %alloc_286 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_163 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_102, [0, 2, 1, 3]), kwargs = {out: %alloc_286})\n",
      "  %aten_view_copy_default_103 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_23, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_104 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_24, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_287 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_25 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_163,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_287})\n",
      "  %alloc_288 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_164 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_103, [0, 2, 1]), kwargs = {out: %alloc_288})\n",
      "  %aten_view_copy_default_105 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_25, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_289 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_8 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_105, %aten_permute_copy_default_164), kwargs = {out: %alloc_289})\n",
      "  %alloc_290 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_4 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_8, -1, False), kwargs = {out: %alloc_290})\n",
      "  %alloc_291 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_26 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_4,), kwargs = {out: %alloc_291})\n",
      "  %alloc_292 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_9 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_26, %aten_view_copy_default_104), kwargs = {out: %alloc_292})\n",
      "  %aten_view_copy_default_106 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_9, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_293 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_165 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_106, [0, 2, 1, 3]), kwargs = {out: %alloc_293})\n",
      "  %alloc_294 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_27 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_165,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_294})\n",
      "  %aten_view_copy_default_108 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_27, [%sym_size_17, 1024]), kwargs = {})\n",
      "  %lowered_module_17 : [num_users=1] = get_attr[target=lowered_module_17]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_108 : [num_users=1] = placeholder[target=aten_view_copy_default_108]\n",
      "      %aten_permute_copy_default_53 : [num_users=1] = placeholder[target=aten_permute_copy_default_53]\n",
      "      %aten_addmm_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_bias, %aten_view_copy_default_108, %aten_permute_copy_default_53), kwargs = {})\n",
      "      return (aten_addmm_default_27,)\n",
      "  %executorch_call_delegate_17 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_17, %aten_view_copy_default_108, %aten_permute_copy_default_27), kwargs = {})\n",
      "  %getitem_37 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_17, 0), kwargs = {})\n",
      "  %aten_view_copy_default_109 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_37, [1, %sym_size_17, 1024]), kwargs = {})\n",
      "  %alloc_295 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_9 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_8, %aten_view_copy_default_109), kwargs = {out: %alloc_295})\n",
      "  %alloc_296 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_297 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_298 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_10 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_9, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_296, out1: %alloc_297, out2: %alloc_298})\n",
      "  %getitem_38 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_10, 0), kwargs = {})\n",
      "  %aten_view_copy_default_110 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_38, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_18 : [num_users=1] = get_attr[target=lowered_module_18]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_110 : [num_users=1] = placeholder[target=aten_view_copy_default_110]\n",
      "      %aten_permute_copy_default_54 : [num_users=1] = placeholder[target=aten_permute_copy_default_54]\n",
      "      %aten_addmm_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_bias, %aten_view_copy_default_110, %aten_permute_copy_default_54), kwargs = {})\n",
      "      return (aten_addmm_default_28,)\n",
      "  %executorch_call_delegate_18 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_18, %aten_view_copy_default_110, %aten_permute_copy_default_28), kwargs = {})\n",
      "  %getitem_39 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_18, 0), kwargs = {})\n",
      "  %aten_view_copy_default_111 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_39, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_299 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_14 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_111, %_lifted_tensor_constant14), kwargs = {out: %alloc_299})\n",
      "  %sym_size_18 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_111, 1), kwargs = {})\n",
      "  %alloc_300 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_4 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_14,), kwargs = {out: %alloc_300})\n",
      "  %alloc_301 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_15 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_111, %aten_sigmoid_default_4), kwargs = {out: %alloc_301})\n",
      "  %aten_view_copy_default_112 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_15, [%sym_size_18, 4096]), kwargs = {})\n",
      "  %lowered_module_19 : [num_users=1] = get_attr[target=lowered_module_19]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_112 : [num_users=1] = placeholder[target=aten_view_copy_default_112]\n",
      "      %aten_permute_copy_default_55 : [num_users=1] = placeholder[target=aten_permute_copy_default_55]\n",
      "      %aten_addmm_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_bias, %aten_view_copy_default_112, %aten_permute_copy_default_55), kwargs = {})\n",
      "      return (aten_addmm_default_29,)\n",
      "  %executorch_call_delegate_19 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_19, %aten_view_copy_default_112, %aten_permute_copy_default_29), kwargs = {})\n",
      "  %getitem_40 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_19, 0), kwargs = {})\n",
      "  %aten_view_copy_default_113 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_40, [1, %sym_size_18, 1024]), kwargs = {})\n",
      "  %alloc_302 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_10 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_9, %aten_view_copy_default_113), kwargs = {out: %alloc_302})\n",
      "  %alloc_303 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_304 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_305 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_11 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_10, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_303, out1: %alloc_304, out2: %alloc_305})\n",
      "  %getitem_41 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_11, 0), kwargs = {})\n",
      "  %aten_view_copy_default_114 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_41, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_115 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_41, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_116 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_41, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_20 : [num_users=1] = get_attr[target=lowered_module_20]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_116 : [num_users=1] = placeholder[target=aten_view_copy_default_116]\n",
      "      %aten_permute_copy_default_57 : [num_users=1] = placeholder[target=aten_permute_copy_default_57]\n",
      "      %aten_view_copy_default_119 : [num_users=1] = placeholder[target=aten_view_copy_default_119]\n",
      "      %aten_permute_copy_default_59 : [num_users=1] = placeholder[target=aten_permute_copy_default_59]\n",
      "      %aten_view_copy_default_114 : [num_users=1] = placeholder[target=aten_view_copy_default_114]\n",
      "      %aten_permute_copy_default_56 : [num_users=1] = placeholder[target=aten_permute_copy_default_56]\n",
      "      %aten_addmm_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_bias, %aten_view_copy_default_116, %aten_permute_copy_default_57), kwargs = {})\n",
      "      %aten_addmm_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_bias, %aten_view_copy_default_119, %aten_permute_copy_default_59), kwargs = {})\n",
      "      %aten_addmm_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_bias, %aten_view_copy_default_114, %aten_permute_copy_default_56), kwargs = {})\n",
      "      return (aten_addmm_default_31, aten_addmm_default_32, aten_addmm_default_30)\n",
      "  %executorch_call_delegate_20 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_20, %aten_view_copy_default_115, %aten_permute_copy_default_30, %aten_view_copy_default_116, %aten_permute_copy_default_31, %aten_view_copy_default_114, %aten_permute_copy_default_32), kwargs = {})\n",
      "  %getitem_42 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_20, 0), kwargs = {})\n",
      "  %getitem_43 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_20, 1), kwargs = {})\n",
      "  %getitem_44 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_20, 2), kwargs = {})\n",
      "  %aten_view_copy_default_119 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_44, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_120 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_42, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_121 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_43, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_306 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_16 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_119, %_lifted_tensor_constant15), kwargs = {out: %alloc_306})\n",
      "  %sym_size_19 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_119, 1), kwargs = {})\n",
      "  %alloc_307 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_166 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_120, [0, 2, 1, 3]), kwargs = {out: %alloc_307})\n",
      "  %alloc_308 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_167 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_121, [0, 2, 1, 3]), kwargs = {out: %alloc_308})\n",
      "  %aten_view_copy_default_122 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_16, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_309 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_28 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_166,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_309})\n",
      "  %alloc_310 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_29 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_167,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_310})\n",
      "  %alloc_311 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_168 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_122, [0, 2, 1, 3]), kwargs = {out: %alloc_311})\n",
      "  %aten_view_copy_default_123 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_28, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_124 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_29, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_312 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_30 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_168,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_312})\n",
      "  %alloc_313 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_169 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_123, [0, 2, 1]), kwargs = {out: %alloc_313})\n",
      "  %aten_view_copy_default_125 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_30, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_314 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_10 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_125, %aten_permute_copy_default_169), kwargs = {out: %alloc_314})\n",
      "  %alloc_315 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_5 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_10, -1, False), kwargs = {out: %alloc_315})\n",
      "  %alloc_316 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_31 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_5,), kwargs = {out: %alloc_316})\n",
      "  %alloc_317 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_11 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_31, %aten_view_copy_default_124), kwargs = {out: %alloc_317})\n",
      "  %aten_view_copy_default_126 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_11, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_318 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_170 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_126, [0, 2, 1, 3]), kwargs = {out: %alloc_318})\n",
      "  %alloc_319 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_32 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_170,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_319})\n",
      "  %aten_view_copy_default_128 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_32, [%sym_size_19, 1024]), kwargs = {})\n",
      "  %lowered_module_21 : [num_users=1] = get_attr[target=lowered_module_21]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_128 : [num_users=1] = placeholder[target=aten_view_copy_default_128]\n",
      "      %aten_permute_copy_default_64 : [num_users=1] = placeholder[target=aten_permute_copy_default_64]\n",
      "      %aten_addmm_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_bias, %aten_view_copy_default_128, %aten_permute_copy_default_64), kwargs = {})\n",
      "      return (aten_addmm_default_33,)\n",
      "  %executorch_call_delegate_21 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_21, %aten_view_copy_default_128, %aten_permute_copy_default_33), kwargs = {})\n",
      "  %getitem_45 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_21, 0), kwargs = {})\n",
      "  %aten_view_copy_default_129 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_45, [1, %sym_size_19, 1024]), kwargs = {})\n",
      "  %alloc_320 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_11 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_10, %aten_view_copy_default_129), kwargs = {out: %alloc_320})\n",
      "  %alloc_321 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_322 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_323 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_12 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_11, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_321, out1: %alloc_322, out2: %alloc_323})\n",
      "  %getitem_46 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_12, 0), kwargs = {})\n",
      "  %aten_view_copy_default_130 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_46, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_22 : [num_users=1] = get_attr[target=lowered_module_22]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_130 : [num_users=1] = placeholder[target=aten_view_copy_default_130]\n",
      "      %aten_permute_copy_default_65 : [num_users=1] = placeholder[target=aten_permute_copy_default_65]\n",
      "      %aten_addmm_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_bias, %aten_view_copy_default_130, %aten_permute_copy_default_65), kwargs = {})\n",
      "      return (aten_addmm_default_34,)\n",
      "  %executorch_call_delegate_22 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_22, %aten_view_copy_default_130, %aten_permute_copy_default_34), kwargs = {})\n",
      "  %getitem_47 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_22, 0), kwargs = {})\n",
      "  %aten_view_copy_default_131 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_47, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_324 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_17 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_131, %_lifted_tensor_constant16), kwargs = {out: %alloc_324})\n",
      "  %sym_size_20 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_131, 1), kwargs = {})\n",
      "  %alloc_325 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_5 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_17,), kwargs = {out: %alloc_325})\n",
      "  %alloc_326 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_18 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_131, %aten_sigmoid_default_5), kwargs = {out: %alloc_326})\n",
      "  %aten_view_copy_default_132 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_18, [%sym_size_20, 4096]), kwargs = {})\n",
      "  %lowered_module_23 : [num_users=1] = get_attr[target=lowered_module_23]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_132 : [num_users=1] = placeholder[target=aten_view_copy_default_132]\n",
      "      %aten_permute_copy_default_66 : [num_users=1] = placeholder[target=aten_permute_copy_default_66]\n",
      "      %aten_addmm_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_bias, %aten_view_copy_default_132, %aten_permute_copy_default_66), kwargs = {})\n",
      "      return (aten_addmm_default_35,)\n",
      "  %executorch_call_delegate_23 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_23, %aten_view_copy_default_132, %aten_permute_copy_default_35), kwargs = {})\n",
      "  %getitem_48 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_23, 0), kwargs = {})\n",
      "  %aten_view_copy_default_133 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_48, [1, %sym_size_20, 1024]), kwargs = {})\n",
      "  %alloc_327 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_12 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_11, %aten_view_copy_default_133), kwargs = {out: %alloc_327})\n",
      "  %alloc_328 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_329 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_330 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_13 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_12, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_328, out1: %alloc_329, out2: %alloc_330})\n",
      "  %getitem_49 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_13, 0), kwargs = {})\n",
      "  %aten_view_copy_default_134 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_49, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_135 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_49, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_136 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_49, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_24 : [num_users=1] = get_attr[target=lowered_module_24]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_136 : [num_users=1] = placeholder[target=aten_view_copy_default_136]\n",
      "      %aten_permute_copy_default_68 : [num_users=1] = placeholder[target=aten_permute_copy_default_68]\n",
      "      %aten_view_copy_default_139 : [num_users=1] = placeholder[target=aten_view_copy_default_139]\n",
      "      %aten_permute_copy_default_70 : [num_users=1] = placeholder[target=aten_permute_copy_default_70]\n",
      "      %aten_view_copy_default_134 : [num_users=1] = placeholder[target=aten_view_copy_default_134]\n",
      "      %aten_permute_copy_default_67 : [num_users=1] = placeholder[target=aten_permute_copy_default_67]\n",
      "      %aten_addmm_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_bias, %aten_view_copy_default_136, %aten_permute_copy_default_68), kwargs = {})\n",
      "      %aten_addmm_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_bias, %aten_view_copy_default_139, %aten_permute_copy_default_70), kwargs = {})\n",
      "      %aten_addmm_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_bias, %aten_view_copy_default_134, %aten_permute_copy_default_67), kwargs = {})\n",
      "      return (aten_addmm_default_37, aten_addmm_default_38, aten_addmm_default_36)\n",
      "  %executorch_call_delegate_24 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_24, %aten_view_copy_default_135, %aten_permute_copy_default_36, %aten_view_copy_default_136, %aten_permute_copy_default_37, %aten_view_copy_default_134, %aten_permute_copy_default_38), kwargs = {})\n",
      "  %getitem_50 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_24, 0), kwargs = {})\n",
      "  %getitem_51 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_24, 1), kwargs = {})\n",
      "  %getitem_52 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_24, 2), kwargs = {})\n",
      "  %aten_view_copy_default_139 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_52, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_140 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_50, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_141 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_51, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_331 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_19 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_139, %_lifted_tensor_constant17), kwargs = {out: %alloc_331})\n",
      "  %sym_size_21 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_139, 1), kwargs = {})\n",
      "  %alloc_332 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_171 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_140, [0, 2, 1, 3]), kwargs = {out: %alloc_332})\n",
      "  %alloc_333 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_172 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_141, [0, 2, 1, 3]), kwargs = {out: %alloc_333})\n",
      "  %aten_view_copy_default_142 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_19, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_334 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_33 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_171,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_334})\n",
      "  %alloc_335 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_34 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_172,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_335})\n",
      "  %alloc_336 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_173 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_142, [0, 2, 1, 3]), kwargs = {out: %alloc_336})\n",
      "  %aten_view_copy_default_143 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_33, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_144 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_34, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_337 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_35 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_173,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_337})\n",
      "  %alloc_338 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_174 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_143, [0, 2, 1]), kwargs = {out: %alloc_338})\n",
      "  %aten_view_copy_default_145 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_35, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_339 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_12 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_145, %aten_permute_copy_default_174), kwargs = {out: %alloc_339})\n",
      "  %alloc_340 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_6 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_12, -1, False), kwargs = {out: %alloc_340})\n",
      "  %alloc_341 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_36 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_6,), kwargs = {out: %alloc_341})\n",
      "  %alloc_342 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_13 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_36, %aten_view_copy_default_144), kwargs = {out: %alloc_342})\n",
      "  %aten_view_copy_default_146 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_13, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_343 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_175 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_146, [0, 2, 1, 3]), kwargs = {out: %alloc_343})\n",
      "  %alloc_344 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_37 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_175,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_344})\n",
      "  %aten_view_copy_default_148 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_37, [%sym_size_21, 1024]), kwargs = {})\n",
      "  %lowered_module_25 : [num_users=1] = get_attr[target=lowered_module_25]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_148 : [num_users=1] = placeholder[target=aten_view_copy_default_148]\n",
      "      %aten_permute_copy_default_75 : [num_users=1] = placeholder[target=aten_permute_copy_default_75]\n",
      "      %aten_addmm_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_bias, %aten_view_copy_default_148, %aten_permute_copy_default_75), kwargs = {})\n",
      "      return (aten_addmm_default_39,)\n",
      "  %executorch_call_delegate_25 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_25, %aten_view_copy_default_148, %aten_permute_copy_default_39), kwargs = {})\n",
      "  %getitem_53 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_25, 0), kwargs = {})\n",
      "  %aten_view_copy_default_149 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_53, [1, %sym_size_21, 1024]), kwargs = {})\n",
      "  %alloc_345 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_13 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_12, %aten_view_copy_default_149), kwargs = {out: %alloc_345})\n",
      "  %alloc_346 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_347 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_348 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_14 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_13, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_346, out1: %alloc_347, out2: %alloc_348})\n",
      "  %getitem_54 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_14, 0), kwargs = {})\n",
      "  %aten_view_copy_default_150 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_54, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_26 : [num_users=1] = get_attr[target=lowered_module_26]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_150 : [num_users=1] = placeholder[target=aten_view_copy_default_150]\n",
      "      %aten_permute_copy_default_76 : [num_users=1] = placeholder[target=aten_permute_copy_default_76]\n",
      "      %aten_addmm_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_bias, %aten_view_copy_default_150, %aten_permute_copy_default_76), kwargs = {})\n",
      "      return (aten_addmm_default_40,)\n",
      "  %executorch_call_delegate_26 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_26, %aten_view_copy_default_150, %aten_permute_copy_default_40), kwargs = {})\n",
      "  %getitem_55 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_26, 0), kwargs = {})\n",
      "  %aten_view_copy_default_151 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_55, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_349 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_20 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_151, %_lifted_tensor_constant18), kwargs = {out: %alloc_349})\n",
      "  %sym_size_22 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_151, 1), kwargs = {})\n",
      "  %alloc_350 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_6 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_20,), kwargs = {out: %alloc_350})\n",
      "  %alloc_351 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_21 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_151, %aten_sigmoid_default_6), kwargs = {out: %alloc_351})\n",
      "  %aten_view_copy_default_152 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_21, [%sym_size_22, 4096]), kwargs = {})\n",
      "  %lowered_module_27 : [num_users=1] = get_attr[target=lowered_module_27]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_152 : [num_users=1] = placeholder[target=aten_view_copy_default_152]\n",
      "      %aten_permute_copy_default_77 : [num_users=1] = placeholder[target=aten_permute_copy_default_77]\n",
      "      %aten_addmm_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_bias, %aten_view_copy_default_152, %aten_permute_copy_default_77), kwargs = {})\n",
      "      return (aten_addmm_default_41,)\n",
      "  %executorch_call_delegate_27 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_27, %aten_view_copy_default_152, %aten_permute_copy_default_41), kwargs = {})\n",
      "  %getitem_56 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_27, 0), kwargs = {})\n",
      "  %aten_view_copy_default_153 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_56, [1, %sym_size_22, 1024]), kwargs = {})\n",
      "  %alloc_352 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_14 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_13, %aten_view_copy_default_153), kwargs = {out: %alloc_352})\n",
      "  %alloc_353 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_354 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_355 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_15 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_14, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_353, out1: %alloc_354, out2: %alloc_355})\n",
      "  %getitem_57 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_15, 0), kwargs = {})\n",
      "  %aten_view_copy_default_154 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_57, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_155 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_57, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_156 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_57, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_28 : [num_users=1] = get_attr[target=lowered_module_28]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_156 : [num_users=1] = placeholder[target=aten_view_copy_default_156]\n",
      "      %aten_permute_copy_default_79 : [num_users=1] = placeholder[target=aten_permute_copy_default_79]\n",
      "      %aten_view_copy_default_159 : [num_users=1] = placeholder[target=aten_view_copy_default_159]\n",
      "      %aten_permute_copy_default_81 : [num_users=1] = placeholder[target=aten_permute_copy_default_81]\n",
      "      %aten_view_copy_default_154 : [num_users=1] = placeholder[target=aten_view_copy_default_154]\n",
      "      %aten_permute_copy_default_78 : [num_users=1] = placeholder[target=aten_permute_copy_default_78]\n",
      "      %aten_addmm_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_bias, %aten_view_copy_default_156, %aten_permute_copy_default_79), kwargs = {})\n",
      "      %aten_addmm_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_bias, %aten_view_copy_default_159, %aten_permute_copy_default_81), kwargs = {})\n",
      "      %aten_addmm_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_bias, %aten_view_copy_default_154, %aten_permute_copy_default_78), kwargs = {})\n",
      "      return (aten_addmm_default_43, aten_addmm_default_44, aten_addmm_default_42)\n",
      "  %executorch_call_delegate_28 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_28, %aten_view_copy_default_155, %aten_permute_copy_default_42, %aten_view_copy_default_156, %aten_permute_copy_default_43, %aten_view_copy_default_154, %aten_permute_copy_default_44), kwargs = {})\n",
      "  %getitem_58 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_28, 0), kwargs = {})\n",
      "  %getitem_59 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_28, 1), kwargs = {})\n",
      "  %getitem_60 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_28, 2), kwargs = {})\n",
      "  %aten_view_copy_default_159 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_60, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_160 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_58, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_161 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_59, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_356 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_22 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_159, %_lifted_tensor_constant19), kwargs = {out: %alloc_356})\n",
      "  %sym_size_23 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_159, 1), kwargs = {})\n",
      "  %alloc_357 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_176 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_160, [0, 2, 1, 3]), kwargs = {out: %alloc_357})\n",
      "  %alloc_358 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_177 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_161, [0, 2, 1, 3]), kwargs = {out: %alloc_358})\n",
      "  %aten_view_copy_default_162 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_22, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_359 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_38 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_176,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_359})\n",
      "  %alloc_360 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_39 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_177,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_360})\n",
      "  %alloc_361 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_178 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_162, [0, 2, 1, 3]), kwargs = {out: %alloc_361})\n",
      "  %aten_view_copy_default_163 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_38, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_164 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_39, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_362 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_40 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_178,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_362})\n",
      "  %alloc_363 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_179 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_163, [0, 2, 1]), kwargs = {out: %alloc_363})\n",
      "  %aten_view_copy_default_165 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_40, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_364 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_14 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_165, %aten_permute_copy_default_179), kwargs = {out: %alloc_364})\n",
      "  %alloc_365 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_7 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_14, -1, False), kwargs = {out: %alloc_365})\n",
      "  %alloc_366 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_41 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_7,), kwargs = {out: %alloc_366})\n",
      "  %alloc_367 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_15 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_41, %aten_view_copy_default_164), kwargs = {out: %alloc_367})\n",
      "  %aten_view_copy_default_166 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_15, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_368 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_180 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_166, [0, 2, 1, 3]), kwargs = {out: %alloc_368})\n",
      "  %alloc_369 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_42 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_180,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_369})\n",
      "  %aten_view_copy_default_168 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_42, [%sym_size_23, 1024]), kwargs = {})\n",
      "  %lowered_module_29 : [num_users=1] = get_attr[target=lowered_module_29]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_168 : [num_users=1] = placeholder[target=aten_view_copy_default_168]\n",
      "      %aten_permute_copy_default_86 : [num_users=1] = placeholder[target=aten_permute_copy_default_86]\n",
      "      %aten_addmm_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_bias, %aten_view_copy_default_168, %aten_permute_copy_default_86), kwargs = {})\n",
      "      return (aten_addmm_default_45,)\n",
      "  %executorch_call_delegate_29 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_29, %aten_view_copy_default_168, %aten_permute_copy_default_45), kwargs = {})\n",
      "  %getitem_61 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_29, 0), kwargs = {})\n",
      "  %aten_view_copy_default_169 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_61, [1, %sym_size_23, 1024]), kwargs = {})\n",
      "  %alloc_370 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_15 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_14, %aten_view_copy_default_169), kwargs = {out: %alloc_370})\n",
      "  %alloc_371 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_372 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_373 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_16 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_15, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_371, out1: %alloc_372, out2: %alloc_373})\n",
      "  %getitem_62 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_16, 0), kwargs = {})\n",
      "  %aten_view_copy_default_170 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_62, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_30 : [num_users=1] = get_attr[target=lowered_module_30]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_170 : [num_users=1] = placeholder[target=aten_view_copy_default_170]\n",
      "      %aten_permute_copy_default_87 : [num_users=1] = placeholder[target=aten_permute_copy_default_87]\n",
      "      %aten_addmm_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_bias, %aten_view_copy_default_170, %aten_permute_copy_default_87), kwargs = {})\n",
      "      return (aten_addmm_default_46,)\n",
      "  %executorch_call_delegate_30 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_30, %aten_view_copy_default_170, %aten_permute_copy_default_46), kwargs = {})\n",
      "  %getitem_63 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_30, 0), kwargs = {})\n",
      "  %aten_view_copy_default_171 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_63, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_374 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_23 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_171, %_lifted_tensor_constant20), kwargs = {out: %alloc_374})\n",
      "  %sym_size_24 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_171, 1), kwargs = {})\n",
      "  %alloc_375 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_7 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_23,), kwargs = {out: %alloc_375})\n",
      "  %alloc_376 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_24 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_171, %aten_sigmoid_default_7), kwargs = {out: %alloc_376})\n",
      "  %aten_view_copy_default_172 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_24, [%sym_size_24, 4096]), kwargs = {})\n",
      "  %lowered_module_31 : [num_users=1] = get_attr[target=lowered_module_31]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_172 : [num_users=1] = placeholder[target=aten_view_copy_default_172]\n",
      "      %aten_permute_copy_default_88 : [num_users=1] = placeholder[target=aten_permute_copy_default_88]\n",
      "      %aten_addmm_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_bias, %aten_view_copy_default_172, %aten_permute_copy_default_88), kwargs = {})\n",
      "      return (aten_addmm_default_47,)\n",
      "  %executorch_call_delegate_31 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_31, %aten_view_copy_default_172, %aten_permute_copy_default_47), kwargs = {})\n",
      "  %getitem_64 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_31, 0), kwargs = {})\n",
      "  %aten_view_copy_default_173 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_64, [1, %sym_size_24, 1024]), kwargs = {})\n",
      "  %alloc_377 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_16 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_15, %aten_view_copy_default_173), kwargs = {out: %alloc_377})\n",
      "  %alloc_378 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_379 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_380 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_17 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_16, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_378, out1: %alloc_379, out2: %alloc_380})\n",
      "  %getitem_65 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_17, 0), kwargs = {})\n",
      "  %aten_view_copy_default_174 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_65, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_175 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_65, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_176 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_65, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_32 : [num_users=1] = get_attr[target=lowered_module_32]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_176 : [num_users=1] = placeholder[target=aten_view_copy_default_176]\n",
      "      %aten_permute_copy_default_90 : [num_users=1] = placeholder[target=aten_permute_copy_default_90]\n",
      "      %aten_view_copy_default_179 : [num_users=1] = placeholder[target=aten_view_copy_default_179]\n",
      "      %aten_permute_copy_default_92 : [num_users=1] = placeholder[target=aten_permute_copy_default_92]\n",
      "      %aten_view_copy_default_174 : [num_users=1] = placeholder[target=aten_view_copy_default_174]\n",
      "      %aten_permute_copy_default_89 : [num_users=1] = placeholder[target=aten_permute_copy_default_89]\n",
      "      %aten_addmm_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_bias, %aten_view_copy_default_176, %aten_permute_copy_default_90), kwargs = {})\n",
      "      %aten_addmm_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_bias, %aten_view_copy_default_179, %aten_permute_copy_default_92), kwargs = {})\n",
      "      %aten_addmm_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_bias, %aten_view_copy_default_174, %aten_permute_copy_default_89), kwargs = {})\n",
      "      return (aten_addmm_default_49, aten_addmm_default_50, aten_addmm_default_48)\n",
      "  %executorch_call_delegate_32 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_32, %aten_view_copy_default_175, %aten_permute_copy_default_48, %aten_view_copy_default_176, %aten_permute_copy_default_49, %aten_view_copy_default_174, %aten_permute_copy_default_50), kwargs = {})\n",
      "  %getitem_66 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_32, 0), kwargs = {})\n",
      "  %getitem_67 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_32, 1), kwargs = {})\n",
      "  %getitem_68 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_32, 2), kwargs = {})\n",
      "  %aten_view_copy_default_179 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_68, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_180 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_66, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_181 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_67, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_381 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_25 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_179, %_lifted_tensor_constant21), kwargs = {out: %alloc_381})\n",
      "  %sym_size_25 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_179, 1), kwargs = {})\n",
      "  %alloc_382 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_181 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_180, [0, 2, 1, 3]), kwargs = {out: %alloc_382})\n",
      "  %alloc_383 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_182 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_181, [0, 2, 1, 3]), kwargs = {out: %alloc_383})\n",
      "  %aten_view_copy_default_182 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_25, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_384 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_43 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_181,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_384})\n",
      "  %alloc_385 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_44 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_182,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_385})\n",
      "  %alloc_386 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_183 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_182, [0, 2, 1, 3]), kwargs = {out: %alloc_386})\n",
      "  %aten_view_copy_default_183 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_43, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_184 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_44, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_387 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_45 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_183,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_387})\n",
      "  %alloc_388 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_184 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_183, [0, 2, 1]), kwargs = {out: %alloc_388})\n",
      "  %aten_view_copy_default_185 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_45, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_389 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_16 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_185, %aten_permute_copy_default_184), kwargs = {out: %alloc_389})\n",
      "  %alloc_390 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_8 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_16, -1, False), kwargs = {out: %alloc_390})\n",
      "  %alloc_391 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_46 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_8,), kwargs = {out: %alloc_391})\n",
      "  %alloc_392 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_17 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_46, %aten_view_copy_default_184), kwargs = {out: %alloc_392})\n",
      "  %aten_view_copy_default_186 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_17, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_393 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_185 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_186, [0, 2, 1, 3]), kwargs = {out: %alloc_393})\n",
      "  %alloc_394 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_47 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_185,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_394})\n",
      "  %aten_view_copy_default_188 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_47, [%sym_size_25, 1024]), kwargs = {})\n",
      "  %lowered_module_33 : [num_users=1] = get_attr[target=lowered_module_33]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_188 : [num_users=1] = placeholder[target=aten_view_copy_default_188]\n",
      "      %aten_permute_copy_default_97 : [num_users=1] = placeholder[target=aten_permute_copy_default_97]\n",
      "      %aten_addmm_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_bias, %aten_view_copy_default_188, %aten_permute_copy_default_97), kwargs = {})\n",
      "      return (aten_addmm_default_51,)\n",
      "  %executorch_call_delegate_33 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_33, %aten_view_copy_default_188, %aten_permute_copy_default_51), kwargs = {})\n",
      "  %getitem_69 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_33, 0), kwargs = {})\n",
      "  %aten_view_copy_default_189 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_69, [1, %sym_size_25, 1024]), kwargs = {})\n",
      "  %alloc_395 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_17 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_16, %aten_view_copy_default_189), kwargs = {out: %alloc_395})\n",
      "  %alloc_396 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_397 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_398 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_18 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_17, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_396, out1: %alloc_397, out2: %alloc_398})\n",
      "  %getitem_70 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_18, 0), kwargs = {})\n",
      "  %aten_view_copy_default_190 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_70, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_34 : [num_users=1] = get_attr[target=lowered_module_34]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_190 : [num_users=1] = placeholder[target=aten_view_copy_default_190]\n",
      "      %aten_permute_copy_default_98 : [num_users=1] = placeholder[target=aten_permute_copy_default_98]\n",
      "      %aten_addmm_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_bias, %aten_view_copy_default_190, %aten_permute_copy_default_98), kwargs = {})\n",
      "      return (aten_addmm_default_52,)\n",
      "  %executorch_call_delegate_34 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_34, %aten_view_copy_default_190, %aten_permute_copy_default_52), kwargs = {})\n",
      "  %getitem_71 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_34, 0), kwargs = {})\n",
      "  %aten_view_copy_default_191 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_71, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_399 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_26 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_191, %_lifted_tensor_constant22), kwargs = {out: %alloc_399})\n",
      "  %sym_size_26 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_191, 1), kwargs = {})\n",
      "  %alloc_400 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_8 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_26,), kwargs = {out: %alloc_400})\n",
      "  %alloc_401 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_27 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_191, %aten_sigmoid_default_8), kwargs = {out: %alloc_401})\n",
      "  %aten_view_copy_default_192 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_27, [%sym_size_26, 4096]), kwargs = {})\n",
      "  %lowered_module_35 : [num_users=1] = get_attr[target=lowered_module_35]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_192 : [num_users=1] = placeholder[target=aten_view_copy_default_192]\n",
      "      %aten_permute_copy_default_99 : [num_users=1] = placeholder[target=aten_permute_copy_default_99]\n",
      "      %aten_addmm_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_bias, %aten_view_copy_default_192, %aten_permute_copy_default_99), kwargs = {})\n",
      "      return (aten_addmm_default_53,)\n",
      "  %executorch_call_delegate_35 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_35, %aten_view_copy_default_192, %aten_permute_copy_default_53), kwargs = {})\n",
      "  %getitem_72 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_35, 0), kwargs = {})\n",
      "  %aten_view_copy_default_193 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_72, [1, %sym_size_26, 1024]), kwargs = {})\n",
      "  %alloc_402 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_18 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_17, %aten_view_copy_default_193), kwargs = {out: %alloc_402})\n",
      "  %alloc_403 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_404 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_405 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_19 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_18, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_403, out1: %alloc_404, out2: %alloc_405})\n",
      "  %getitem_73 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_19, 0), kwargs = {})\n",
      "  %aten_view_copy_default_194 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_73, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_195 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_73, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_196 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_73, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_36 : [num_users=1] = get_attr[target=lowered_module_36]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_196 : [num_users=1] = placeholder[target=aten_view_copy_default_196]\n",
      "      %aten_permute_copy_default_101 : [num_users=1] = placeholder[target=aten_permute_copy_default_101]\n",
      "      %aten_view_copy_default_199 : [num_users=1] = placeholder[target=aten_view_copy_default_199]\n",
      "      %aten_permute_copy_default_103 : [num_users=1] = placeholder[target=aten_permute_copy_default_103]\n",
      "      %aten_view_copy_default_194 : [num_users=1] = placeholder[target=aten_view_copy_default_194]\n",
      "      %aten_permute_copy_default_100 : [num_users=1] = placeholder[target=aten_permute_copy_default_100]\n",
      "      %aten_addmm_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_bias, %aten_view_copy_default_196, %aten_permute_copy_default_101), kwargs = {})\n",
      "      %aten_addmm_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_bias, %aten_view_copy_default_199, %aten_permute_copy_default_103), kwargs = {})\n",
      "      %aten_addmm_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_bias, %aten_view_copy_default_194, %aten_permute_copy_default_100), kwargs = {})\n",
      "      return (aten_addmm_default_55, aten_addmm_default_56, aten_addmm_default_54)\n",
      "  %executorch_call_delegate_36 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_36, %aten_view_copy_default_195, %aten_permute_copy_default_54, %aten_view_copy_default_196, %aten_permute_copy_default_55, %aten_view_copy_default_194, %aten_permute_copy_default_56), kwargs = {})\n",
      "  %getitem_74 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_36, 0), kwargs = {})\n",
      "  %getitem_75 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_36, 1), kwargs = {})\n",
      "  %getitem_76 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_36, 2), kwargs = {})\n",
      "  %aten_view_copy_default_199 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_76, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_200 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_74, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_201 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_75, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_406 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_28 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_199, %_lifted_tensor_constant23), kwargs = {out: %alloc_406})\n",
      "  %sym_size_27 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_199, 1), kwargs = {})\n",
      "  %alloc_407 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_186 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_200, [0, 2, 1, 3]), kwargs = {out: %alloc_407})\n",
      "  %alloc_408 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_187 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_201, [0, 2, 1, 3]), kwargs = {out: %alloc_408})\n",
      "  %aten_view_copy_default_202 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_28, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_409 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_48 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_186,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_409})\n",
      "  %alloc_410 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_49 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_187,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_410})\n",
      "  %alloc_411 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_188 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_202, [0, 2, 1, 3]), kwargs = {out: %alloc_411})\n",
      "  %aten_view_copy_default_203 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_48, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_204 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_49, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_412 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_50 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_188,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_412})\n",
      "  %alloc_413 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_189 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_203, [0, 2, 1]), kwargs = {out: %alloc_413})\n",
      "  %aten_view_copy_default_205 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_50, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_414 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_18 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_205, %aten_permute_copy_default_189), kwargs = {out: %alloc_414})\n",
      "  %alloc_415 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_9 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_18, -1, False), kwargs = {out: %alloc_415})\n",
      "  %alloc_416 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_51 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_9,), kwargs = {out: %alloc_416})\n",
      "  %alloc_417 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_19 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_51, %aten_view_copy_default_204), kwargs = {out: %alloc_417})\n",
      "  %aten_view_copy_default_206 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_19, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_418 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_190 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_206, [0, 2, 1, 3]), kwargs = {out: %alloc_418})\n",
      "  %alloc_419 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_52 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_190,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_419})\n",
      "  %aten_view_copy_default_208 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_52, [%sym_size_27, 1024]), kwargs = {})\n",
      "  %lowered_module_37 : [num_users=1] = get_attr[target=lowered_module_37]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_208 : [num_users=1] = placeholder[target=aten_view_copy_default_208]\n",
      "      %aten_permute_copy_default_108 : [num_users=1] = placeholder[target=aten_permute_copy_default_108]\n",
      "      %aten_addmm_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_bias, %aten_view_copy_default_208, %aten_permute_copy_default_108), kwargs = {})\n",
      "      return (aten_addmm_default_57,)\n",
      "  %executorch_call_delegate_37 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_37, %aten_view_copy_default_208, %aten_permute_copy_default_57), kwargs = {})\n",
      "  %getitem_77 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_37, 0), kwargs = {})\n",
      "  %aten_view_copy_default_209 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_77, [1, %sym_size_27, 1024]), kwargs = {})\n",
      "  %alloc_420 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_19 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_18, %aten_view_copy_default_209), kwargs = {out: %alloc_420})\n",
      "  %alloc_421 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_422 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_423 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_20 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_19, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_421, out1: %alloc_422, out2: %alloc_423})\n",
      "  %getitem_78 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_20, 0), kwargs = {})\n",
      "  %aten_view_copy_default_210 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_78, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_38 : [num_users=1] = get_attr[target=lowered_module_38]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_210 : [num_users=1] = placeholder[target=aten_view_copy_default_210]\n",
      "      %aten_permute_copy_default_109 : [num_users=1] = placeholder[target=aten_permute_copy_default_109]\n",
      "      %aten_addmm_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_bias, %aten_view_copy_default_210, %aten_permute_copy_default_109), kwargs = {})\n",
      "      return (aten_addmm_default_58,)\n",
      "  %executorch_call_delegate_38 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_38, %aten_view_copy_default_210, %aten_permute_copy_default_58), kwargs = {})\n",
      "  %getitem_79 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_38, 0), kwargs = {})\n",
      "  %aten_view_copy_default_211 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_79, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_424 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_29 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_211, %_lifted_tensor_constant24), kwargs = {out: %alloc_424})\n",
      "  %sym_size_28 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_211, 1), kwargs = {})\n",
      "  %alloc_425 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_9 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_29,), kwargs = {out: %alloc_425})\n",
      "  %alloc_426 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_30 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_211, %aten_sigmoid_default_9), kwargs = {out: %alloc_426})\n",
      "  %aten_view_copy_default_212 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_30, [%sym_size_28, 4096]), kwargs = {})\n",
      "  %lowered_module_39 : [num_users=1] = get_attr[target=lowered_module_39]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_212 : [num_users=1] = placeholder[target=aten_view_copy_default_212]\n",
      "      %aten_permute_copy_default_110 : [num_users=1] = placeholder[target=aten_permute_copy_default_110]\n",
      "      %aten_addmm_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_bias, %aten_view_copy_default_212, %aten_permute_copy_default_110), kwargs = {})\n",
      "      return (aten_addmm_default_59,)\n",
      "  %executorch_call_delegate_39 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_39, %aten_view_copy_default_212, %aten_permute_copy_default_59), kwargs = {})\n",
      "  %getitem_80 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_39, 0), kwargs = {})\n",
      "  %aten_view_copy_default_213 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_80, [1, %sym_size_28, 1024]), kwargs = {})\n",
      "  %alloc_427 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_20 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_19, %aten_view_copy_default_213), kwargs = {out: %alloc_427})\n",
      "  %alloc_428 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_429 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_430 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_21 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_20, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_428, out1: %alloc_429, out2: %alloc_430})\n",
      "  %getitem_81 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_21, 0), kwargs = {})\n",
      "  %aten_view_copy_default_214 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_81, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_215 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_81, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_216 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_81, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_40 : [num_users=1] = get_attr[target=lowered_module_40]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_216 : [num_users=1] = placeholder[target=aten_view_copy_default_216]\n",
      "      %aten_permute_copy_default_112 : [num_users=1] = placeholder[target=aten_permute_copy_default_112]\n",
      "      %aten_view_copy_default_219 : [num_users=1] = placeholder[target=aten_view_copy_default_219]\n",
      "      %aten_permute_copy_default_114 : [num_users=1] = placeholder[target=aten_permute_copy_default_114]\n",
      "      %aten_view_copy_default_214 : [num_users=1] = placeholder[target=aten_view_copy_default_214]\n",
      "      %aten_permute_copy_default_111 : [num_users=1] = placeholder[target=aten_permute_copy_default_111]\n",
      "      %aten_addmm_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_bias, %aten_view_copy_default_216, %aten_permute_copy_default_112), kwargs = {})\n",
      "      %aten_addmm_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_bias, %aten_view_copy_default_219, %aten_permute_copy_default_114), kwargs = {})\n",
      "      %aten_addmm_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_bias, %aten_view_copy_default_214, %aten_permute_copy_default_111), kwargs = {})\n",
      "      return (aten_addmm_default_61, aten_addmm_default_62, aten_addmm_default_60)\n",
      "  %executorch_call_delegate_40 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_40, %aten_view_copy_default_215, %aten_permute_copy_default_60, %aten_view_copy_default_216, %aten_permute_copy_default_61, %aten_view_copy_default_214, %aten_permute_copy_default_62), kwargs = {})\n",
      "  %getitem_82 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_40, 0), kwargs = {})\n",
      "  %getitem_83 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_40, 1), kwargs = {})\n",
      "  %getitem_84 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_40, 2), kwargs = {})\n",
      "  %aten_view_copy_default_219 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_84, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_220 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_82, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_221 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_83, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_431 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_31 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_219, %_lifted_tensor_constant25), kwargs = {out: %alloc_431})\n",
      "  %sym_size_29 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_219, 1), kwargs = {})\n",
      "  %alloc_432 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_191 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_220, [0, 2, 1, 3]), kwargs = {out: %alloc_432})\n",
      "  %alloc_433 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_192 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_221, [0, 2, 1, 3]), kwargs = {out: %alloc_433})\n",
      "  %aten_view_copy_default_222 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_31, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_434 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_53 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_191,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_434})\n",
      "  %alloc_435 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_54 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_192,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_435})\n",
      "  %alloc_436 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_193 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_222, [0, 2, 1, 3]), kwargs = {out: %alloc_436})\n",
      "  %aten_view_copy_default_223 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_53, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_224 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_54, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_437 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_55 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_193,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_437})\n",
      "  %alloc_438 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_194 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_223, [0, 2, 1]), kwargs = {out: %alloc_438})\n",
      "  %aten_view_copy_default_225 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_55, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_439 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_20 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_225, %aten_permute_copy_default_194), kwargs = {out: %alloc_439})\n",
      "  %alloc_440 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_10 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_20, -1, False), kwargs = {out: %alloc_440})\n",
      "  %alloc_441 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_56 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_10,), kwargs = {out: %alloc_441})\n",
      "  %alloc_442 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_21 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_56, %aten_view_copy_default_224), kwargs = {out: %alloc_442})\n",
      "  %aten_view_copy_default_226 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_21, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_443 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_195 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_226, [0, 2, 1, 3]), kwargs = {out: %alloc_443})\n",
      "  %alloc_444 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_57 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_195,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_444})\n",
      "  %aten_view_copy_default_228 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_57, [%sym_size_29, 1024]), kwargs = {})\n",
      "  %lowered_module_41 : [num_users=1] = get_attr[target=lowered_module_41]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_228 : [num_users=1] = placeholder[target=aten_view_copy_default_228]\n",
      "      %aten_permute_copy_default_119 : [num_users=1] = placeholder[target=aten_permute_copy_default_119]\n",
      "      %aten_addmm_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_bias, %aten_view_copy_default_228, %aten_permute_copy_default_119), kwargs = {})\n",
      "      return (aten_addmm_default_63,)\n",
      "  %executorch_call_delegate_41 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_41, %aten_view_copy_default_228, %aten_permute_copy_default_63), kwargs = {})\n",
      "  %getitem_85 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_41, 0), kwargs = {})\n",
      "  %aten_view_copy_default_229 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_85, [1, %sym_size_29, 1024]), kwargs = {})\n",
      "  %alloc_445 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_21 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_20, %aten_view_copy_default_229), kwargs = {out: %alloc_445})\n",
      "  %alloc_446 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_447 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_448 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_22 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_21, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_446, out1: %alloc_447, out2: %alloc_448})\n",
      "  %getitem_86 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_22, 0), kwargs = {})\n",
      "  %aten_view_copy_default_230 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_86, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_42 : [num_users=1] = get_attr[target=lowered_module_42]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_230 : [num_users=1] = placeholder[target=aten_view_copy_default_230]\n",
      "      %aten_permute_copy_default_120 : [num_users=1] = placeholder[target=aten_permute_copy_default_120]\n",
      "      %aten_addmm_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_bias, %aten_view_copy_default_230, %aten_permute_copy_default_120), kwargs = {})\n",
      "      return (aten_addmm_default_64,)\n",
      "  %executorch_call_delegate_42 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_42, %aten_view_copy_default_230, %aten_permute_copy_default_64), kwargs = {})\n",
      "  %getitem_87 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_42, 0), kwargs = {})\n",
      "  %aten_view_copy_default_231 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_87, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_449 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_32 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_231, %_lifted_tensor_constant26), kwargs = {out: %alloc_449})\n",
      "  %sym_size_30 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_231, 1), kwargs = {})\n",
      "  %alloc_450 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_10 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_32,), kwargs = {out: %alloc_450})\n",
      "  %alloc_451 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_33 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_231, %aten_sigmoid_default_10), kwargs = {out: %alloc_451})\n",
      "  %aten_view_copy_default_232 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_33, [%sym_size_30, 4096]), kwargs = {})\n",
      "  %lowered_module_43 : [num_users=1] = get_attr[target=lowered_module_43]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_232 : [num_users=1] = placeholder[target=aten_view_copy_default_232]\n",
      "      %aten_permute_copy_default_121 : [num_users=1] = placeholder[target=aten_permute_copy_default_121]\n",
      "      %aten_addmm_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_bias, %aten_view_copy_default_232, %aten_permute_copy_default_121), kwargs = {})\n",
      "      return (aten_addmm_default_65,)\n",
      "  %executorch_call_delegate_43 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_43, %aten_view_copy_default_232, %aten_permute_copy_default_65), kwargs = {})\n",
      "  %getitem_88 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_43, 0), kwargs = {})\n",
      "  %aten_view_copy_default_233 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_88, [1, %sym_size_30, 1024]), kwargs = {})\n",
      "  %alloc_452 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_22 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_21, %aten_view_copy_default_233), kwargs = {out: %alloc_452})\n",
      "  %alloc_453 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_454 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_455 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_23 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_22, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_453, out1: %alloc_454, out2: %alloc_455})\n",
      "  %getitem_89 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_23, 0), kwargs = {})\n",
      "  %aten_view_copy_default_234 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_89, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_235 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_89, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_236 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_89, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_44 : [num_users=1] = get_attr[target=lowered_module_44]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_236 : [num_users=1] = placeholder[target=aten_view_copy_default_236]\n",
      "      %aten_permute_copy_default_123 : [num_users=1] = placeholder[target=aten_permute_copy_default_123]\n",
      "      %aten_view_copy_default_239 : [num_users=1] = placeholder[target=aten_view_copy_default_239]\n",
      "      %aten_permute_copy_default_125 : [num_users=1] = placeholder[target=aten_permute_copy_default_125]\n",
      "      %aten_view_copy_default_234 : [num_users=1] = placeholder[target=aten_view_copy_default_234]\n",
      "      %aten_permute_copy_default_122 : [num_users=1] = placeholder[target=aten_permute_copy_default_122]\n",
      "      %aten_addmm_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_bias, %aten_view_copy_default_236, %aten_permute_copy_default_123), kwargs = {})\n",
      "      %aten_addmm_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_bias, %aten_view_copy_default_239, %aten_permute_copy_default_125), kwargs = {})\n",
      "      %aten_addmm_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_bias, %aten_view_copy_default_234, %aten_permute_copy_default_122), kwargs = {})\n",
      "      return (aten_addmm_default_67, aten_addmm_default_68, aten_addmm_default_66)\n",
      "  %executorch_call_delegate_44 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_44, %aten_view_copy_default_235, %aten_permute_copy_default_66, %aten_view_copy_default_236, %aten_permute_copy_default_67, %aten_view_copy_default_234, %aten_permute_copy_default_68), kwargs = {})\n",
      "  %getitem_90 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_44, 0), kwargs = {})\n",
      "  %getitem_91 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_44, 1), kwargs = {})\n",
      "  %getitem_92 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_44, 2), kwargs = {})\n",
      "  %aten_view_copy_default_239 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_92, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_240 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_90, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_241 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_91, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_456 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_34 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_239, %_lifted_tensor_constant27), kwargs = {out: %alloc_456})\n",
      "  %sym_size_31 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_239, 1), kwargs = {})\n",
      "  %alloc_457 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_196 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_240, [0, 2, 1, 3]), kwargs = {out: %alloc_457})\n",
      "  %alloc_458 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_197 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_241, [0, 2, 1, 3]), kwargs = {out: %alloc_458})\n",
      "  %aten_view_copy_default_242 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_34, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_459 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_58 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_196,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_459})\n",
      "  %alloc_460 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_59 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_197,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_460})\n",
      "  %alloc_461 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_198 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_242, [0, 2, 1, 3]), kwargs = {out: %alloc_461})\n",
      "  %aten_view_copy_default_243 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_58, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_244 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_59, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_462 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_60 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_198,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_462})\n",
      "  %alloc_463 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_199 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_243, [0, 2, 1]), kwargs = {out: %alloc_463})\n",
      "  %aten_view_copy_default_245 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_60, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_464 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_22 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_245, %aten_permute_copy_default_199), kwargs = {out: %alloc_464})\n",
      "  %alloc_465 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_11 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_22, -1, False), kwargs = {out: %alloc_465})\n",
      "  %alloc_466 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_61 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_11,), kwargs = {out: %alloc_466})\n",
      "  %alloc_467 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_23 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_61, %aten_view_copy_default_244), kwargs = {out: %alloc_467})\n",
      "  %aten_view_copy_default_246 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_23, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_468 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_200 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_246, [0, 2, 1, 3]), kwargs = {out: %alloc_468})\n",
      "  %alloc_469 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_62 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_200,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_469})\n",
      "  %aten_view_copy_default_248 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_62, [%sym_size_31, 1024]), kwargs = {})\n",
      "  %lowered_module_45 : [num_users=1] = get_attr[target=lowered_module_45]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_248 : [num_users=1] = placeholder[target=aten_view_copy_default_248]\n",
      "      %aten_permute_copy_default_130 : [num_users=1] = placeholder[target=aten_permute_copy_default_130]\n",
      "      %aten_addmm_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_bias, %aten_view_copy_default_248, %aten_permute_copy_default_130), kwargs = {})\n",
      "      return (aten_addmm_default_69,)\n",
      "  %executorch_call_delegate_45 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_45, %aten_view_copy_default_248, %aten_permute_copy_default_69), kwargs = {})\n",
      "  %getitem_93 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_45, 0), kwargs = {})\n",
      "  %aten_view_copy_default_249 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_93, [1, %sym_size_31, 1024]), kwargs = {})\n",
      "  %alloc_470 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_23 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_22, %aten_view_copy_default_249), kwargs = {out: %alloc_470})\n",
      "  %alloc_471 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_472 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_473 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_24 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_23, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_471, out1: %alloc_472, out2: %alloc_473})\n",
      "  %getitem_94 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_24, 0), kwargs = {})\n",
      "  %aten_view_copy_default_250 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_94, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_46 : [num_users=1] = get_attr[target=lowered_module_46]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_250 : [num_users=1] = placeholder[target=aten_view_copy_default_250]\n",
      "      %aten_permute_copy_default_131 : [num_users=1] = placeholder[target=aten_permute_copy_default_131]\n",
      "      %aten_addmm_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_bias, %aten_view_copy_default_250, %aten_permute_copy_default_131), kwargs = {})\n",
      "      return (aten_addmm_default_70,)\n",
      "  %executorch_call_delegate_46 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_46, %aten_view_copy_default_250, %aten_permute_copy_default_70), kwargs = {})\n",
      "  %getitem_95 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_46, 0), kwargs = {})\n",
      "  %aten_view_copy_default_251 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_95, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_474 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_35 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_251, %_lifted_tensor_constant28), kwargs = {out: %alloc_474})\n",
      "  %sym_size_32 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_251, 1), kwargs = {})\n",
      "  %alloc_475 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_11 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_35,), kwargs = {out: %alloc_475})\n",
      "  %alloc_476 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_36 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_251, %aten_sigmoid_default_11), kwargs = {out: %alloc_476})\n",
      "  %aten_view_copy_default_252 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_36, [%sym_size_32, 4096]), kwargs = {})\n",
      "  %lowered_module_47 : [num_users=1] = get_attr[target=lowered_module_47]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_252 : [num_users=1] = placeholder[target=aten_view_copy_default_252]\n",
      "      %aten_permute_copy_default_132 : [num_users=1] = placeholder[target=aten_permute_copy_default_132]\n",
      "      %aten_addmm_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_bias, %aten_view_copy_default_252, %aten_permute_copy_default_132), kwargs = {})\n",
      "      return (aten_addmm_default_71,)\n",
      "  %executorch_call_delegate_47 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_47, %aten_view_copy_default_252, %aten_permute_copy_default_71), kwargs = {})\n",
      "  %getitem_96 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_47, 0), kwargs = {})\n",
      "  %aten_view_copy_default_253 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_96, [1, %sym_size_32, 1024]), kwargs = {})\n",
      "  %alloc_477 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_24 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_23, %aten_view_copy_default_253), kwargs = {out: %alloc_477})\n",
      "  %alloc_478 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_479 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_480 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_25 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_24, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_478, out1: %alloc_479, out2: %alloc_480})\n",
      "  %getitem_97 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_25, 0), kwargs = {})\n",
      "  %aten_view_copy_default_254 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_97, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_255 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_97, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_256 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_97, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_48 : [num_users=1] = get_attr[target=lowered_module_48]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_256 : [num_users=1] = placeholder[target=aten_view_copy_default_256]\n",
      "      %aten_permute_copy_default_134 : [num_users=1] = placeholder[target=aten_permute_copy_default_134]\n",
      "      %aten_view_copy_default_259 : [num_users=1] = placeholder[target=aten_view_copy_default_259]\n",
      "      %aten_permute_copy_default_136 : [num_users=1] = placeholder[target=aten_permute_copy_default_136]\n",
      "      %aten_view_copy_default_254 : [num_users=1] = placeholder[target=aten_view_copy_default_254]\n",
      "      %aten_permute_copy_default_133 : [num_users=1] = placeholder[target=aten_permute_copy_default_133]\n",
      "      %aten_addmm_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_bias, %aten_view_copy_default_256, %aten_permute_copy_default_134), kwargs = {})\n",
      "      %aten_addmm_default_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_bias, %aten_view_copy_default_259, %aten_permute_copy_default_136), kwargs = {})\n",
      "      %aten_addmm_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_bias, %aten_view_copy_default_254, %aten_permute_copy_default_133), kwargs = {})\n",
      "      return (aten_addmm_default_73, aten_addmm_default_74, aten_addmm_default_72)\n",
      "  %executorch_call_delegate_48 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_48, %aten_view_copy_default_255, %aten_permute_copy_default_72, %aten_view_copy_default_256, %aten_permute_copy_default_73, %aten_view_copy_default_254, %aten_permute_copy_default_74), kwargs = {})\n",
      "  %getitem_98 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_48, 0), kwargs = {})\n",
      "  %getitem_99 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_48, 1), kwargs = {})\n",
      "  %getitem_100 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_48, 2), kwargs = {})\n",
      "  %aten_view_copy_default_259 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_100, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_260 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_98, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_261 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_99, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_481 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_37 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_259, %_lifted_tensor_constant29), kwargs = {out: %alloc_481})\n",
      "  %sym_size_33 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_259, 1), kwargs = {})\n",
      "  %alloc_482 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_201 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_260, [0, 2, 1, 3]), kwargs = {out: %alloc_482})\n",
      "  %alloc_483 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_202 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_261, [0, 2, 1, 3]), kwargs = {out: %alloc_483})\n",
      "  %aten_view_copy_default_262 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_37, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_484 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_63 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_201,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_484})\n",
      "  %alloc_485 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_64 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_202,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_485})\n",
      "  %alloc_486 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_203 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_262, [0, 2, 1, 3]), kwargs = {out: %alloc_486})\n",
      "  %aten_view_copy_default_263 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_63, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_264 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_64, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_487 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_65 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_203,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_487})\n",
      "  %alloc_488 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_204 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_263, [0, 2, 1]), kwargs = {out: %alloc_488})\n",
      "  %aten_view_copy_default_265 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_65, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_489 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_24 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_265, %aten_permute_copy_default_204), kwargs = {out: %alloc_489})\n",
      "  %alloc_490 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_12 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_24, -1, False), kwargs = {out: %alloc_490})\n",
      "  %alloc_491 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_66 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_12,), kwargs = {out: %alloc_491})\n",
      "  %alloc_492 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_25 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_66, %aten_view_copy_default_264), kwargs = {out: %alloc_492})\n",
      "  %aten_view_copy_default_266 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_25, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_493 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_205 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_266, [0, 2, 1, 3]), kwargs = {out: %alloc_493})\n",
      "  %alloc_494 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_67 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_205,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_494})\n",
      "  %aten_view_copy_default_268 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_67, [%sym_size_33, 1024]), kwargs = {})\n",
      "  %lowered_module_49 : [num_users=1] = get_attr[target=lowered_module_49]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_268 : [num_users=1] = placeholder[target=aten_view_copy_default_268]\n",
      "      %aten_permute_copy_default_141 : [num_users=1] = placeholder[target=aten_permute_copy_default_141]\n",
      "      %aten_addmm_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_bias, %aten_view_copy_default_268, %aten_permute_copy_default_141), kwargs = {})\n",
      "      return (aten_addmm_default_75,)\n",
      "  %executorch_call_delegate_49 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_49, %aten_view_copy_default_268, %aten_permute_copy_default_75), kwargs = {})\n",
      "  %getitem_101 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_49, 0), kwargs = {})\n",
      "  %aten_view_copy_default_269 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_101, [1, %sym_size_33, 1024]), kwargs = {})\n",
      "  %alloc_495 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_25 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_24, %aten_view_copy_default_269), kwargs = {out: %alloc_495})\n",
      "  %alloc_496 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_497 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_498 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_26 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_25, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_496, out1: %alloc_497, out2: %alloc_498})\n",
      "  %getitem_102 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_26, 0), kwargs = {})\n",
      "  %aten_view_copy_default_270 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_102, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_50 : [num_users=1] = get_attr[target=lowered_module_50]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_270 : [num_users=1] = placeholder[target=aten_view_copy_default_270]\n",
      "      %aten_permute_copy_default_142 : [num_users=1] = placeholder[target=aten_permute_copy_default_142]\n",
      "      %aten_addmm_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_bias, %aten_view_copy_default_270, %aten_permute_copy_default_142), kwargs = {})\n",
      "      return (aten_addmm_default_76,)\n",
      "  %executorch_call_delegate_50 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_50, %aten_view_copy_default_270, %aten_permute_copy_default_76), kwargs = {})\n",
      "  %getitem_103 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_50, 0), kwargs = {})\n",
      "  %aten_view_copy_default_271 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_103, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_499 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_38 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_271, %_lifted_tensor_constant30), kwargs = {out: %alloc_499})\n",
      "  %sym_size_34 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_271, 1), kwargs = {})\n",
      "  %alloc_500 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_12 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_38,), kwargs = {out: %alloc_500})\n",
      "  %alloc_501 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_39 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_271, %aten_sigmoid_default_12), kwargs = {out: %alloc_501})\n",
      "  %aten_view_copy_default_272 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_39, [%sym_size_34, 4096]), kwargs = {})\n",
      "  %lowered_module_51 : [num_users=1] = get_attr[target=lowered_module_51]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_272 : [num_users=1] = placeholder[target=aten_view_copy_default_272]\n",
      "      %aten_permute_copy_default_143 : [num_users=1] = placeholder[target=aten_permute_copy_default_143]\n",
      "      %aten_addmm_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_bias, %aten_view_copy_default_272, %aten_permute_copy_default_143), kwargs = {})\n",
      "      return (aten_addmm_default_77,)\n",
      "  %executorch_call_delegate_51 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_51, %aten_view_copy_default_272, %aten_permute_copy_default_77), kwargs = {})\n",
      "  %getitem_104 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_51, 0), kwargs = {})\n",
      "  %aten_view_copy_default_273 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_104, [1, %sym_size_34, 1024]), kwargs = {})\n",
      "  %alloc_502 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_26 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_25, %aten_view_copy_default_273), kwargs = {out: %alloc_502})\n",
      "  %alloc_503 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_504 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_505 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_27 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_26, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_503, out1: %alloc_504, out2: %alloc_505})\n",
      "  %getitem_105 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_27, 0), kwargs = {})\n",
      "  %aten_view_copy_default_274 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_105, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_275 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_105, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_276 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_105, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_52 : [num_users=1] = get_attr[target=lowered_module_52]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_276 : [num_users=1] = placeholder[target=aten_view_copy_default_276]\n",
      "      %aten_permute_copy_default_145 : [num_users=1] = placeholder[target=aten_permute_copy_default_145]\n",
      "      %aten_view_copy_default_279 : [num_users=1] = placeholder[target=aten_view_copy_default_279]\n",
      "      %aten_permute_copy_default_147 : [num_users=1] = placeholder[target=aten_permute_copy_default_147]\n",
      "      %aten_view_copy_default_274 : [num_users=1] = placeholder[target=aten_view_copy_default_274]\n",
      "      %aten_permute_copy_default_144 : [num_users=1] = placeholder[target=aten_permute_copy_default_144]\n",
      "      %aten_addmm_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_bias, %aten_view_copy_default_276, %aten_permute_copy_default_145), kwargs = {})\n",
      "      %aten_addmm_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_bias, %aten_view_copy_default_279, %aten_permute_copy_default_147), kwargs = {})\n",
      "      %aten_addmm_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_bias, %aten_view_copy_default_274, %aten_permute_copy_default_144), kwargs = {})\n",
      "      return (aten_addmm_default_79, aten_addmm_default_80, aten_addmm_default_78)\n",
      "  %executorch_call_delegate_52 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_52, %aten_view_copy_default_275, %aten_permute_copy_default_78, %aten_view_copy_default_276, %aten_permute_copy_default_79, %aten_view_copy_default_274, %aten_permute_copy_default_80), kwargs = {})\n",
      "  %getitem_106 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_52, 0), kwargs = {})\n",
      "  %getitem_107 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_52, 1), kwargs = {})\n",
      "  %getitem_108 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_52, 2), kwargs = {})\n",
      "  %aten_view_copy_default_279 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_108, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_280 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_106, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_281 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_107, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_506 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_40 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_279, %_lifted_tensor_constant31), kwargs = {out: %alloc_506})\n",
      "  %sym_size_35 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_279, 1), kwargs = {})\n",
      "  %alloc_507 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_206 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_280, [0, 2, 1, 3]), kwargs = {out: %alloc_507})\n",
      "  %alloc_508 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_207 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_281, [0, 2, 1, 3]), kwargs = {out: %alloc_508})\n",
      "  %aten_view_copy_default_282 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_40, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_509 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_68 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_206,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_509})\n",
      "  %alloc_510 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_69 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_207,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_510})\n",
      "  %alloc_511 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_208 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_282, [0, 2, 1, 3]), kwargs = {out: %alloc_511})\n",
      "  %aten_view_copy_default_283 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_68, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_284 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_69, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_512 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_70 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_208,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_512})\n",
      "  %alloc_513 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_209 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_283, [0, 2, 1]), kwargs = {out: %alloc_513})\n",
      "  %aten_view_copy_default_285 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_70, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_514 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_26 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_285, %aten_permute_copy_default_209), kwargs = {out: %alloc_514})\n",
      "  %alloc_515 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_13 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_26, -1, False), kwargs = {out: %alloc_515})\n",
      "  %alloc_516 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_71 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_13,), kwargs = {out: %alloc_516})\n",
      "  %alloc_517 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_27 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_71, %aten_view_copy_default_284), kwargs = {out: %alloc_517})\n",
      "  %aten_view_copy_default_286 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_27, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_518 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_210 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_286, [0, 2, 1, 3]), kwargs = {out: %alloc_518})\n",
      "  %alloc_519 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_72 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_210,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_519})\n",
      "  %aten_view_copy_default_288 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_72, [%sym_size_35, 1024]), kwargs = {})\n",
      "  %lowered_module_53 : [num_users=1] = get_attr[target=lowered_module_53]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_288 : [num_users=1] = placeholder[target=aten_view_copy_default_288]\n",
      "      %aten_permute_copy_default_152 : [num_users=1] = placeholder[target=aten_permute_copy_default_152]\n",
      "      %aten_addmm_default_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_bias, %aten_view_copy_default_288, %aten_permute_copy_default_152), kwargs = {})\n",
      "      return (aten_addmm_default_81,)\n",
      "  %executorch_call_delegate_53 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_53, %aten_view_copy_default_288, %aten_permute_copy_default_81), kwargs = {})\n",
      "  %getitem_109 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_53, 0), kwargs = {})\n",
      "  %aten_view_copy_default_289 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_109, [1, %sym_size_35, 1024]), kwargs = {})\n",
      "  %alloc_520 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_27 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_26, %aten_view_copy_default_289), kwargs = {out: %alloc_520})\n",
      "  %alloc_521 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_522 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_523 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_28 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_27, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_521, out1: %alloc_522, out2: %alloc_523})\n",
      "  %getitem_110 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_28, 0), kwargs = {})\n",
      "  %aten_view_copy_default_290 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_110, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_54 : [num_users=1] = get_attr[target=lowered_module_54]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_290 : [num_users=1] = placeholder[target=aten_view_copy_default_290]\n",
      "      %aten_permute_copy_default_153 : [num_users=1] = placeholder[target=aten_permute_copy_default_153]\n",
      "      %aten_addmm_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_bias, %aten_view_copy_default_290, %aten_permute_copy_default_153), kwargs = {})\n",
      "      return (aten_addmm_default_82,)\n",
      "  %executorch_call_delegate_54 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_54, %aten_view_copy_default_290, %aten_permute_copy_default_82), kwargs = {})\n",
      "  %getitem_111 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_54, 0), kwargs = {})\n",
      "  %aten_view_copy_default_291 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_111, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_524 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_41 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_291, %_lifted_tensor_constant32), kwargs = {out: %alloc_524})\n",
      "  %sym_size_36 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_291, 1), kwargs = {})\n",
      "  %alloc_525 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_13 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_41,), kwargs = {out: %alloc_525})\n",
      "  %alloc_526 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_42 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_291, %aten_sigmoid_default_13), kwargs = {out: %alloc_526})\n",
      "  %aten_view_copy_default_292 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_42, [%sym_size_36, 4096]), kwargs = {})\n",
      "  %lowered_module_55 : [num_users=1] = get_attr[target=lowered_module_55]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_292 : [num_users=1] = placeholder[target=aten_view_copy_default_292]\n",
      "      %aten_permute_copy_default_154 : [num_users=1] = placeholder[target=aten_permute_copy_default_154]\n",
      "      %aten_addmm_default_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_bias, %aten_view_copy_default_292, %aten_permute_copy_default_154), kwargs = {})\n",
      "      return (aten_addmm_default_83,)\n",
      "  %executorch_call_delegate_55 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_55, %aten_view_copy_default_292, %aten_permute_copy_default_83), kwargs = {})\n",
      "  %getitem_112 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_55, 0), kwargs = {})\n",
      "  %aten_view_copy_default_293 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_112, [1, %sym_size_36, 1024]), kwargs = {})\n",
      "  %alloc_527 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_28 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_27, %aten_view_copy_default_293), kwargs = {out: %alloc_527})\n",
      "  %alloc_528 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_529 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_530 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_29 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_28, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_528, out1: %alloc_529, out2: %alloc_530})\n",
      "  %getitem_113 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_29, 0), kwargs = {})\n",
      "  %aten_view_copy_default_294 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_113, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_295 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_113, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_296 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_113, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_56 : [num_users=1] = get_attr[target=lowered_module_56]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_296 : [num_users=1] = placeholder[target=aten_view_copy_default_296]\n",
      "      %aten_permute_copy_default_156 : [num_users=1] = placeholder[target=aten_permute_copy_default_156]\n",
      "      %aten_view_copy_default_299 : [num_users=1] = placeholder[target=aten_view_copy_default_299]\n",
      "      %aten_permute_copy_default_158 : [num_users=1] = placeholder[target=aten_permute_copy_default_158]\n",
      "      %aten_view_copy_default_294 : [num_users=1] = placeholder[target=aten_view_copy_default_294]\n",
      "      %aten_permute_copy_default_155 : [num_users=1] = placeholder[target=aten_permute_copy_default_155]\n",
      "      %aten_addmm_default_85 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_bias, %aten_view_copy_default_296, %aten_permute_copy_default_156), kwargs = {})\n",
      "      %aten_addmm_default_86 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_bias, %aten_view_copy_default_299, %aten_permute_copy_default_158), kwargs = {})\n",
      "      %aten_addmm_default_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_bias, %aten_view_copy_default_294, %aten_permute_copy_default_155), kwargs = {})\n",
      "      return (aten_addmm_default_85, aten_addmm_default_86, aten_addmm_default_84)\n",
      "  %executorch_call_delegate_56 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_56, %aten_view_copy_default_295, %aten_permute_copy_default_84, %aten_view_copy_default_296, %aten_permute_copy_default_85, %aten_view_copy_default_294, %aten_permute_copy_default_86), kwargs = {})\n",
      "  %getitem_114 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_56, 0), kwargs = {})\n",
      "  %getitem_115 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_56, 1), kwargs = {})\n",
      "  %getitem_116 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_56, 2), kwargs = {})\n",
      "  %aten_view_copy_default_299 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_116, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_300 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_114, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_301 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_115, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_531 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_43 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_299, %_lifted_tensor_constant33), kwargs = {out: %alloc_531})\n",
      "  %sym_size_37 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_299, 1), kwargs = {})\n",
      "  %alloc_532 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_211 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_300, [0, 2, 1, 3]), kwargs = {out: %alloc_532})\n",
      "  %alloc_533 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_212 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_301, [0, 2, 1, 3]), kwargs = {out: %alloc_533})\n",
      "  %aten_view_copy_default_302 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_43, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_534 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_73 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_211,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_534})\n",
      "  %alloc_535 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_74 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_212,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_535})\n",
      "  %alloc_536 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_213 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_302, [0, 2, 1, 3]), kwargs = {out: %alloc_536})\n",
      "  %aten_view_copy_default_303 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_73, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_304 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_74, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_537 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_75 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_213,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_537})\n",
      "  %alloc_538 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_214 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_303, [0, 2, 1]), kwargs = {out: %alloc_538})\n",
      "  %aten_view_copy_default_305 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_75, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_539 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_28 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_305, %aten_permute_copy_default_214), kwargs = {out: %alloc_539})\n",
      "  %alloc_540 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_14 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_28, -1, False), kwargs = {out: %alloc_540})\n",
      "  %alloc_541 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_76 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_14,), kwargs = {out: %alloc_541})\n",
      "  %alloc_542 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_29 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_76, %aten_view_copy_default_304), kwargs = {out: %alloc_542})\n",
      "  %aten_view_copy_default_306 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_29, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_543 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_215 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_306, [0, 2, 1, 3]), kwargs = {out: %alloc_543})\n",
      "  %alloc_544 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_77 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_215,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_544})\n",
      "  %aten_view_copy_default_308 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_77, [%sym_size_37, 1024]), kwargs = {})\n",
      "  %lowered_module_57 : [num_users=1] = get_attr[target=lowered_module_57]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_308 : [num_users=1] = placeholder[target=aten_view_copy_default_308]\n",
      "      %aten_permute_copy_default_163 : [num_users=1] = placeholder[target=aten_permute_copy_default_163]\n",
      "      %aten_addmm_default_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_bias, %aten_view_copy_default_308, %aten_permute_copy_default_163), kwargs = {})\n",
      "      return (aten_addmm_default_87,)\n",
      "  %executorch_call_delegate_57 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_57, %aten_view_copy_default_308, %aten_permute_copy_default_87), kwargs = {})\n",
      "  %getitem_117 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_57, 0), kwargs = {})\n",
      "  %aten_view_copy_default_309 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_117, [1, %sym_size_37, 1024]), kwargs = {})\n",
      "  %alloc_545 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_29 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_28, %aten_view_copy_default_309), kwargs = {out: %alloc_545})\n",
      "  %alloc_546 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_547 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_548 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_30 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_29, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_546, out1: %alloc_547, out2: %alloc_548})\n",
      "  %getitem_118 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_30, 0), kwargs = {})\n",
      "  %aten_view_copy_default_310 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_118, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_58 : [num_users=1] = get_attr[target=lowered_module_58]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_310 : [num_users=1] = placeholder[target=aten_view_copy_default_310]\n",
      "      %aten_permute_copy_default_164 : [num_users=1] = placeholder[target=aten_permute_copy_default_164]\n",
      "      %aten_addmm_default_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_bias, %aten_view_copy_default_310, %aten_permute_copy_default_164), kwargs = {})\n",
      "      return (aten_addmm_default_88,)\n",
      "  %executorch_call_delegate_58 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_58, %aten_view_copy_default_310, %aten_permute_copy_default_88), kwargs = {})\n",
      "  %getitem_119 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_58, 0), kwargs = {})\n",
      "  %aten_view_copy_default_311 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_119, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_549 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_44 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_311, %_lifted_tensor_constant34), kwargs = {out: %alloc_549})\n",
      "  %sym_size_38 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_311, 1), kwargs = {})\n",
      "  %alloc_550 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_14 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_44,), kwargs = {out: %alloc_550})\n",
      "  %alloc_551 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_45 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_311, %aten_sigmoid_default_14), kwargs = {out: %alloc_551})\n",
      "  %aten_view_copy_default_312 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_45, [%sym_size_38, 4096]), kwargs = {})\n",
      "  %lowered_module_59 : [num_users=1] = get_attr[target=lowered_module_59]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_312 : [num_users=1] = placeholder[target=aten_view_copy_default_312]\n",
      "      %aten_permute_copy_default_165 : [num_users=1] = placeholder[target=aten_permute_copy_default_165]\n",
      "      %aten_addmm_default_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_bias, %aten_view_copy_default_312, %aten_permute_copy_default_165), kwargs = {})\n",
      "      return (aten_addmm_default_89,)\n",
      "  %executorch_call_delegate_59 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_59, %aten_view_copy_default_312, %aten_permute_copy_default_89), kwargs = {})\n",
      "  %getitem_120 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_59, 0), kwargs = {})\n",
      "  %aten_view_copy_default_313 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_120, [1, %sym_size_38, 1024]), kwargs = {})\n",
      "  %alloc_552 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_30 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_29, %aten_view_copy_default_313), kwargs = {out: %alloc_552})\n",
      "  %alloc_553 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_554 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_555 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_31 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_30, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_553, out1: %alloc_554, out2: %alloc_555})\n",
      "  %getitem_121 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_31, 0), kwargs = {})\n",
      "  %aten_view_copy_default_314 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_121, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_315 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_121, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_316 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_121, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_60 : [num_users=1] = get_attr[target=lowered_module_60]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_316 : [num_users=1] = placeholder[target=aten_view_copy_default_316]\n",
      "      %aten_permute_copy_default_167 : [num_users=1] = placeholder[target=aten_permute_copy_default_167]\n",
      "      %aten_view_copy_default_319 : [num_users=1] = placeholder[target=aten_view_copy_default_319]\n",
      "      %aten_permute_copy_default_169 : [num_users=1] = placeholder[target=aten_permute_copy_default_169]\n",
      "      %aten_view_copy_default_314 : [num_users=1] = placeholder[target=aten_view_copy_default_314]\n",
      "      %aten_permute_copy_default_166 : [num_users=1] = placeholder[target=aten_permute_copy_default_166]\n",
      "      %aten_addmm_default_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_bias, %aten_view_copy_default_316, %aten_permute_copy_default_167), kwargs = {})\n",
      "      %aten_addmm_default_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_bias, %aten_view_copy_default_319, %aten_permute_copy_default_169), kwargs = {})\n",
      "      %aten_addmm_default_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_bias, %aten_view_copy_default_314, %aten_permute_copy_default_166), kwargs = {})\n",
      "      return (aten_addmm_default_91, aten_addmm_default_92, aten_addmm_default_90)\n",
      "  %executorch_call_delegate_60 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_60, %aten_view_copy_default_315, %aten_permute_copy_default_90, %aten_view_copy_default_316, %aten_permute_copy_default_91, %aten_view_copy_default_314, %aten_permute_copy_default_92), kwargs = {})\n",
      "  %getitem_122 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_60, 0), kwargs = {})\n",
      "  %getitem_123 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_60, 1), kwargs = {})\n",
      "  %getitem_124 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_60, 2), kwargs = {})\n",
      "  %aten_view_copy_default_319 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_124, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_320 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_122, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_321 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_123, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_556 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_46 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_319, %_lifted_tensor_constant35), kwargs = {out: %alloc_556})\n",
      "  %sym_size_39 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_319, 1), kwargs = {})\n",
      "  %alloc_557 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_216 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_320, [0, 2, 1, 3]), kwargs = {out: %alloc_557})\n",
      "  %alloc_558 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_217 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_321, [0, 2, 1, 3]), kwargs = {out: %alloc_558})\n",
      "  %aten_view_copy_default_322 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_46, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_559 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_78 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_216,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_559})\n",
      "  %alloc_560 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_79 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_217,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_560})\n",
      "  %alloc_561 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_218 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_322, [0, 2, 1, 3]), kwargs = {out: %alloc_561})\n",
      "  %aten_view_copy_default_323 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_78, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_324 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_79, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_562 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_80 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_218,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_562})\n",
      "  %alloc_563 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_219 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_323, [0, 2, 1]), kwargs = {out: %alloc_563})\n",
      "  %aten_view_copy_default_325 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_80, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_564 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_30 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_325, %aten_permute_copy_default_219), kwargs = {out: %alloc_564})\n",
      "  %alloc_565 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_15 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_30, -1, False), kwargs = {out: %alloc_565})\n",
      "  %alloc_566 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_81 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_15,), kwargs = {out: %alloc_566})\n",
      "  %alloc_567 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_31 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_81, %aten_view_copy_default_324), kwargs = {out: %alloc_567})\n",
      "  %aten_view_copy_default_326 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_31, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_568 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_220 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_326, [0, 2, 1, 3]), kwargs = {out: %alloc_568})\n",
      "  %alloc_569 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_82 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_220,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_569})\n",
      "  %aten_view_copy_default_328 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_82, [%sym_size_39, 1024]), kwargs = {})\n",
      "  %lowered_module_61 : [num_users=1] = get_attr[target=lowered_module_61]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_328 : [num_users=1] = placeholder[target=aten_view_copy_default_328]\n",
      "      %aten_permute_copy_default_174 : [num_users=1] = placeholder[target=aten_permute_copy_default_174]\n",
      "      %aten_addmm_default_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_bias, %aten_view_copy_default_328, %aten_permute_copy_default_174), kwargs = {})\n",
      "      return (aten_addmm_default_93,)\n",
      "  %executorch_call_delegate_61 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_61, %aten_view_copy_default_328, %aten_permute_copy_default_93), kwargs = {})\n",
      "  %getitem_125 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_61, 0), kwargs = {})\n",
      "  %aten_view_copy_default_329 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_125, [1, %sym_size_39, 1024]), kwargs = {})\n",
      "  %alloc_570 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_31 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_30, %aten_view_copy_default_329), kwargs = {out: %alloc_570})\n",
      "  %alloc_571 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_572 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_573 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_32 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_31, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_571, out1: %alloc_572, out2: %alloc_573})\n",
      "  %getitem_126 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_32, 0), kwargs = {})\n",
      "  %aten_view_copy_default_330 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_126, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_62 : [num_users=1] = get_attr[target=lowered_module_62]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_330 : [num_users=1] = placeholder[target=aten_view_copy_default_330]\n",
      "      %aten_permute_copy_default_175 : [num_users=1] = placeholder[target=aten_permute_copy_default_175]\n",
      "      %aten_addmm_default_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_bias, %aten_view_copy_default_330, %aten_permute_copy_default_175), kwargs = {})\n",
      "      return (aten_addmm_default_94,)\n",
      "  %executorch_call_delegate_62 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_62, %aten_view_copy_default_330, %aten_permute_copy_default_94), kwargs = {})\n",
      "  %getitem_127 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_62, 0), kwargs = {})\n",
      "  %aten_view_copy_default_331 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_127, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_574 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_47 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_331, %_lifted_tensor_constant36), kwargs = {out: %alloc_574})\n",
      "  %sym_size_40 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_331, 1), kwargs = {})\n",
      "  %alloc_575 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_15 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_47,), kwargs = {out: %alloc_575})\n",
      "  %alloc_576 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_48 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_331, %aten_sigmoid_default_15), kwargs = {out: %alloc_576})\n",
      "  %aten_view_copy_default_332 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_48, [%sym_size_40, 4096]), kwargs = {})\n",
      "  %lowered_module_63 : [num_users=1] = get_attr[target=lowered_module_63]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_332 : [num_users=1] = placeholder[target=aten_view_copy_default_332]\n",
      "      %aten_permute_copy_default_176 : [num_users=1] = placeholder[target=aten_permute_copy_default_176]\n",
      "      %aten_addmm_default_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_bias, %aten_view_copy_default_332, %aten_permute_copy_default_176), kwargs = {})\n",
      "      return (aten_addmm_default_95,)\n",
      "  %executorch_call_delegate_63 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_63, %aten_view_copy_default_332, %aten_permute_copy_default_95), kwargs = {})\n",
      "  %getitem_128 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_63, 0), kwargs = {})\n",
      "  %aten_view_copy_default_333 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_128, [1, %sym_size_40, 1024]), kwargs = {})\n",
      "  %alloc_577 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_32 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_31, %aten_view_copy_default_333), kwargs = {out: %alloc_577})\n",
      "  %alloc_578 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_579 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_580 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_33 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_32, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_578, out1: %alloc_579, out2: %alloc_580})\n",
      "  %getitem_129 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_33, 0), kwargs = {})\n",
      "  %aten_view_copy_default_334 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_129, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_335 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_129, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_336 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_129, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_64 : [num_users=1] = get_attr[target=lowered_module_64]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_336 : [num_users=1] = placeholder[target=aten_view_copy_default_336]\n",
      "      %aten_permute_copy_default_178 : [num_users=1] = placeholder[target=aten_permute_copy_default_178]\n",
      "      %aten_view_copy_default_339 : [num_users=1] = placeholder[target=aten_view_copy_default_339]\n",
      "      %aten_permute_copy_default_180 : [num_users=1] = placeholder[target=aten_permute_copy_default_180]\n",
      "      %aten_view_copy_default_334 : [num_users=1] = placeholder[target=aten_view_copy_default_334]\n",
      "      %aten_permute_copy_default_177 : [num_users=1] = placeholder[target=aten_permute_copy_default_177]\n",
      "      %aten_addmm_default_97 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_bias, %aten_view_copy_default_336, %aten_permute_copy_default_178), kwargs = {})\n",
      "      %aten_addmm_default_98 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_bias, %aten_view_copy_default_339, %aten_permute_copy_default_180), kwargs = {})\n",
      "      %aten_addmm_default_96 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_bias, %aten_view_copy_default_334, %aten_permute_copy_default_177), kwargs = {})\n",
      "      return (aten_addmm_default_97, aten_addmm_default_98, aten_addmm_default_96)\n",
      "  %executorch_call_delegate_64 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_64, %aten_view_copy_default_335, %aten_permute_copy_default_96, %aten_view_copy_default_336, %aten_permute_copy_default_97, %aten_view_copy_default_334, %aten_permute_copy_default_98), kwargs = {})\n",
      "  %getitem_130 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_64, 0), kwargs = {})\n",
      "  %getitem_131 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_64, 1), kwargs = {})\n",
      "  %getitem_132 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_64, 2), kwargs = {})\n",
      "  %aten_view_copy_default_339 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_132, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_340 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_130, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_341 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_131, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_581 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_49 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_339, %_lifted_tensor_constant37), kwargs = {out: %alloc_581})\n",
      "  %sym_size_41 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_339, 1), kwargs = {})\n",
      "  %alloc_582 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_221 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_340, [0, 2, 1, 3]), kwargs = {out: %alloc_582})\n",
      "  %alloc_583 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_222 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_341, [0, 2, 1, 3]), kwargs = {out: %alloc_583})\n",
      "  %aten_view_copy_default_342 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_49, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_584 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_83 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_221,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_584})\n",
      "  %alloc_585 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_84 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_222,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_585})\n",
      "  %alloc_586 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_223 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_342, [0, 2, 1, 3]), kwargs = {out: %alloc_586})\n",
      "  %aten_view_copy_default_343 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_83, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_344 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_84, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_587 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_85 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_223,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_587})\n",
      "  %alloc_588 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_224 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_343, [0, 2, 1]), kwargs = {out: %alloc_588})\n",
      "  %aten_view_copy_default_345 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_85, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_589 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_32 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_345, %aten_permute_copy_default_224), kwargs = {out: %alloc_589})\n",
      "  %alloc_590 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_16 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_32, -1, False), kwargs = {out: %alloc_590})\n",
      "  %alloc_591 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_86 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_16,), kwargs = {out: %alloc_591})\n",
      "  %alloc_592 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_33 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_86, %aten_view_copy_default_344), kwargs = {out: %alloc_592})\n",
      "  %aten_view_copy_default_346 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_33, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_593 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_225 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_346, [0, 2, 1, 3]), kwargs = {out: %alloc_593})\n",
      "  %alloc_594 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_87 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_225,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_594})\n",
      "  %aten_view_copy_default_348 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_87, [%sym_size_41, 1024]), kwargs = {})\n",
      "  %lowered_module_65 : [num_users=1] = get_attr[target=lowered_module_65]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_348 : [num_users=1] = placeholder[target=aten_view_copy_default_348]\n",
      "      %aten_permute_copy_default_185 : [num_users=1] = placeholder[target=aten_permute_copy_default_185]\n",
      "      %aten_addmm_default_99 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_bias, %aten_view_copy_default_348, %aten_permute_copy_default_185), kwargs = {})\n",
      "      return (aten_addmm_default_99,)\n",
      "  %executorch_call_delegate_65 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_65, %aten_view_copy_default_348, %aten_permute_copy_default_99), kwargs = {})\n",
      "  %getitem_133 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_65, 0), kwargs = {})\n",
      "  %aten_view_copy_default_349 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_133, [1, %sym_size_41, 1024]), kwargs = {})\n",
      "  %alloc_595 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_33 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_32, %aten_view_copy_default_349), kwargs = {out: %alloc_595})\n",
      "  %alloc_596 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_597 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_598 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_34 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_33, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_596, out1: %alloc_597, out2: %alloc_598})\n",
      "  %getitem_134 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_34, 0), kwargs = {})\n",
      "  %aten_view_copy_default_350 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_134, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_66 : [num_users=1] = get_attr[target=lowered_module_66]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_350 : [num_users=1] = placeholder[target=aten_view_copy_default_350]\n",
      "      %aten_permute_copy_default_186 : [num_users=1] = placeholder[target=aten_permute_copy_default_186]\n",
      "      %aten_addmm_default_100 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_bias, %aten_view_copy_default_350, %aten_permute_copy_default_186), kwargs = {})\n",
      "      return (aten_addmm_default_100,)\n",
      "  %executorch_call_delegate_66 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_66, %aten_view_copy_default_350, %aten_permute_copy_default_100), kwargs = {})\n",
      "  %getitem_135 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_66, 0), kwargs = {})\n",
      "  %aten_view_copy_default_351 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_135, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_599 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_50 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_351, %_lifted_tensor_constant38), kwargs = {out: %alloc_599})\n",
      "  %sym_size_42 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_351, 1), kwargs = {})\n",
      "  %alloc_600 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_16 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_50,), kwargs = {out: %alloc_600})\n",
      "  %alloc_601 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_51 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_351, %aten_sigmoid_default_16), kwargs = {out: %alloc_601})\n",
      "  %aten_view_copy_default_352 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_51, [%sym_size_42, 4096]), kwargs = {})\n",
      "  %lowered_module_67 : [num_users=1] = get_attr[target=lowered_module_67]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_352 : [num_users=1] = placeholder[target=aten_view_copy_default_352]\n",
      "      %aten_permute_copy_default_187 : [num_users=1] = placeholder[target=aten_permute_copy_default_187]\n",
      "      %aten_addmm_default_101 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_bias, %aten_view_copy_default_352, %aten_permute_copy_default_187), kwargs = {})\n",
      "      return (aten_addmm_default_101,)\n",
      "  %executorch_call_delegate_67 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_67, %aten_view_copy_default_352, %aten_permute_copy_default_101), kwargs = {})\n",
      "  %getitem_136 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_67, 0), kwargs = {})\n",
      "  %aten_view_copy_default_353 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_136, [1, %sym_size_42, 1024]), kwargs = {})\n",
      "  %alloc_602 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_34 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_33, %aten_view_copy_default_353), kwargs = {out: %alloc_602})\n",
      "  %alloc_603 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_604 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_605 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_35 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_34, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_603, out1: %alloc_604, out2: %alloc_605})\n",
      "  %getitem_137 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_35, 0), kwargs = {})\n",
      "  %aten_view_copy_default_354 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_137, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_355 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_137, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_356 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_137, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_68 : [num_users=1] = get_attr[target=lowered_module_68]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_356 : [num_users=1] = placeholder[target=aten_view_copy_default_356]\n",
      "      %aten_permute_copy_default_189 : [num_users=1] = placeholder[target=aten_permute_copy_default_189]\n",
      "      %aten_view_copy_default_359 : [num_users=1] = placeholder[target=aten_view_copy_default_359]\n",
      "      %aten_permute_copy_default_191 : [num_users=1] = placeholder[target=aten_permute_copy_default_191]\n",
      "      %aten_view_copy_default_354 : [num_users=1] = placeholder[target=aten_view_copy_default_354]\n",
      "      %aten_permute_copy_default_188 : [num_users=1] = placeholder[target=aten_permute_copy_default_188]\n",
      "      %aten_addmm_default_103 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_bias, %aten_view_copy_default_356, %aten_permute_copy_default_189), kwargs = {})\n",
      "      %aten_addmm_default_104 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_bias, %aten_view_copy_default_359, %aten_permute_copy_default_191), kwargs = {})\n",
      "      %aten_addmm_default_102 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_bias, %aten_view_copy_default_354, %aten_permute_copy_default_188), kwargs = {})\n",
      "      return (aten_addmm_default_103, aten_addmm_default_104, aten_addmm_default_102)\n",
      "  %executorch_call_delegate_68 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_68, %aten_view_copy_default_355, %aten_permute_copy_default_102, %aten_view_copy_default_356, %aten_permute_copy_default_103, %aten_view_copy_default_354, %aten_permute_copy_default_104), kwargs = {})\n",
      "  %getitem_138 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_68, 0), kwargs = {})\n",
      "  %getitem_139 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_68, 1), kwargs = {})\n",
      "  %getitem_140 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_68, 2), kwargs = {})\n",
      "  %aten_view_copy_default_359 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_140, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_360 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_138, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_361 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_139, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_606 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_52 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_359, %_lifted_tensor_constant39), kwargs = {out: %alloc_606})\n",
      "  %sym_size_43 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_359, 1), kwargs = {})\n",
      "  %alloc_607 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_226 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_360, [0, 2, 1, 3]), kwargs = {out: %alloc_607})\n",
      "  %alloc_608 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_227 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_361, [0, 2, 1, 3]), kwargs = {out: %alloc_608})\n",
      "  %aten_view_copy_default_362 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_52, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_609 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_88 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_226,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_609})\n",
      "  %alloc_610 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_89 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_227,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_610})\n",
      "  %alloc_611 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_228 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_362, [0, 2, 1, 3]), kwargs = {out: %alloc_611})\n",
      "  %aten_view_copy_default_363 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_88, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_364 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_89, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_612 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_90 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_228,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_612})\n",
      "  %alloc_613 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_229 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_363, [0, 2, 1]), kwargs = {out: %alloc_613})\n",
      "  %aten_view_copy_default_365 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_90, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_614 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_34 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_365, %aten_permute_copy_default_229), kwargs = {out: %alloc_614})\n",
      "  %alloc_615 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_17 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_34, -1, False), kwargs = {out: %alloc_615})\n",
      "  %alloc_616 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_91 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_17,), kwargs = {out: %alloc_616})\n",
      "  %alloc_617 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_35 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_91, %aten_view_copy_default_364), kwargs = {out: %alloc_617})\n",
      "  %aten_view_copy_default_366 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_35, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_618 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_230 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_366, [0, 2, 1, 3]), kwargs = {out: %alloc_618})\n",
      "  %alloc_619 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_92 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_230,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_619})\n",
      "  %aten_view_copy_default_368 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_92, [%sym_size_43, 1024]), kwargs = {})\n",
      "  %lowered_module_69 : [num_users=1] = get_attr[target=lowered_module_69]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_368 : [num_users=1] = placeholder[target=aten_view_copy_default_368]\n",
      "      %aten_permute_copy_default_196 : [num_users=1] = placeholder[target=aten_permute_copy_default_196]\n",
      "      %aten_addmm_default_105 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_bias, %aten_view_copy_default_368, %aten_permute_copy_default_196), kwargs = {})\n",
      "      return (aten_addmm_default_105,)\n",
      "  %executorch_call_delegate_69 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_69, %aten_view_copy_default_368, %aten_permute_copy_default_105), kwargs = {})\n",
      "  %getitem_141 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_69, 0), kwargs = {})\n",
      "  %aten_view_copy_default_369 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_141, [1, %sym_size_43, 1024]), kwargs = {})\n",
      "  %alloc_620 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_35 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_34, %aten_view_copy_default_369), kwargs = {out: %alloc_620})\n",
      "  %alloc_621 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_622 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_623 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_36 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_35, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_621, out1: %alloc_622, out2: %alloc_623})\n",
      "  %getitem_142 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_36, 0), kwargs = {})\n",
      "  %aten_view_copy_default_370 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_142, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_70 : [num_users=1] = get_attr[target=lowered_module_70]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_370 : [num_users=1] = placeholder[target=aten_view_copy_default_370]\n",
      "      %aten_permute_copy_default_197 : [num_users=1] = placeholder[target=aten_permute_copy_default_197]\n",
      "      %aten_addmm_default_106 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_bias, %aten_view_copy_default_370, %aten_permute_copy_default_197), kwargs = {})\n",
      "      return (aten_addmm_default_106,)\n",
      "  %executorch_call_delegate_70 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_70, %aten_view_copy_default_370, %aten_permute_copy_default_106), kwargs = {})\n",
      "  %getitem_143 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_70, 0), kwargs = {})\n",
      "  %aten_view_copy_default_371 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_143, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_624 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_53 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_371, %_lifted_tensor_constant40), kwargs = {out: %alloc_624})\n",
      "  %sym_size_44 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_371, 1), kwargs = {})\n",
      "  %alloc_625 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_17 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_53,), kwargs = {out: %alloc_625})\n",
      "  %alloc_626 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_54 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_371, %aten_sigmoid_default_17), kwargs = {out: %alloc_626})\n",
      "  %aten_view_copy_default_372 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_54, [%sym_size_44, 4096]), kwargs = {})\n",
      "  %lowered_module_71 : [num_users=1] = get_attr[target=lowered_module_71]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_372 : [num_users=1] = placeholder[target=aten_view_copy_default_372]\n",
      "      %aten_permute_copy_default_198 : [num_users=1] = placeholder[target=aten_permute_copy_default_198]\n",
      "      %aten_addmm_default_107 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_bias, %aten_view_copy_default_372, %aten_permute_copy_default_198), kwargs = {})\n",
      "      return (aten_addmm_default_107,)\n",
      "  %executorch_call_delegate_71 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_71, %aten_view_copy_default_372, %aten_permute_copy_default_107), kwargs = {})\n",
      "  %getitem_144 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_71, 0), kwargs = {})\n",
      "  %aten_view_copy_default_373 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_144, [1, %sym_size_44, 1024]), kwargs = {})\n",
      "  %alloc_627 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_36 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_35, %aten_view_copy_default_373), kwargs = {out: %alloc_627})\n",
      "  %alloc_628 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_629 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_630 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_37 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_36, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_628, out1: %alloc_629, out2: %alloc_630})\n",
      "  %getitem_145 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_37, 0), kwargs = {})\n",
      "  %aten_view_copy_default_374 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_145, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_375 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_145, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_376 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_145, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_72 : [num_users=1] = get_attr[target=lowered_module_72]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_376 : [num_users=1] = placeholder[target=aten_view_copy_default_376]\n",
      "      %aten_permute_copy_default_200 : [num_users=1] = placeholder[target=aten_permute_copy_default_200]\n",
      "      %aten_view_copy_default_379 : [num_users=1] = placeholder[target=aten_view_copy_default_379]\n",
      "      %aten_permute_copy_default_202 : [num_users=1] = placeholder[target=aten_permute_copy_default_202]\n",
      "      %aten_view_copy_default_374 : [num_users=1] = placeholder[target=aten_view_copy_default_374]\n",
      "      %aten_permute_copy_default_199 : [num_users=1] = placeholder[target=aten_permute_copy_default_199]\n",
      "      %aten_addmm_default_109 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_bias, %aten_view_copy_default_376, %aten_permute_copy_default_200), kwargs = {})\n",
      "      %aten_addmm_default_110 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_bias, %aten_view_copy_default_379, %aten_permute_copy_default_202), kwargs = {})\n",
      "      %aten_addmm_default_108 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_bias, %aten_view_copy_default_374, %aten_permute_copy_default_199), kwargs = {})\n",
      "      return (aten_addmm_default_109, aten_addmm_default_110, aten_addmm_default_108)\n",
      "  %executorch_call_delegate_72 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_72, %aten_view_copy_default_375, %aten_permute_copy_default_108, %aten_view_copy_default_376, %aten_permute_copy_default_109, %aten_view_copy_default_374, %aten_permute_copy_default_110), kwargs = {})\n",
      "  %getitem_146 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_72, 0), kwargs = {})\n",
      "  %getitem_147 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_72, 1), kwargs = {})\n",
      "  %getitem_148 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_72, 2), kwargs = {})\n",
      "  %aten_view_copy_default_379 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_148, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_380 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_146, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_381 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_147, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_631 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_55 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_379, %_lifted_tensor_constant41), kwargs = {out: %alloc_631})\n",
      "  %sym_size_45 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_379, 1), kwargs = {})\n",
      "  %alloc_632 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_231 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_380, [0, 2, 1, 3]), kwargs = {out: %alloc_632})\n",
      "  %alloc_633 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_232 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_381, [0, 2, 1, 3]), kwargs = {out: %alloc_633})\n",
      "  %aten_view_copy_default_382 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_55, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_634 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_93 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_231,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_634})\n",
      "  %alloc_635 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_94 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_232,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_635})\n",
      "  %alloc_636 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_233 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_382, [0, 2, 1, 3]), kwargs = {out: %alloc_636})\n",
      "  %aten_view_copy_default_383 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_93, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_384 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_94, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_637 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_95 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_233,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_637})\n",
      "  %alloc_638 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_234 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_383, [0, 2, 1]), kwargs = {out: %alloc_638})\n",
      "  %aten_view_copy_default_385 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_95, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_639 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_36 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_385, %aten_permute_copy_default_234), kwargs = {out: %alloc_639})\n",
      "  %alloc_640 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_18 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_36, -1, False), kwargs = {out: %alloc_640})\n",
      "  %alloc_641 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_96 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_18,), kwargs = {out: %alloc_641})\n",
      "  %alloc_642 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_37 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_96, %aten_view_copy_default_384), kwargs = {out: %alloc_642})\n",
      "  %aten_view_copy_default_386 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_37, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_643 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_235 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_386, [0, 2, 1, 3]), kwargs = {out: %alloc_643})\n",
      "  %alloc_644 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_97 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_235,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_644})\n",
      "  %aten_view_copy_default_388 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_97, [%sym_size_45, 1024]), kwargs = {})\n",
      "  %lowered_module_73 : [num_users=1] = get_attr[target=lowered_module_73]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_388 : [num_users=1] = placeholder[target=aten_view_copy_default_388]\n",
      "      %aten_permute_copy_default_207 : [num_users=1] = placeholder[target=aten_permute_copy_default_207]\n",
      "      %aten_addmm_default_111 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_bias, %aten_view_copy_default_388, %aten_permute_copy_default_207), kwargs = {})\n",
      "      return (aten_addmm_default_111,)\n",
      "  %executorch_call_delegate_73 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_73, %aten_view_copy_default_388, %aten_permute_copy_default_111), kwargs = {})\n",
      "  %getitem_149 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_73, 0), kwargs = {})\n",
      "  %aten_view_copy_default_389 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_149, [1, %sym_size_45, 1024]), kwargs = {})\n",
      "  %alloc_645 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_37 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_36, %aten_view_copy_default_389), kwargs = {out: %alloc_645})\n",
      "  %alloc_646 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_647 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_648 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_38 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_37, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_646, out1: %alloc_647, out2: %alloc_648})\n",
      "  %getitem_150 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_38, 0), kwargs = {})\n",
      "  %aten_view_copy_default_390 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_150, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_74 : [num_users=1] = get_attr[target=lowered_module_74]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_390 : [num_users=1] = placeholder[target=aten_view_copy_default_390]\n",
      "      %aten_permute_copy_default_208 : [num_users=1] = placeholder[target=aten_permute_copy_default_208]\n",
      "      %aten_addmm_default_112 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_bias, %aten_view_copy_default_390, %aten_permute_copy_default_208), kwargs = {})\n",
      "      return (aten_addmm_default_112,)\n",
      "  %executorch_call_delegate_74 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_74, %aten_view_copy_default_390, %aten_permute_copy_default_112), kwargs = {})\n",
      "  %getitem_151 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_74, 0), kwargs = {})\n",
      "  %aten_view_copy_default_391 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_151, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_649 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_56 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_391, %_lifted_tensor_constant42), kwargs = {out: %alloc_649})\n",
      "  %sym_size_46 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_391, 1), kwargs = {})\n",
      "  %alloc_650 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_18 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_56,), kwargs = {out: %alloc_650})\n",
      "  %alloc_651 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_57 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_391, %aten_sigmoid_default_18), kwargs = {out: %alloc_651})\n",
      "  %aten_view_copy_default_392 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_57, [%sym_size_46, 4096]), kwargs = {})\n",
      "  %lowered_module_75 : [num_users=1] = get_attr[target=lowered_module_75]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_392 : [num_users=1] = placeholder[target=aten_view_copy_default_392]\n",
      "      %aten_permute_copy_default_209 : [num_users=1] = placeholder[target=aten_permute_copy_default_209]\n",
      "      %aten_addmm_default_113 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_bias, %aten_view_copy_default_392, %aten_permute_copy_default_209), kwargs = {})\n",
      "      return (aten_addmm_default_113,)\n",
      "  %executorch_call_delegate_75 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_75, %aten_view_copy_default_392, %aten_permute_copy_default_113), kwargs = {})\n",
      "  %getitem_152 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_75, 0), kwargs = {})\n",
      "  %aten_view_copy_default_393 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_152, [1, %sym_size_46, 1024]), kwargs = {})\n",
      "  %alloc_652 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_38 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_37, %aten_view_copy_default_393), kwargs = {out: %alloc_652})\n",
      "  %alloc_653 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_654 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_655 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_39 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_38, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_653, out1: %alloc_654, out2: %alloc_655})\n",
      "  %getitem_153 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_39, 0), kwargs = {})\n",
      "  %aten_view_copy_default_394 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_153, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_395 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_153, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_396 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_153, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_76 : [num_users=1] = get_attr[target=lowered_module_76]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_396 : [num_users=1] = placeholder[target=aten_view_copy_default_396]\n",
      "      %aten_permute_copy_default_211 : [num_users=1] = placeholder[target=aten_permute_copy_default_211]\n",
      "      %aten_view_copy_default_399 : [num_users=1] = placeholder[target=aten_view_copy_default_399]\n",
      "      %aten_permute_copy_default_213 : [num_users=1] = placeholder[target=aten_permute_copy_default_213]\n",
      "      %aten_view_copy_default_394 : [num_users=1] = placeholder[target=aten_view_copy_default_394]\n",
      "      %aten_permute_copy_default_210 : [num_users=1] = placeholder[target=aten_permute_copy_default_210]\n",
      "      %aten_addmm_default_115 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_bias, %aten_view_copy_default_396, %aten_permute_copy_default_211), kwargs = {})\n",
      "      %aten_addmm_default_116 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_bias, %aten_view_copy_default_399, %aten_permute_copy_default_213), kwargs = {})\n",
      "      %aten_addmm_default_114 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_bias, %aten_view_copy_default_394, %aten_permute_copy_default_210), kwargs = {})\n",
      "      return (aten_addmm_default_115, aten_addmm_default_116, aten_addmm_default_114)\n",
      "  %executorch_call_delegate_76 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_76, %aten_view_copy_default_395, %aten_permute_copy_default_114, %aten_view_copy_default_396, %aten_permute_copy_default_115, %aten_view_copy_default_394, %aten_permute_copy_default_116), kwargs = {})\n",
      "  %getitem_154 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_76, 0), kwargs = {})\n",
      "  %getitem_155 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_76, 1), kwargs = {})\n",
      "  %getitem_156 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_76, 2), kwargs = {})\n",
      "  %aten_view_copy_default_399 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_156, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_400 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_154, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_401 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_155, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_656 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_58 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_399, %_lifted_tensor_constant43), kwargs = {out: %alloc_656})\n",
      "  %sym_size_47 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_399, 1), kwargs = {})\n",
      "  %alloc_657 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_236 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_400, [0, 2, 1, 3]), kwargs = {out: %alloc_657})\n",
      "  %alloc_658 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_237 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_401, [0, 2, 1, 3]), kwargs = {out: %alloc_658})\n",
      "  %aten_view_copy_default_402 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_58, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_659 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_98 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_236,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_659})\n",
      "  %alloc_660 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_99 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_237,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_660})\n",
      "  %alloc_661 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_238 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_402, [0, 2, 1, 3]), kwargs = {out: %alloc_661})\n",
      "  %aten_view_copy_default_403 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_98, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_404 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_99, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_662 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_100 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_238,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_662})\n",
      "  %alloc_663 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_239 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_403, [0, 2, 1]), kwargs = {out: %alloc_663})\n",
      "  %aten_view_copy_default_405 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_100, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_664 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_38 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_405, %aten_permute_copy_default_239), kwargs = {out: %alloc_664})\n",
      "  %alloc_665 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_19 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_38, -1, False), kwargs = {out: %alloc_665})\n",
      "  %alloc_666 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_101 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_19,), kwargs = {out: %alloc_666})\n",
      "  %alloc_667 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_39 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_101, %aten_view_copy_default_404), kwargs = {out: %alloc_667})\n",
      "  %aten_view_copy_default_406 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_39, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_668 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_240 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_406, [0, 2, 1, 3]), kwargs = {out: %alloc_668})\n",
      "  %alloc_669 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_102 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_240,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_669})\n",
      "  %aten_view_copy_default_408 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_102, [%sym_size_47, 1024]), kwargs = {})\n",
      "  %lowered_module_77 : [num_users=1] = get_attr[target=lowered_module_77]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_408 : [num_users=1] = placeholder[target=aten_view_copy_default_408]\n",
      "      %aten_permute_copy_default_218 : [num_users=1] = placeholder[target=aten_permute_copy_default_218]\n",
      "      %aten_addmm_default_117 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_bias, %aten_view_copy_default_408, %aten_permute_copy_default_218), kwargs = {})\n",
      "      return (aten_addmm_default_117,)\n",
      "  %executorch_call_delegate_77 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_77, %aten_view_copy_default_408, %aten_permute_copy_default_117), kwargs = {})\n",
      "  %getitem_157 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_77, 0), kwargs = {})\n",
      "  %aten_view_copy_default_409 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_157, [1, %sym_size_47, 1024]), kwargs = {})\n",
      "  %alloc_670 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_39 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_38, %aten_view_copy_default_409), kwargs = {out: %alloc_670})\n",
      "  %alloc_671 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_672 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_673 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_40 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_39, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_671, out1: %alloc_672, out2: %alloc_673})\n",
      "  %getitem_158 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_40, 0), kwargs = {})\n",
      "  %aten_view_copy_default_410 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_158, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_78 : [num_users=1] = get_attr[target=lowered_module_78]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_410 : [num_users=1] = placeholder[target=aten_view_copy_default_410]\n",
      "      %aten_permute_copy_default_219 : [num_users=1] = placeholder[target=aten_permute_copy_default_219]\n",
      "      %aten_addmm_default_118 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_bias, %aten_view_copy_default_410, %aten_permute_copy_default_219), kwargs = {})\n",
      "      return (aten_addmm_default_118,)\n",
      "  %executorch_call_delegate_78 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_78, %aten_view_copy_default_410, %aten_permute_copy_default_118), kwargs = {})\n",
      "  %getitem_159 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_78, 0), kwargs = {})\n",
      "  %aten_view_copy_default_411 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_159, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_674 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_59 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_411, %_lifted_tensor_constant44), kwargs = {out: %alloc_674})\n",
      "  %sym_size_48 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_411, 1), kwargs = {})\n",
      "  %alloc_675 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_19 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_59,), kwargs = {out: %alloc_675})\n",
      "  %alloc_676 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_60 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_411, %aten_sigmoid_default_19), kwargs = {out: %alloc_676})\n",
      "  %aten_view_copy_default_412 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_60, [%sym_size_48, 4096]), kwargs = {})\n",
      "  %lowered_module_79 : [num_users=1] = get_attr[target=lowered_module_79]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_412 : [num_users=1] = placeholder[target=aten_view_copy_default_412]\n",
      "      %aten_permute_copy_default_220 : [num_users=1] = placeholder[target=aten_permute_copy_default_220]\n",
      "      %aten_addmm_default_119 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_bias, %aten_view_copy_default_412, %aten_permute_copy_default_220), kwargs = {})\n",
      "      return (aten_addmm_default_119,)\n",
      "  %executorch_call_delegate_79 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_79, %aten_view_copy_default_412, %aten_permute_copy_default_119), kwargs = {})\n",
      "  %getitem_160 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_79, 0), kwargs = {})\n",
      "  %aten_view_copy_default_413 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_160, [1, %sym_size_48, 1024]), kwargs = {})\n",
      "  %alloc_677 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_40 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_39, %aten_view_copy_default_413), kwargs = {out: %alloc_677})\n",
      "  %alloc_678 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_679 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_680 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_41 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_40, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_678, out1: %alloc_679, out2: %alloc_680})\n",
      "  %getitem_161 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_41, 0), kwargs = {})\n",
      "  %aten_view_copy_default_414 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_161, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_415 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_161, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_416 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_161, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_80 : [num_users=1] = get_attr[target=lowered_module_80]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_416 : [num_users=1] = placeholder[target=aten_view_copy_default_416]\n",
      "      %aten_permute_copy_default_222 : [num_users=1] = placeholder[target=aten_permute_copy_default_222]\n",
      "      %aten_view_copy_default_419 : [num_users=1] = placeholder[target=aten_view_copy_default_419]\n",
      "      %aten_permute_copy_default_224 : [num_users=1] = placeholder[target=aten_permute_copy_default_224]\n",
      "      %aten_view_copy_default_414 : [num_users=1] = placeholder[target=aten_view_copy_default_414]\n",
      "      %aten_permute_copy_default_221 : [num_users=1] = placeholder[target=aten_permute_copy_default_221]\n",
      "      %aten_addmm_default_121 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_bias, %aten_view_copy_default_416, %aten_permute_copy_default_222), kwargs = {})\n",
      "      %aten_addmm_default_122 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_bias, %aten_view_copy_default_419, %aten_permute_copy_default_224), kwargs = {})\n",
      "      %aten_addmm_default_120 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_bias, %aten_view_copy_default_414, %aten_permute_copy_default_221), kwargs = {})\n",
      "      return (aten_addmm_default_121, aten_addmm_default_122, aten_addmm_default_120)\n",
      "  %executorch_call_delegate_80 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_80, %aten_view_copy_default_415, %aten_permute_copy_default_120, %aten_view_copy_default_416, %aten_permute_copy_default_121, %aten_view_copy_default_414, %aten_permute_copy_default_122), kwargs = {})\n",
      "  %getitem_162 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_80, 0), kwargs = {})\n",
      "  %getitem_163 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_80, 1), kwargs = {})\n",
      "  %getitem_164 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_80, 2), kwargs = {})\n",
      "  %aten_view_copy_default_419 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_164, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_420 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_162, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_421 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_163, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_681 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_61 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_419, %_lifted_tensor_constant45), kwargs = {out: %alloc_681})\n",
      "  %sym_size_49 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_419, 1), kwargs = {})\n",
      "  %alloc_682 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_241 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_420, [0, 2, 1, 3]), kwargs = {out: %alloc_682})\n",
      "  %alloc_683 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_242 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_421, [0, 2, 1, 3]), kwargs = {out: %alloc_683})\n",
      "  %aten_view_copy_default_422 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_61, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_684 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_103 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_241,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_684})\n",
      "  %alloc_685 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_104 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_242,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_685})\n",
      "  %alloc_686 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_243 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_422, [0, 2, 1, 3]), kwargs = {out: %alloc_686})\n",
      "  %aten_view_copy_default_423 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_103, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_424 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_104, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_687 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_105 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_243,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_687})\n",
      "  %alloc_688 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_244 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_423, [0, 2, 1]), kwargs = {out: %alloc_688})\n",
      "  %aten_view_copy_default_425 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_105, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_689 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_40 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_425, %aten_permute_copy_default_244), kwargs = {out: %alloc_689})\n",
      "  %alloc_690 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_20 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_40, -1, False), kwargs = {out: %alloc_690})\n",
      "  %alloc_691 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_106 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_20,), kwargs = {out: %alloc_691})\n",
      "  %alloc_692 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_41 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_106, %aten_view_copy_default_424), kwargs = {out: %alloc_692})\n",
      "  %aten_view_copy_default_426 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_41, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_693 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_245 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_426, [0, 2, 1, 3]), kwargs = {out: %alloc_693})\n",
      "  %alloc_694 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_107 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_245,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_694})\n",
      "  %aten_view_copy_default_428 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_107, [%sym_size_49, 1024]), kwargs = {})\n",
      "  %lowered_module_81 : [num_users=1] = get_attr[target=lowered_module_81]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_428 : [num_users=1] = placeholder[target=aten_view_copy_default_428]\n",
      "      %aten_permute_copy_default_229 : [num_users=1] = placeholder[target=aten_permute_copy_default_229]\n",
      "      %aten_addmm_default_123 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_bias, %aten_view_copy_default_428, %aten_permute_copy_default_229), kwargs = {})\n",
      "      return (aten_addmm_default_123,)\n",
      "  %executorch_call_delegate_81 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_81, %aten_view_copy_default_428, %aten_permute_copy_default_123), kwargs = {})\n",
      "  %getitem_165 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_81, 0), kwargs = {})\n",
      "  %aten_view_copy_default_429 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_165, [1, %sym_size_49, 1024]), kwargs = {})\n",
      "  %alloc_695 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_41 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_40, %aten_view_copy_default_429), kwargs = {out: %alloc_695})\n",
      "  %alloc_696 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_697 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_698 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_42 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_41, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_696, out1: %alloc_697, out2: %alloc_698})\n",
      "  %getitem_166 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_42, 0), kwargs = {})\n",
      "  %aten_view_copy_default_430 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_166, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_82 : [num_users=1] = get_attr[target=lowered_module_82]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_430 : [num_users=1] = placeholder[target=aten_view_copy_default_430]\n",
      "      %aten_permute_copy_default_230 : [num_users=1] = placeholder[target=aten_permute_copy_default_230]\n",
      "      %aten_addmm_default_124 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_bias, %aten_view_copy_default_430, %aten_permute_copy_default_230), kwargs = {})\n",
      "      return (aten_addmm_default_124,)\n",
      "  %executorch_call_delegate_82 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_82, %aten_view_copy_default_430, %aten_permute_copy_default_124), kwargs = {})\n",
      "  %getitem_167 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_82, 0), kwargs = {})\n",
      "  %aten_view_copy_default_431 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_167, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_699 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_62 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_431, %_lifted_tensor_constant46), kwargs = {out: %alloc_699})\n",
      "  %sym_size_50 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_431, 1), kwargs = {})\n",
      "  %alloc_700 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_20 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_62,), kwargs = {out: %alloc_700})\n",
      "  %alloc_701 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_63 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_431, %aten_sigmoid_default_20), kwargs = {out: %alloc_701})\n",
      "  %aten_view_copy_default_432 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_63, [%sym_size_50, 4096]), kwargs = {})\n",
      "  %lowered_module_83 : [num_users=1] = get_attr[target=lowered_module_83]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_432 : [num_users=1] = placeholder[target=aten_view_copy_default_432]\n",
      "      %aten_permute_copy_default_231 : [num_users=1] = placeholder[target=aten_permute_copy_default_231]\n",
      "      %aten_addmm_default_125 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_bias, %aten_view_copy_default_432, %aten_permute_copy_default_231), kwargs = {})\n",
      "      return (aten_addmm_default_125,)\n",
      "  %executorch_call_delegate_83 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_83, %aten_view_copy_default_432, %aten_permute_copy_default_125), kwargs = {})\n",
      "  %getitem_168 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_83, 0), kwargs = {})\n",
      "  %aten_view_copy_default_433 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_168, [1, %sym_size_50, 1024]), kwargs = {})\n",
      "  %alloc_702 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_42 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_41, %aten_view_copy_default_433), kwargs = {out: %alloc_702})\n",
      "  %alloc_703 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_704 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_705 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_43 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_42, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_703, out1: %alloc_704, out2: %alloc_705})\n",
      "  %getitem_169 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_43, 0), kwargs = {})\n",
      "  %aten_view_copy_default_434 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_169, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_435 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_169, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_436 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_169, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_84 : [num_users=1] = get_attr[target=lowered_module_84]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_436 : [num_users=1] = placeholder[target=aten_view_copy_default_436]\n",
      "      %aten_permute_copy_default_233 : [num_users=1] = placeholder[target=aten_permute_copy_default_233]\n",
      "      %aten_view_copy_default_439 : [num_users=1] = placeholder[target=aten_view_copy_default_439]\n",
      "      %aten_permute_copy_default_235 : [num_users=1] = placeholder[target=aten_permute_copy_default_235]\n",
      "      %aten_view_copy_default_434 : [num_users=1] = placeholder[target=aten_view_copy_default_434]\n",
      "      %aten_permute_copy_default_232 : [num_users=1] = placeholder[target=aten_permute_copy_default_232]\n",
      "      %aten_addmm_default_127 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_bias, %aten_view_copy_default_436, %aten_permute_copy_default_233), kwargs = {})\n",
      "      %aten_addmm_default_128 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_bias, %aten_view_copy_default_439, %aten_permute_copy_default_235), kwargs = {})\n",
      "      %aten_addmm_default_126 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_bias, %aten_view_copy_default_434, %aten_permute_copy_default_232), kwargs = {})\n",
      "      return (aten_addmm_default_127, aten_addmm_default_128, aten_addmm_default_126)\n",
      "  %executorch_call_delegate_84 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_84, %aten_view_copy_default_435, %aten_permute_copy_default_126, %aten_view_copy_default_436, %aten_permute_copy_default_127, %aten_view_copy_default_434, %aten_permute_copy_default_128), kwargs = {})\n",
      "  %getitem_170 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_84, 0), kwargs = {})\n",
      "  %getitem_171 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_84, 1), kwargs = {})\n",
      "  %getitem_172 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_84, 2), kwargs = {})\n",
      "  %aten_view_copy_default_439 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_172, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_440 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_170, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_441 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_171, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_706 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_64 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_439, %_lifted_tensor_constant47), kwargs = {out: %alloc_706})\n",
      "  %sym_size_51 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_439, 1), kwargs = {})\n",
      "  %alloc_707 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_246 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_440, [0, 2, 1, 3]), kwargs = {out: %alloc_707})\n",
      "  %alloc_708 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_247 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_441, [0, 2, 1, 3]), kwargs = {out: %alloc_708})\n",
      "  %aten_view_copy_default_442 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_64, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_709 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_108 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_246,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_709})\n",
      "  %alloc_710 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_109 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_247,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_710})\n",
      "  %alloc_711 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_248 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_442, [0, 2, 1, 3]), kwargs = {out: %alloc_711})\n",
      "  %aten_view_copy_default_443 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_108, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_444 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_109, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_712 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_110 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_248,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_712})\n",
      "  %alloc_713 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_249 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_443, [0, 2, 1]), kwargs = {out: %alloc_713})\n",
      "  %aten_view_copy_default_445 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_110, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_714 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_42 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_445, %aten_permute_copy_default_249), kwargs = {out: %alloc_714})\n",
      "  %alloc_715 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_21 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_42, -1, False), kwargs = {out: %alloc_715})\n",
      "  %alloc_716 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_111 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_21,), kwargs = {out: %alloc_716})\n",
      "  %alloc_717 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_43 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_111, %aten_view_copy_default_444), kwargs = {out: %alloc_717})\n",
      "  %aten_view_copy_default_446 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_43, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_718 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_250 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_446, [0, 2, 1, 3]), kwargs = {out: %alloc_718})\n",
      "  %alloc_719 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_112 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_250,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_719})\n",
      "  %aten_view_copy_default_448 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_112, [%sym_size_51, 1024]), kwargs = {})\n",
      "  %lowered_module_85 : [num_users=1] = get_attr[target=lowered_module_85]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_448 : [num_users=1] = placeholder[target=aten_view_copy_default_448]\n",
      "      %aten_permute_copy_default_240 : [num_users=1] = placeholder[target=aten_permute_copy_default_240]\n",
      "      %aten_addmm_default_129 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_bias, %aten_view_copy_default_448, %aten_permute_copy_default_240), kwargs = {})\n",
      "      return (aten_addmm_default_129,)\n",
      "  %executorch_call_delegate_85 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_85, %aten_view_copy_default_448, %aten_permute_copy_default_129), kwargs = {})\n",
      "  %getitem_173 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_85, 0), kwargs = {})\n",
      "  %aten_view_copy_default_449 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_173, [1, %sym_size_51, 1024]), kwargs = {})\n",
      "  %alloc_720 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_43 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_42, %aten_view_copy_default_449), kwargs = {out: %alloc_720})\n",
      "  %alloc_721 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_722 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_723 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_44 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_43, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_721, out1: %alloc_722, out2: %alloc_723})\n",
      "  %getitem_174 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_44, 0), kwargs = {})\n",
      "  %aten_view_copy_default_450 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_174, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_86 : [num_users=1] = get_attr[target=lowered_module_86]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_450 : [num_users=1] = placeholder[target=aten_view_copy_default_450]\n",
      "      %aten_permute_copy_default_241 : [num_users=1] = placeholder[target=aten_permute_copy_default_241]\n",
      "      %aten_addmm_default_130 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_bias, %aten_view_copy_default_450, %aten_permute_copy_default_241), kwargs = {})\n",
      "      return (aten_addmm_default_130,)\n",
      "  %executorch_call_delegate_86 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_86, %aten_view_copy_default_450, %aten_permute_copy_default_130), kwargs = {})\n",
      "  %getitem_175 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_86, 0), kwargs = {})\n",
      "  %aten_view_copy_default_451 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_175, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_724 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_65 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_451, %_lifted_tensor_constant48), kwargs = {out: %alloc_724})\n",
      "  %sym_size_52 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_451, 1), kwargs = {})\n",
      "  %alloc_725 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_21 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_65,), kwargs = {out: %alloc_725})\n",
      "  %alloc_726 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_66 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_451, %aten_sigmoid_default_21), kwargs = {out: %alloc_726})\n",
      "  %aten_view_copy_default_452 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_66, [%sym_size_52, 4096]), kwargs = {})\n",
      "  %lowered_module_87 : [num_users=1] = get_attr[target=lowered_module_87]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_452 : [num_users=1] = placeholder[target=aten_view_copy_default_452]\n",
      "      %aten_permute_copy_default_242 : [num_users=1] = placeholder[target=aten_permute_copy_default_242]\n",
      "      %aten_addmm_default_131 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_bias, %aten_view_copy_default_452, %aten_permute_copy_default_242), kwargs = {})\n",
      "      return (aten_addmm_default_131,)\n",
      "  %executorch_call_delegate_87 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_87, %aten_view_copy_default_452, %aten_permute_copy_default_131), kwargs = {})\n",
      "  %getitem_176 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_87, 0), kwargs = {})\n",
      "  %aten_view_copy_default_453 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_176, [1, %sym_size_52, 1024]), kwargs = {})\n",
      "  %alloc_727 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_44 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_43, %aten_view_copy_default_453), kwargs = {out: %alloc_727})\n",
      "  %alloc_728 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_729 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_730 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_45 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_44, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_bias, 1e-05), kwargs = {out0: %alloc_728, out1: %alloc_729, out2: %alloc_730})\n",
      "  %getitem_177 : [num_users=3] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_45, 0), kwargs = {})\n",
      "  %aten_view_copy_default_454 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_177, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_455 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_177, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_456 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_177, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_88 : [num_users=1] = get_attr[target=lowered_module_88]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_bias]\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_bias]\n",
      "      %aten_view_copy_default_456 : [num_users=1] = placeholder[target=aten_view_copy_default_456]\n",
      "      %aten_permute_copy_default_244 : [num_users=1] = placeholder[target=aten_permute_copy_default_244]\n",
      "      %aten_view_copy_default_459 : [num_users=1] = placeholder[target=aten_view_copy_default_459]\n",
      "      %aten_permute_copy_default_246 : [num_users=1] = placeholder[target=aten_permute_copy_default_246]\n",
      "      %aten_view_copy_default_454 : [num_users=1] = placeholder[target=aten_view_copy_default_454]\n",
      "      %aten_permute_copy_default_243 : [num_users=1] = placeholder[target=aten_permute_copy_default_243]\n",
      "      %aten_addmm_default_133 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_bias, %aten_view_copy_default_456, %aten_permute_copy_default_244), kwargs = {})\n",
      "      %aten_addmm_default_134 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_bias, %aten_view_copy_default_459, %aten_permute_copy_default_246), kwargs = {})\n",
      "      %aten_addmm_default_132 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_bias, %aten_view_copy_default_454, %aten_permute_copy_default_243), kwargs = {})\n",
      "      return (aten_addmm_default_133, aten_addmm_default_134, aten_addmm_default_132)\n",
      "  %executorch_call_delegate_88 : [num_users=3] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_88, %aten_view_copy_default_455, %aten_permute_copy_default_132, %aten_view_copy_default_456, %aten_permute_copy_default_133, %aten_view_copy_default_454, %aten_permute_copy_default_134), kwargs = {})\n",
      "  %getitem_178 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_88, 0), kwargs = {})\n",
      "  %getitem_179 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_88, 1), kwargs = {})\n",
      "  %getitem_180 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_88, 2), kwargs = {})\n",
      "  %aten_view_copy_default_459 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_180, [1, %sym_size_8, 1024]), kwargs = {})\n",
      "  %aten_view_copy_default_460 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_178, [1, -1, 16, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_461 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_179, [1, -1, 16, 64]), kwargs = {})\n",
      "  %alloc_731 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_67 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_459, %_lifted_tensor_constant49), kwargs = {out: %alloc_731})\n",
      "  %sym_size_53 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_459, 1), kwargs = {})\n",
      "  %alloc_732 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_251 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_460, [0, 2, 1, 3]), kwargs = {out: %alloc_732})\n",
      "  %alloc_733 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_252 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_461, [0, 2, 1, 3]), kwargs = {out: %alloc_733})\n",
      "  %aten_view_copy_default_462 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_67, [1, %sym_size_8, 16, 64]), kwargs = {})\n",
      "  %alloc_734 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_113 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_251,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_734})\n",
      "  %alloc_735 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_114 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_252,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_735})\n",
      "  %alloc_736 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_253 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_462, [0, 2, 1, 3]), kwargs = {out: %alloc_736})\n",
      "  %aten_view_copy_default_463 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_113, [16, -1, 64]), kwargs = {})\n",
      "  %aten_view_copy_default_464 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_114, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_737 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_115 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_253,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_737})\n",
      "  %alloc_738 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, 64, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_254 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_463, [0, 2, 1]), kwargs = {out: %alloc_738})\n",
      "  %aten_view_copy_default_465 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_115, [16, -1, 64]), kwargs = {})\n",
      "  %alloc_739 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_44 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_view_copy_default_465, %aten_permute_copy_default_254), kwargs = {out: %alloc_739})\n",
      "  %alloc_740 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten__softmax_default_22 : [num_users=1] = call_function[target=torch.ops.aten._softmax.out](args = (%aten_bmm_default_44, -1, False), kwargs = {out: %alloc_740})\n",
      "  %alloc_741 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_116 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten__softmax_default_22,), kwargs = {out: %alloc_741})\n",
      "  %alloc_742 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((16, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 64), torch.float32),), kwargs = {})\n",
      "  %aten_bmm_default_45 : [num_users=1] = call_function[target=torch.ops.aten.bmm.out](args = (%aten_clone_default_116, %aten_view_copy_default_464), kwargs = {out: %alloc_742})\n",
      "  %aten_view_copy_default_466 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_bmm_default_45, [1, 16, %sym_size_8, 64]), kwargs = {})\n",
      "  %alloc_743 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_permute_copy_default_255 : [num_users=1] = call_function[target=torch.ops.aten.permute_copy.out](args = (%aten_view_copy_default_466, [0, 2, 1, 3]), kwargs = {out: %alloc_743})\n",
      "  %alloc_744 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 16, 64), torch.float32),), kwargs = {})\n",
      "  %aten_clone_default_117 : [num_users=1] = call_function[target=torch.ops.aten.clone.out](args = (%aten_permute_copy_default_255,), kwargs = {memory_format: torch.contiguous_format, out: %alloc_744})\n",
      "  %aten_view_copy_default_468 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_clone_default_117, [%sym_size_53, 1024]), kwargs = {})\n",
      "  %lowered_module_89 : [num_users=1] = get_attr[target=lowered_module_89]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_bias]\n",
      "      %aten_view_copy_default_468 : [num_users=1] = placeholder[target=aten_view_copy_default_468]\n",
      "      %aten_permute_copy_default_251 : [num_users=1] = placeholder[target=aten_permute_copy_default_251]\n",
      "      %aten_addmm_default_135 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_bias, %aten_view_copy_default_468, %aten_permute_copy_default_251), kwargs = {})\n",
      "      return (aten_addmm_default_135,)\n",
      "  %executorch_call_delegate_89 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_89, %aten_view_copy_default_468, %aten_permute_copy_default_135), kwargs = {})\n",
      "  %getitem_181 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_89, 0), kwargs = {})\n",
      "  %aten_view_copy_default_469 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_181, [1, %sym_size_53, 1024]), kwargs = {})\n",
      "  %alloc_745 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_45 : [num_users=2] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_44, %aten_view_copy_default_469), kwargs = {out: %alloc_745})\n",
      "  %alloc_746 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %alloc_747 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %alloc_748 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1), torch.float32),), kwargs = {})\n",
      "  %aten_native_layer_norm_default_46 : [num_users=1] = call_function[target=torch.ops.aten.native_layer_norm.out](args = (%aten_add_tensor_45, [1024], %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_weight, %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_bias, 1e-05), kwargs = {out0: %alloc_746, out1: %alloc_747, out2: %alloc_748})\n",
      "  %getitem_182 : [num_users=1] = call_function[target=operator.getitem](args = (%aten_native_layer_norm_default_46, 0), kwargs = {})\n",
      "  %aten_view_copy_default_470 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_182, [%sym_size_8, 1024]), kwargs = {})\n",
      "  %lowered_module_90 : [num_users=1] = get_attr[target=lowered_module_90]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_bias]\n",
      "      %aten_view_copy_default_470 : [num_users=1] = placeholder[target=aten_view_copy_default_470]\n",
      "      %aten_permute_copy_default_252 : [num_users=1] = placeholder[target=aten_permute_copy_default_252]\n",
      "      %aten_addmm_default_136 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_bias, %aten_view_copy_default_470, %aten_permute_copy_default_252), kwargs = {})\n",
      "      return (aten_addmm_default_136,)\n",
      "  %executorch_call_delegate_90 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_90, %aten_view_copy_default_470, %aten_permute_copy_default_136), kwargs = {})\n",
      "  %getitem_183 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_90, 0), kwargs = {})\n",
      "  %aten_view_copy_default_471 : [num_users=3] = call_function[target=executorch.exir.memory.view](args = (%getitem_183, [1, %sym_size_8, 4096]), kwargs = {})\n",
      "  %alloc_749 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_68 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_471, %_lifted_tensor_constant50), kwargs = {out: %alloc_749})\n",
      "  %sym_size_54 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_471, 1), kwargs = {})\n",
      "  %alloc_750 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_sigmoid_default_22 : [num_users=1] = call_function[target=torch.ops.aten.sigmoid.out](args = (%aten_mul_tensor_68,), kwargs = {out: %alloc_750})\n",
      "  %alloc_751 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 4096), torch.float32),), kwargs = {})\n",
      "  %aten_mul_tensor_69 : [num_users=1] = call_function[target=torch.ops.aten.mul.out](args = (%aten_view_copy_default_471, %aten_sigmoid_default_22), kwargs = {out: %alloc_751})\n",
      "  %aten_view_copy_default_472 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_mul_tensor_69, [%sym_size_54, 4096]), kwargs = {})\n",
      "  %lowered_module_91 : [num_users=1] = get_attr[target=lowered_module_91]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_bias]\n",
      "      %aten_view_copy_default_472 : [num_users=1] = placeholder[target=aten_view_copy_default_472]\n",
      "      %aten_permute_copy_default_253 : [num_users=1] = placeholder[target=aten_permute_copy_default_253]\n",
      "      %aten_addmm_default_137 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_bias, %aten_view_copy_default_472, %aten_permute_copy_default_253), kwargs = {})\n",
      "      return (aten_addmm_default_137,)\n",
      "  %executorch_call_delegate_91 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_91, %aten_view_copy_default_472, %aten_permute_copy_default_137), kwargs = {})\n",
      "  %getitem_184 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_91, 0), kwargs = {})\n",
      "  %aten_view_copy_default_473 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%getitem_184, [1, %sym_size_54, 1024]), kwargs = {})\n",
      "  %alloc_752 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_add_tensor_46 : [num_users=1] = call_function[target=torch.ops.aten.add.out](args = (%aten_add_tensor_45, %aten_view_copy_default_473), kwargs = {out: %alloc_752})\n",
      "  %alloc_753 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)) + 1, 1024), torch.float32),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_add_tensor_46, 0, 0, 9223372036854775807), kwargs = {out: %alloc_753})\n",
      "  %alloc_754 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)), 1024), torch.float32),), kwargs = {})\n",
      "  %aten_slice_copy_tensor_9 : [num_users=2] = call_function[target=torch.ops.aten.slice_copy.Tensor_out](args = (%aten_slice_copy_tensor_8, 1, 1, 9223372036854775807), kwargs = {out: %alloc_754})\n",
      "  %sym_size_55 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_slice_copy_tensor_9, 1), kwargs = {})\n",
      "  %aten_view_copy_default_474 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_slice_copy_tensor_9, [%sym_size_55, 1024]), kwargs = {})\n",
      "  %lowered_module_92 : [num_users=1] = get_attr[target=lowered_module_92]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_mm_projector___0___bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_mm_projector___0___bias]\n",
      "      %aten_view_copy_default_474 : [num_users=1] = placeholder[target=aten_view_copy_default_474]\n",
      "      %aten_permute_copy_default_254 : [num_users=1] = placeholder[target=aten_permute_copy_default_254]\n",
      "      %aten_addmm_default_138 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_mm_projector___0___bias, %aten_view_copy_default_474, %aten_permute_copy_default_254), kwargs = {})\n",
      "      return (aten_addmm_default_138,)\n",
      "  %executorch_call_delegate_92 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_92, %aten_view_copy_default_474, %aten_permute_copy_default_138), kwargs = {})\n",
      "  %getitem_185 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_92, 0), kwargs = {})\n",
      "  %aten_view_copy_default_475 : [num_users=2] = call_function[target=executorch.exir.memory.view](args = (%getitem_185, [1, %sym_size_55, 4096]), kwargs = {})\n",
      "  %alloc_755 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)), 4096), torch.float32),), kwargs = {})\n",
      "  %aten_gelu_default : [num_users=1] = call_function[target=torch.ops.aten.gelu.out](args = (%aten_view_copy_default_475,), kwargs = {out: %alloc_755})\n",
      "  %sym_size_56 : [num_users=2] = call_function[target=torch.ops.aten.sym_size.int](args = (%aten_view_copy_default_475, 1), kwargs = {})\n",
      "  %aten_view_copy_default_476 : [num_users=1] = call_function[target=executorch.exir.memory.view](args = (%aten_gelu_default, [%sym_size_56, 4096]), kwargs = {})\n",
      "  %lowered_module_93 : [num_users=1] = get_attr[target=lowered_module_93]\n",
      "    backend_id: XnnpackBackend\n",
      "    lowered graph():\n",
      "      %p_getattr_l__self___llava_mm_projector___2___bias : [num_users=1] = placeholder[target=p_getattr_l__self___llava_mm_projector___2___bias]\n",
      "      %aten_view_copy_default_476 : [num_users=1] = placeholder[target=aten_view_copy_default_476]\n",
      "      %aten_permute_copy_default_255 : [num_users=1] = placeholder[target=aten_permute_copy_default_255]\n",
      "      %aten_addmm_default_139 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.addmm.default](args = (%p_getattr_l__self___llava_mm_projector___2___bias, %aten_view_copy_default_476, %aten_permute_copy_default_255), kwargs = {})\n",
      "      return (aten_addmm_default_139,)\n",
      "  %executorch_call_delegate_93 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_93, %aten_view_copy_default_476, %aten_permute_copy_default_139), kwargs = {})\n",
      "  %getitem_186 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_93, 0), kwargs = {})\n",
      "  %alloc_756 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, ((s0//14))*((s1//14)) + 8*((s1//14)), 4096), torch.float32),), kwargs = {})\n",
      "  %aten_view_copy_default_477 : [num_users=1] = call_function[target=torch.ops.aten.view_copy.out](args = (%getitem_186, [1, %sym_size_56, 4096]), kwargs = {out: %alloc_756})\n",
      "  return (aten_view_copy_default_477,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir.backend.utils import print_delegated_graph\n",
    "\n",
    "print_delegated_graph(executorch_program.exported_program(\"image_encoder\").graph_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, p_llava_vision_tower_vision_tower_vision_model_embeddings_class_embedding, p_llava_vision_tower_vision_tower_vision_model_embeddings_patch_embedding_weight, p_llava_vision_tower_vision_tower_vision_model_embeddings_position_embedding_weight, p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_weight, p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_bias, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_bias, p_getattr_l__self___llava_mm_projector___0___weight, p_getattr_l__self___llava_mm_projector___0___bias, p_getattr_l__self___llava_mm_projector___2___weight, p_getattr_l__self___llava_mm_projector___2___bias, b_llava_vision_tower_vision_tower_vision_model_embeddings_position_ids, b_lifted_tensor_0, b_lifted_tensor_1, b_lifted_tensor_2, b__tensor_constant_0, b__tensor_constant_1, b__tensor_constant_2, b__tensor_constant_3, b__tensor_constant_4, b__tensor_constant_5, b__tensor_constant_6, b__tensor_constant_7, b__tensor_constant_8, b__tensor_constant_9, b__tensor_constant_10, b__tensor_constant_11, b__tensor_constant_12, b__tensor_constant_13, b__tensor_constant_14, b__tensor_constant_15, b__tensor_constant_16, b__tensor_constant_17, b__tensor_constant_18, b__tensor_constant_19, b__tensor_constant_20, b__tensor_constant_21, b__tensor_constant_22, b__tensor_constant_23, b__tensor_constant_24, b__tensor_constant_25, b__tensor_constant_26, b__tensor_constant_27, b__tensor_constant_28, b__tensor_constant_29, b__tensor_constant_30, b__tensor_constant_31, b__tensor_constant_32, b__tensor_constant_33, b__tensor_constant_34, b__tensor_constant_35, b__tensor_constant_36, b__tensor_constant_37, b__tensor_constant_38, b__tensor_constant_39, b__tensor_constant_40, b__tensor_constant_41, b__tensor_constant_42, b__tensor_constant_43, b__tensor_constant_44, b__tensor_constant_45, b__tensor_constant_46, image):\n",
      "    sym_size_int = torch.ops.aten.sym_size.int(image, 1)\n",
      "    sym_size_int_1 = torch.ops.aten.sym_size.int(image, 2)\n",
      "    view = torch.ops.aten.view.default(image, [1, 3, sym_size_int, sym_size_int_1]);  image = sym_size_int = sym_size_int_1 = None\n",
      "    pad = torch.ops.aten.pad.default(view, [0, 0, 56, 56], 'constant', 0.0);  view = None\n",
      "    sym_size_int_2 = torch.ops.aten.sym_size.int(pad, 2)\n",
      "    sym_size_int_3 = torch.ops.aten.sym_size.int(pad, 3)\n",
      "    view_1 = torch.ops.aten.view.default(pad, [3, sym_size_int_2, sym_size_int_3])\n",
      "    clone = torch.ops.aten.clone.default(b_lifted_tensor_0);  b_lifted_tensor_0 = None\n",
      "    detach = torch.ops.aten.detach.default(clone);  clone = None\n",
      "    _to_copy = torch.ops.aten._to_copy.default(detach, dtype = torch.uint8);  detach = None\n",
      "    view_2 = torch.ops.aten.view.default(_to_copy, [-1, 1, 1]);  _to_copy = None\n",
      "    slice_1 = torch.ops.aten.slice.Tensor(view_1, 1, 0, 56)\n",
      "    slice_2 = torch.ops.aten.slice.Tensor(slice_1, 2, 0, 9223372036854775807);  slice_1 = None\n",
      "    view_3 = torch.ops.aten.view.default(view_2, [3, 1, 1])\n",
      "    sym_size_int_4 = torch.ops.aten.sym_size.int(slice_2, 2)\n",
      "    expand = torch.ops.aten.expand.default(view_3, [3, 56, sym_size_int_4]);  view_3 = sym_size_int_4 = None\n",
      "    copy = torch.ops.aten.copy.default(slice_2, expand);  slice_2 = expand = None\n",
      "    view_4 = torch.ops.aten.view.default(pad, [3, sym_size_int_2, sym_size_int_3]);  pad = None\n",
      "    slice_3 = torch.ops.aten.slice.Tensor(view_4, 1, 0, 56)\n",
      "    slice_scatter = torch.ops.aten.slice_scatter.default(slice_3, copy, 2, 0, 9223372036854775807);  slice_3 = copy = None\n",
      "    slice_scatter_1 = torch.ops.aten.slice_scatter.default(view_4, slice_scatter, 1, 0, 56);  view_4 = slice_scatter = None\n",
      "    view_5 = torch.ops.aten.view.default(slice_scatter_1, [1, 3, sym_size_int_2, sym_size_int_3]);  slice_scatter_1 = None\n",
      "    slice_4 = torch.ops.aten.slice.Tensor(view_1, 1, -56, 9223372036854775807);  view_1 = None\n",
      "    slice_5 = torch.ops.aten.slice.Tensor(slice_4, 2, 0, 9223372036854775807);  slice_4 = None\n",
      "    view_6 = torch.ops.aten.view.default(view_2, [3, 1, 1]);  view_2 = None\n",
      "    sym_size_int_5 = torch.ops.aten.sym_size.int(slice_5, 2);  slice_5 = None\n",
      "    expand_1 = torch.ops.aten.expand.default(view_6, [3, 56, sym_size_int_5]);  view_6 = sym_size_int_5 = None\n",
      "    view_7 = torch.ops.aten.view.default(view_5, [3, sym_size_int_2, sym_size_int_3])\n",
      "    slice_6 = torch.ops.aten.slice.Tensor(view_7, 1, -56, 9223372036854775807);  view_7 = None\n",
      "    slice_7 = torch.ops.aten.slice.Tensor(slice_6, 2, 0, 9223372036854775807);  slice_6 = None\n",
      "    copy_1 = torch.ops.aten.copy.default(slice_7, expand_1);  slice_7 = expand_1 = None\n",
      "    view_8 = torch.ops.aten.view.default(view_5, [3, sym_size_int_2, sym_size_int_3]);  view_5 = None\n",
      "    slice_8 = torch.ops.aten.slice.Tensor(view_8, 1, -56, 9223372036854775807)\n",
      "    slice_scatter_2 = torch.ops.aten.slice_scatter.default(slice_8, copy_1, 2, 0, 9223372036854775807);  slice_8 = copy_1 = None\n",
      "    slice_scatter_3 = torch.ops.aten.slice_scatter.default(view_8, slice_scatter_2, 1, -56, 9223372036854775807);  view_8 = slice_scatter_2 = None\n",
      "    view_9 = torch.ops.aten.view.default(slice_scatter_3, [1, 3, sym_size_int_2, sym_size_int_3]);  slice_scatter_3 = None\n",
      "    view_10 = torch.ops.aten.view.default(view_9, [3, sym_size_int_2, sym_size_int_3]);  view_9 = sym_size_int_2 = sym_size_int_3 = None\n",
      "    mul = torch.ops.aten.mul.Tensor(view_10, b__tensor_constant_0);  view_10 = b__tensor_constant_0 = None\n",
      "    clone_1 = torch.ops.aten.clone.default(b_lifted_tensor_1);  b_lifted_tensor_1 = None\n",
      "    clone_2 = torch.ops.aten.clone.default(b_lifted_tensor_2);  b_lifted_tensor_2 = None\n",
      "    view_11 = torch.ops.aten.view.default(clone_1, [-1, 1, 1]);  clone_1 = None\n",
      "    view_12 = torch.ops.aten.view.default(clone_2, [-1, 1, 1]);  clone_2 = None\n",
      "    sub = torch.ops.aten.sub.Tensor(mul, view_11);  mul = view_11 = None\n",
      "    div = torch.ops.aten.div.Tensor(sub, view_12);  sub = view_12 = None\n",
      "    unsqueeze = torch.ops.aten.unsqueeze.default(div, 0);  div = None\n",
      "    _to_copy_1 = torch.ops.aten._to_copy.default(unsqueeze, dtype = torch.float32);  unsqueeze = None\n",
      "    _to_copy_2 = torch.ops.aten._to_copy.default(_to_copy_1, dtype = torch.float32, device = device(type='cpu'));  _to_copy_1 = None\n",
      "    _to_copy_3 = torch.ops.aten._to_copy.default(_to_copy_2, dtype = torch.float32);  _to_copy_2 = None\n",
      "    conv2d = torch.ops.aten.conv2d.default(_to_copy_3, p_llava_vision_tower_vision_tower_vision_model_embeddings_patch_embedding_weight, None, [14, 14]);  _to_copy_3 = p_llava_vision_tower_vision_tower_vision_model_embeddings_patch_embedding_weight = None\n",
      "    sym_size_int_6 = torch.ops.aten.sym_size.int(conv2d, 2)\n",
      "    sym_size_int_7 = torch.ops.aten.sym_size.int(conv2d, 3)\n",
      "    mul_1 = sym_size_int_6 * sym_size_int_7;  sym_size_int_6 = sym_size_int_7 = None\n",
      "    view_13 = torch.ops.aten.view.default(conv2d, [1, 1024, mul_1]);  conv2d = mul_1 = None\n",
      "    transpose = torch.ops.aten.transpose.int(view_13, 1, 2);  view_13 = None\n",
      "    expand_2 = torch.ops.aten.expand.default(p_llava_vision_tower_vision_tower_vision_model_embeddings_class_embedding, [1, 1, -1]);  p_llava_vision_tower_vision_tower_vision_model_embeddings_class_embedding = None\n",
      "    cat = torch.ops.aten.cat.default([expand_2, transpose], 1);  expand_2 = transpose = None\n",
      "    embedding = torch.ops.aten.embedding.default(p_llava_vision_tower_vision_tower_vision_model_embeddings_position_embedding_weight, b_llava_vision_tower_vision_tower_vision_model_embeddings_position_ids);  p_llava_vision_tower_vision_tower_vision_model_embeddings_position_embedding_weight = b_llava_vision_tower_vision_tower_vision_model_embeddings_position_ids = None\n",
      "    add = torch.ops.aten.add.Tensor(cat, embedding);  embedding = None\n",
      "    layer_norm = torch.ops.aten.layer_norm.default(add, [1024], p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_weight, p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_bias);  add = p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_weight = p_llava_vision_tower_vision_tower_vision_model_pre_layrnorm_bias = None\n",
      "    layer_norm_1 = torch.ops.aten.layer_norm.default(layer_norm, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm1_bias = None\n",
      "    linear = torch.ops.aten.linear.default(layer_norm_1, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_q_proj_bias = None\n",
      "    mul_2 = torch.ops.aten.mul.Tensor(linear, b__tensor_constant_1);  linear = b__tensor_constant_1 = None\n",
      "    linear_1 = torch.ops.aten.linear.default(layer_norm_1, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_k_proj_bias = None\n",
      "    view_14 = torch.ops.aten.view.default(linear_1, [1, -1, 16, 64]);  linear_1 = None\n",
      "    transpose_1 = torch.ops.aten.transpose.int(view_14, 1, 2);  view_14 = None\n",
      "    clone_3 = torch.ops.aten.clone.default(transpose_1, memory_format = torch.contiguous_format);  transpose_1 = None\n",
      "    linear_2 = torch.ops.aten.linear.default(layer_norm_1, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_bias);  layer_norm_1 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_v_proj_bias = None\n",
      "    view_15 = torch.ops.aten.view.default(linear_2, [1, -1, 16, 64]);  linear_2 = None\n",
      "    transpose_2 = torch.ops.aten.transpose.int(view_15, 1, 2);  view_15 = None\n",
      "    clone_4 = torch.ops.aten.clone.default(transpose_2, memory_format = torch.contiguous_format);  transpose_2 = None\n",
      "    sym_size_int_8 = torch.ops.aten.sym_size.int(cat, 1);  cat = None\n",
      "    view_16 = torch.ops.aten.view.default(mul_2, [1, sym_size_int_8, 16, 64]);  mul_2 = None\n",
      "    transpose_3 = torch.ops.aten.transpose.int(view_16, 1, 2);  view_16 = None\n",
      "    clone_5 = torch.ops.aten.clone.default(transpose_3, memory_format = torch.contiguous_format);  transpose_3 = None\n",
      "    view_17 = torch.ops.aten.view.default(clone_5, [16, -1, 64]);  clone_5 = None\n",
      "    view_18 = torch.ops.aten.view.default(clone_3, [16, -1, 64]);  clone_3 = None\n",
      "    view_19 = torch.ops.aten.view.default(clone_4, [16, -1, 64]);  clone_4 = None\n",
      "    transpose_4 = torch.ops.aten.transpose.int(view_18, 1, 2);  view_18 = None\n",
      "    bmm = torch.ops.aten.bmm.default(view_17, transpose_4);  view_17 = transpose_4 = None\n",
      "    softmax = torch.ops.aten.softmax.int(bmm, -1);  bmm = None\n",
      "    dropout = torch.ops.aten.dropout.default(softmax, 0.0, False);  softmax = None\n",
      "    bmm_1 = torch.ops.aten.bmm.default(dropout, view_19);  dropout = view_19 = None\n",
      "    view_20 = torch.ops.aten.view.default(bmm_1, [1, 16, sym_size_int_8, 64]);  bmm_1 = None\n",
      "    transpose_5 = torch.ops.aten.transpose.int(view_20, 1, 2);  view_20 = None\n",
      "    clone_6 = torch.ops.aten.clone.default(transpose_5, memory_format = torch.contiguous_format);  transpose_5 = None\n",
      "    _unsafe_view = torch.ops.aten._unsafe_view.default(clone_6, [1, sym_size_int_8, 1024]);  clone_6 = None\n",
      "    linear_3 = torch.ops.aten.linear.default(_unsafe_view, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_bias);  _unsafe_view = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___self_attn_out_proj_bias = None\n",
      "    add_1 = torch.ops.aten.add.Tensor(layer_norm, linear_3);  layer_norm = linear_3 = None\n",
      "    layer_norm_2 = torch.ops.aten.layer_norm.default(add_1, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___layer_norm2_bias = None\n",
      "    linear_4 = torch.ops.aten.linear.default(layer_norm_2, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_bias);  layer_norm_2 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc1_bias = None\n",
      "    mul_3 = torch.ops.aten.mul.Tensor(linear_4, b__tensor_constant_2);  b__tensor_constant_2 = None\n",
      "    sigmoid = torch.ops.aten.sigmoid.default(mul_3);  mul_3 = None\n",
      "    mul_4 = torch.ops.aten.mul.Tensor(linear_4, sigmoid);  linear_4 = sigmoid = None\n",
      "    linear_5 = torch.ops.aten.linear.default(mul_4, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_bias);  mul_4 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___0___mlp_fc2_bias = None\n",
      "    add_2 = torch.ops.aten.add.Tensor(add_1, linear_5);  add_1 = linear_5 = None\n",
      "    layer_norm_3 = torch.ops.aten.layer_norm.default(add_2, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm1_bias = None\n",
      "    linear_6 = torch.ops.aten.linear.default(layer_norm_3, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_q_proj_bias = None\n",
      "    mul_5 = torch.ops.aten.mul.Tensor(linear_6, b__tensor_constant_3);  linear_6 = b__tensor_constant_3 = None\n",
      "    linear_7 = torch.ops.aten.linear.default(layer_norm_3, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_k_proj_bias = None\n",
      "    view_21 = torch.ops.aten.view.default(linear_7, [1, -1, 16, 64]);  linear_7 = None\n",
      "    transpose_6 = torch.ops.aten.transpose.int(view_21, 1, 2);  view_21 = None\n",
      "    clone_7 = torch.ops.aten.clone.default(transpose_6, memory_format = torch.contiguous_format);  transpose_6 = None\n",
      "    linear_8 = torch.ops.aten.linear.default(layer_norm_3, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_bias);  layer_norm_3 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_v_proj_bias = None\n",
      "    view_22 = torch.ops.aten.view.default(linear_8, [1, -1, 16, 64]);  linear_8 = None\n",
      "    transpose_7 = torch.ops.aten.transpose.int(view_22, 1, 2);  view_22 = None\n",
      "    clone_8 = torch.ops.aten.clone.default(transpose_7, memory_format = torch.contiguous_format);  transpose_7 = None\n",
      "    view_23 = torch.ops.aten.view.default(mul_5, [1, sym_size_int_8, 16, 64]);  mul_5 = None\n",
      "    transpose_8 = torch.ops.aten.transpose.int(view_23, 1, 2);  view_23 = None\n",
      "    clone_9 = torch.ops.aten.clone.default(transpose_8, memory_format = torch.contiguous_format);  transpose_8 = None\n",
      "    view_24 = torch.ops.aten.view.default(clone_9, [16, -1, 64]);  clone_9 = None\n",
      "    view_25 = torch.ops.aten.view.default(clone_7, [16, -1, 64]);  clone_7 = None\n",
      "    view_26 = torch.ops.aten.view.default(clone_8, [16, -1, 64]);  clone_8 = None\n",
      "    transpose_9 = torch.ops.aten.transpose.int(view_25, 1, 2);  view_25 = None\n",
      "    bmm_2 = torch.ops.aten.bmm.default(view_24, transpose_9);  view_24 = transpose_9 = None\n",
      "    softmax_1 = torch.ops.aten.softmax.int(bmm_2, -1);  bmm_2 = None\n",
      "    dropout_1 = torch.ops.aten.dropout.default(softmax_1, 0.0, False);  softmax_1 = None\n",
      "    bmm_3 = torch.ops.aten.bmm.default(dropout_1, view_26);  dropout_1 = view_26 = None\n",
      "    view_27 = torch.ops.aten.view.default(bmm_3, [1, 16, sym_size_int_8, 64]);  bmm_3 = None\n",
      "    transpose_10 = torch.ops.aten.transpose.int(view_27, 1, 2);  view_27 = None\n",
      "    clone_10 = torch.ops.aten.clone.default(transpose_10, memory_format = torch.contiguous_format);  transpose_10 = None\n",
      "    _unsafe_view_1 = torch.ops.aten._unsafe_view.default(clone_10, [1, sym_size_int_8, 1024]);  clone_10 = None\n",
      "    linear_9 = torch.ops.aten.linear.default(_unsafe_view_1, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_bias);  _unsafe_view_1 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___self_attn_out_proj_bias = None\n",
      "    add_3 = torch.ops.aten.add.Tensor(add_2, linear_9);  add_2 = linear_9 = None\n",
      "    layer_norm_4 = torch.ops.aten.layer_norm.default(add_3, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___layer_norm2_bias = None\n",
      "    linear_10 = torch.ops.aten.linear.default(layer_norm_4, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_bias);  layer_norm_4 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc1_bias = None\n",
      "    mul_6 = torch.ops.aten.mul.Tensor(linear_10, b__tensor_constant_4);  b__tensor_constant_4 = None\n",
      "    sigmoid_1 = torch.ops.aten.sigmoid.default(mul_6);  mul_6 = None\n",
      "    mul_7 = torch.ops.aten.mul.Tensor(linear_10, sigmoid_1);  linear_10 = sigmoid_1 = None\n",
      "    linear_11 = torch.ops.aten.linear.default(mul_7, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_bias);  mul_7 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___1___mlp_fc2_bias = None\n",
      "    add_4 = torch.ops.aten.add.Tensor(add_3, linear_11);  add_3 = linear_11 = None\n",
      "    layer_norm_5 = torch.ops.aten.layer_norm.default(add_4, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm1_bias = None\n",
      "    linear_12 = torch.ops.aten.linear.default(layer_norm_5, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_q_proj_bias = None\n",
      "    mul_8 = torch.ops.aten.mul.Tensor(linear_12, b__tensor_constant_5);  linear_12 = b__tensor_constant_5 = None\n",
      "    linear_13 = torch.ops.aten.linear.default(layer_norm_5, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_k_proj_bias = None\n",
      "    view_28 = torch.ops.aten.view.default(linear_13, [1, -1, 16, 64]);  linear_13 = None\n",
      "    transpose_11 = torch.ops.aten.transpose.int(view_28, 1, 2);  view_28 = None\n",
      "    clone_11 = torch.ops.aten.clone.default(transpose_11, memory_format = torch.contiguous_format);  transpose_11 = None\n",
      "    linear_14 = torch.ops.aten.linear.default(layer_norm_5, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_bias);  layer_norm_5 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_v_proj_bias = None\n",
      "    view_29 = torch.ops.aten.view.default(linear_14, [1, -1, 16, 64]);  linear_14 = None\n",
      "    transpose_12 = torch.ops.aten.transpose.int(view_29, 1, 2);  view_29 = None\n",
      "    clone_12 = torch.ops.aten.clone.default(transpose_12, memory_format = torch.contiguous_format);  transpose_12 = None\n",
      "    view_30 = torch.ops.aten.view.default(mul_8, [1, sym_size_int_8, 16, 64]);  mul_8 = None\n",
      "    transpose_13 = torch.ops.aten.transpose.int(view_30, 1, 2);  view_30 = None\n",
      "    clone_13 = torch.ops.aten.clone.default(transpose_13, memory_format = torch.contiguous_format);  transpose_13 = None\n",
      "    view_31 = torch.ops.aten.view.default(clone_13, [16, -1, 64]);  clone_13 = None\n",
      "    view_32 = torch.ops.aten.view.default(clone_11, [16, -1, 64]);  clone_11 = None\n",
      "    view_33 = torch.ops.aten.view.default(clone_12, [16, -1, 64]);  clone_12 = None\n",
      "    transpose_14 = torch.ops.aten.transpose.int(view_32, 1, 2);  view_32 = None\n",
      "    bmm_4 = torch.ops.aten.bmm.default(view_31, transpose_14);  view_31 = transpose_14 = None\n",
      "    softmax_2 = torch.ops.aten.softmax.int(bmm_4, -1);  bmm_4 = None\n",
      "    dropout_2 = torch.ops.aten.dropout.default(softmax_2, 0.0, False);  softmax_2 = None\n",
      "    bmm_5 = torch.ops.aten.bmm.default(dropout_2, view_33);  dropout_2 = view_33 = None\n",
      "    view_34 = torch.ops.aten.view.default(bmm_5, [1, 16, sym_size_int_8, 64]);  bmm_5 = None\n",
      "    transpose_15 = torch.ops.aten.transpose.int(view_34, 1, 2);  view_34 = None\n",
      "    clone_14 = torch.ops.aten.clone.default(transpose_15, memory_format = torch.contiguous_format);  transpose_15 = None\n",
      "    _unsafe_view_2 = torch.ops.aten._unsafe_view.default(clone_14, [1, sym_size_int_8, 1024]);  clone_14 = None\n",
      "    linear_15 = torch.ops.aten.linear.default(_unsafe_view_2, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_bias);  _unsafe_view_2 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___self_attn_out_proj_bias = None\n",
      "    add_5 = torch.ops.aten.add.Tensor(add_4, linear_15);  add_4 = linear_15 = None\n",
      "    layer_norm_6 = torch.ops.aten.layer_norm.default(add_5, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___layer_norm2_bias = None\n",
      "    linear_16 = torch.ops.aten.linear.default(layer_norm_6, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_bias);  layer_norm_6 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc1_bias = None\n",
      "    mul_9 = torch.ops.aten.mul.Tensor(linear_16, b__tensor_constant_6);  b__tensor_constant_6 = None\n",
      "    sigmoid_2 = torch.ops.aten.sigmoid.default(mul_9);  mul_9 = None\n",
      "    mul_10 = torch.ops.aten.mul.Tensor(linear_16, sigmoid_2);  linear_16 = sigmoid_2 = None\n",
      "    linear_17 = torch.ops.aten.linear.default(mul_10, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_bias);  mul_10 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___2___mlp_fc2_bias = None\n",
      "    add_6 = torch.ops.aten.add.Tensor(add_5, linear_17);  add_5 = linear_17 = None\n",
      "    layer_norm_7 = torch.ops.aten.layer_norm.default(add_6, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm1_bias = None\n",
      "    linear_18 = torch.ops.aten.linear.default(layer_norm_7, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_q_proj_bias = None\n",
      "    mul_11 = torch.ops.aten.mul.Tensor(linear_18, b__tensor_constant_7);  linear_18 = b__tensor_constant_7 = None\n",
      "    linear_19 = torch.ops.aten.linear.default(layer_norm_7, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_k_proj_bias = None\n",
      "    view_35 = torch.ops.aten.view.default(linear_19, [1, -1, 16, 64]);  linear_19 = None\n",
      "    transpose_16 = torch.ops.aten.transpose.int(view_35, 1, 2);  view_35 = None\n",
      "    clone_15 = torch.ops.aten.clone.default(transpose_16, memory_format = torch.contiguous_format);  transpose_16 = None\n",
      "    linear_20 = torch.ops.aten.linear.default(layer_norm_7, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_bias);  layer_norm_7 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_v_proj_bias = None\n",
      "    view_36 = torch.ops.aten.view.default(linear_20, [1, -1, 16, 64]);  linear_20 = None\n",
      "    transpose_17 = torch.ops.aten.transpose.int(view_36, 1, 2);  view_36 = None\n",
      "    clone_16 = torch.ops.aten.clone.default(transpose_17, memory_format = torch.contiguous_format);  transpose_17 = None\n",
      "    view_37 = torch.ops.aten.view.default(mul_11, [1, sym_size_int_8, 16, 64]);  mul_11 = None\n",
      "    transpose_18 = torch.ops.aten.transpose.int(view_37, 1, 2);  view_37 = None\n",
      "    clone_17 = torch.ops.aten.clone.default(transpose_18, memory_format = torch.contiguous_format);  transpose_18 = None\n",
      "    view_38 = torch.ops.aten.view.default(clone_17, [16, -1, 64]);  clone_17 = None\n",
      "    view_39 = torch.ops.aten.view.default(clone_15, [16, -1, 64]);  clone_15 = None\n",
      "    view_40 = torch.ops.aten.view.default(clone_16, [16, -1, 64]);  clone_16 = None\n",
      "    transpose_19 = torch.ops.aten.transpose.int(view_39, 1, 2);  view_39 = None\n",
      "    bmm_6 = torch.ops.aten.bmm.default(view_38, transpose_19);  view_38 = transpose_19 = None\n",
      "    softmax_3 = torch.ops.aten.softmax.int(bmm_6, -1);  bmm_6 = None\n",
      "    dropout_3 = torch.ops.aten.dropout.default(softmax_3, 0.0, False);  softmax_3 = None\n",
      "    bmm_7 = torch.ops.aten.bmm.default(dropout_3, view_40);  dropout_3 = view_40 = None\n",
      "    view_41 = torch.ops.aten.view.default(bmm_7, [1, 16, sym_size_int_8, 64]);  bmm_7 = None\n",
      "    transpose_20 = torch.ops.aten.transpose.int(view_41, 1, 2);  view_41 = None\n",
      "    clone_18 = torch.ops.aten.clone.default(transpose_20, memory_format = torch.contiguous_format);  transpose_20 = None\n",
      "    _unsafe_view_3 = torch.ops.aten._unsafe_view.default(clone_18, [1, sym_size_int_8, 1024]);  clone_18 = None\n",
      "    linear_21 = torch.ops.aten.linear.default(_unsafe_view_3, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_bias);  _unsafe_view_3 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___self_attn_out_proj_bias = None\n",
      "    add_7 = torch.ops.aten.add.Tensor(add_6, linear_21);  add_6 = linear_21 = None\n",
      "    layer_norm_8 = torch.ops.aten.layer_norm.default(add_7, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___layer_norm2_bias = None\n",
      "    linear_22 = torch.ops.aten.linear.default(layer_norm_8, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_bias);  layer_norm_8 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc1_bias = None\n",
      "    mul_12 = torch.ops.aten.mul.Tensor(linear_22, b__tensor_constant_8);  b__tensor_constant_8 = None\n",
      "    sigmoid_3 = torch.ops.aten.sigmoid.default(mul_12);  mul_12 = None\n",
      "    mul_13 = torch.ops.aten.mul.Tensor(linear_22, sigmoid_3);  linear_22 = sigmoid_3 = None\n",
      "    linear_23 = torch.ops.aten.linear.default(mul_13, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_bias);  mul_13 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___3___mlp_fc2_bias = None\n",
      "    add_8 = torch.ops.aten.add.Tensor(add_7, linear_23);  add_7 = linear_23 = None\n",
      "    layer_norm_9 = torch.ops.aten.layer_norm.default(add_8, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm1_bias = None\n",
      "    linear_24 = torch.ops.aten.linear.default(layer_norm_9, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_q_proj_bias = None\n",
      "    mul_14 = torch.ops.aten.mul.Tensor(linear_24, b__tensor_constant_9);  linear_24 = b__tensor_constant_9 = None\n",
      "    linear_25 = torch.ops.aten.linear.default(layer_norm_9, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_k_proj_bias = None\n",
      "    view_42 = torch.ops.aten.view.default(linear_25, [1, -1, 16, 64]);  linear_25 = None\n",
      "    transpose_21 = torch.ops.aten.transpose.int(view_42, 1, 2);  view_42 = None\n",
      "    clone_19 = torch.ops.aten.clone.default(transpose_21, memory_format = torch.contiguous_format);  transpose_21 = None\n",
      "    linear_26 = torch.ops.aten.linear.default(layer_norm_9, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_bias);  layer_norm_9 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_v_proj_bias = None\n",
      "    view_43 = torch.ops.aten.view.default(linear_26, [1, -1, 16, 64]);  linear_26 = None\n",
      "    transpose_22 = torch.ops.aten.transpose.int(view_43, 1, 2);  view_43 = None\n",
      "    clone_20 = torch.ops.aten.clone.default(transpose_22, memory_format = torch.contiguous_format);  transpose_22 = None\n",
      "    view_44 = torch.ops.aten.view.default(mul_14, [1, sym_size_int_8, 16, 64]);  mul_14 = None\n",
      "    transpose_23 = torch.ops.aten.transpose.int(view_44, 1, 2);  view_44 = None\n",
      "    clone_21 = torch.ops.aten.clone.default(transpose_23, memory_format = torch.contiguous_format);  transpose_23 = None\n",
      "    view_45 = torch.ops.aten.view.default(clone_21, [16, -1, 64]);  clone_21 = None\n",
      "    view_46 = torch.ops.aten.view.default(clone_19, [16, -1, 64]);  clone_19 = None\n",
      "    view_47 = torch.ops.aten.view.default(clone_20, [16, -1, 64]);  clone_20 = None\n",
      "    transpose_24 = torch.ops.aten.transpose.int(view_46, 1, 2);  view_46 = None\n",
      "    bmm_8 = torch.ops.aten.bmm.default(view_45, transpose_24);  view_45 = transpose_24 = None\n",
      "    softmax_4 = torch.ops.aten.softmax.int(bmm_8, -1);  bmm_8 = None\n",
      "    dropout_4 = torch.ops.aten.dropout.default(softmax_4, 0.0, False);  softmax_4 = None\n",
      "    bmm_9 = torch.ops.aten.bmm.default(dropout_4, view_47);  dropout_4 = view_47 = None\n",
      "    view_48 = torch.ops.aten.view.default(bmm_9, [1, 16, sym_size_int_8, 64]);  bmm_9 = None\n",
      "    transpose_25 = torch.ops.aten.transpose.int(view_48, 1, 2);  view_48 = None\n",
      "    clone_22 = torch.ops.aten.clone.default(transpose_25, memory_format = torch.contiguous_format);  transpose_25 = None\n",
      "    _unsafe_view_4 = torch.ops.aten._unsafe_view.default(clone_22, [1, sym_size_int_8, 1024]);  clone_22 = None\n",
      "    linear_27 = torch.ops.aten.linear.default(_unsafe_view_4, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_bias);  _unsafe_view_4 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___self_attn_out_proj_bias = None\n",
      "    add_9 = torch.ops.aten.add.Tensor(add_8, linear_27);  add_8 = linear_27 = None\n",
      "    layer_norm_10 = torch.ops.aten.layer_norm.default(add_9, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___layer_norm2_bias = None\n",
      "    linear_28 = torch.ops.aten.linear.default(layer_norm_10, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_bias);  layer_norm_10 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc1_bias = None\n",
      "    mul_15 = torch.ops.aten.mul.Tensor(linear_28, b__tensor_constant_10);  b__tensor_constant_10 = None\n",
      "    sigmoid_4 = torch.ops.aten.sigmoid.default(mul_15);  mul_15 = None\n",
      "    mul_16 = torch.ops.aten.mul.Tensor(linear_28, sigmoid_4);  linear_28 = sigmoid_4 = None\n",
      "    linear_29 = torch.ops.aten.linear.default(mul_16, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_bias);  mul_16 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___4___mlp_fc2_bias = None\n",
      "    add_10 = torch.ops.aten.add.Tensor(add_9, linear_29);  add_9 = linear_29 = None\n",
      "    layer_norm_11 = torch.ops.aten.layer_norm.default(add_10, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm1_bias = None\n",
      "    linear_30 = torch.ops.aten.linear.default(layer_norm_11, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_q_proj_bias = None\n",
      "    mul_17 = torch.ops.aten.mul.Tensor(linear_30, b__tensor_constant_11);  linear_30 = b__tensor_constant_11 = None\n",
      "    linear_31 = torch.ops.aten.linear.default(layer_norm_11, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_k_proj_bias = None\n",
      "    view_49 = torch.ops.aten.view.default(linear_31, [1, -1, 16, 64]);  linear_31 = None\n",
      "    transpose_26 = torch.ops.aten.transpose.int(view_49, 1, 2);  view_49 = None\n",
      "    clone_23 = torch.ops.aten.clone.default(transpose_26, memory_format = torch.contiguous_format);  transpose_26 = None\n",
      "    linear_32 = torch.ops.aten.linear.default(layer_norm_11, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_bias);  layer_norm_11 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_v_proj_bias = None\n",
      "    view_50 = torch.ops.aten.view.default(linear_32, [1, -1, 16, 64]);  linear_32 = None\n",
      "    transpose_27 = torch.ops.aten.transpose.int(view_50, 1, 2);  view_50 = None\n",
      "    clone_24 = torch.ops.aten.clone.default(transpose_27, memory_format = torch.contiguous_format);  transpose_27 = None\n",
      "    view_51 = torch.ops.aten.view.default(mul_17, [1, sym_size_int_8, 16, 64]);  mul_17 = None\n",
      "    transpose_28 = torch.ops.aten.transpose.int(view_51, 1, 2);  view_51 = None\n",
      "    clone_25 = torch.ops.aten.clone.default(transpose_28, memory_format = torch.contiguous_format);  transpose_28 = None\n",
      "    view_52 = torch.ops.aten.view.default(clone_25, [16, -1, 64]);  clone_25 = None\n",
      "    view_53 = torch.ops.aten.view.default(clone_23, [16, -1, 64]);  clone_23 = None\n",
      "    view_54 = torch.ops.aten.view.default(clone_24, [16, -1, 64]);  clone_24 = None\n",
      "    transpose_29 = torch.ops.aten.transpose.int(view_53, 1, 2);  view_53 = None\n",
      "    bmm_10 = torch.ops.aten.bmm.default(view_52, transpose_29);  view_52 = transpose_29 = None\n",
      "    softmax_5 = torch.ops.aten.softmax.int(bmm_10, -1);  bmm_10 = None\n",
      "    dropout_5 = torch.ops.aten.dropout.default(softmax_5, 0.0, False);  softmax_5 = None\n",
      "    bmm_11 = torch.ops.aten.bmm.default(dropout_5, view_54);  dropout_5 = view_54 = None\n",
      "    view_55 = torch.ops.aten.view.default(bmm_11, [1, 16, sym_size_int_8, 64]);  bmm_11 = None\n",
      "    transpose_30 = torch.ops.aten.transpose.int(view_55, 1, 2);  view_55 = None\n",
      "    clone_26 = torch.ops.aten.clone.default(transpose_30, memory_format = torch.contiguous_format);  transpose_30 = None\n",
      "    _unsafe_view_5 = torch.ops.aten._unsafe_view.default(clone_26, [1, sym_size_int_8, 1024]);  clone_26 = None\n",
      "    linear_33 = torch.ops.aten.linear.default(_unsafe_view_5, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_bias);  _unsafe_view_5 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___self_attn_out_proj_bias = None\n",
      "    add_11 = torch.ops.aten.add.Tensor(add_10, linear_33);  add_10 = linear_33 = None\n",
      "    layer_norm_12 = torch.ops.aten.layer_norm.default(add_11, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___layer_norm2_bias = None\n",
      "    linear_34 = torch.ops.aten.linear.default(layer_norm_12, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_bias);  layer_norm_12 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc1_bias = None\n",
      "    mul_18 = torch.ops.aten.mul.Tensor(linear_34, b__tensor_constant_12);  b__tensor_constant_12 = None\n",
      "    sigmoid_5 = torch.ops.aten.sigmoid.default(mul_18);  mul_18 = None\n",
      "    mul_19 = torch.ops.aten.mul.Tensor(linear_34, sigmoid_5);  linear_34 = sigmoid_5 = None\n",
      "    linear_35 = torch.ops.aten.linear.default(mul_19, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_bias);  mul_19 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___5___mlp_fc2_bias = None\n",
      "    add_12 = torch.ops.aten.add.Tensor(add_11, linear_35);  add_11 = linear_35 = None\n",
      "    layer_norm_13 = torch.ops.aten.layer_norm.default(add_12, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm1_bias = None\n",
      "    linear_36 = torch.ops.aten.linear.default(layer_norm_13, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_q_proj_bias = None\n",
      "    mul_20 = torch.ops.aten.mul.Tensor(linear_36, b__tensor_constant_13);  linear_36 = b__tensor_constant_13 = None\n",
      "    linear_37 = torch.ops.aten.linear.default(layer_norm_13, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_k_proj_bias = None\n",
      "    view_56 = torch.ops.aten.view.default(linear_37, [1, -1, 16, 64]);  linear_37 = None\n",
      "    transpose_31 = torch.ops.aten.transpose.int(view_56, 1, 2);  view_56 = None\n",
      "    clone_27 = torch.ops.aten.clone.default(transpose_31, memory_format = torch.contiguous_format);  transpose_31 = None\n",
      "    linear_38 = torch.ops.aten.linear.default(layer_norm_13, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_bias);  layer_norm_13 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_v_proj_bias = None\n",
      "    view_57 = torch.ops.aten.view.default(linear_38, [1, -1, 16, 64]);  linear_38 = None\n",
      "    transpose_32 = torch.ops.aten.transpose.int(view_57, 1, 2);  view_57 = None\n",
      "    clone_28 = torch.ops.aten.clone.default(transpose_32, memory_format = torch.contiguous_format);  transpose_32 = None\n",
      "    view_58 = torch.ops.aten.view.default(mul_20, [1, sym_size_int_8, 16, 64]);  mul_20 = None\n",
      "    transpose_33 = torch.ops.aten.transpose.int(view_58, 1, 2);  view_58 = None\n",
      "    clone_29 = torch.ops.aten.clone.default(transpose_33, memory_format = torch.contiguous_format);  transpose_33 = None\n",
      "    view_59 = torch.ops.aten.view.default(clone_29, [16, -1, 64]);  clone_29 = None\n",
      "    view_60 = torch.ops.aten.view.default(clone_27, [16, -1, 64]);  clone_27 = None\n",
      "    view_61 = torch.ops.aten.view.default(clone_28, [16, -1, 64]);  clone_28 = None\n",
      "    transpose_34 = torch.ops.aten.transpose.int(view_60, 1, 2);  view_60 = None\n",
      "    bmm_12 = torch.ops.aten.bmm.default(view_59, transpose_34);  view_59 = transpose_34 = None\n",
      "    softmax_6 = torch.ops.aten.softmax.int(bmm_12, -1);  bmm_12 = None\n",
      "    dropout_6 = torch.ops.aten.dropout.default(softmax_6, 0.0, False);  softmax_6 = None\n",
      "    bmm_13 = torch.ops.aten.bmm.default(dropout_6, view_61);  dropout_6 = view_61 = None\n",
      "    view_62 = torch.ops.aten.view.default(bmm_13, [1, 16, sym_size_int_8, 64]);  bmm_13 = None\n",
      "    transpose_35 = torch.ops.aten.transpose.int(view_62, 1, 2);  view_62 = None\n",
      "    clone_30 = torch.ops.aten.clone.default(transpose_35, memory_format = torch.contiguous_format);  transpose_35 = None\n",
      "    _unsafe_view_6 = torch.ops.aten._unsafe_view.default(clone_30, [1, sym_size_int_8, 1024]);  clone_30 = None\n",
      "    linear_39 = torch.ops.aten.linear.default(_unsafe_view_6, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_bias);  _unsafe_view_6 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___self_attn_out_proj_bias = None\n",
      "    add_13 = torch.ops.aten.add.Tensor(add_12, linear_39);  add_12 = linear_39 = None\n",
      "    layer_norm_14 = torch.ops.aten.layer_norm.default(add_13, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___layer_norm2_bias = None\n",
      "    linear_40 = torch.ops.aten.linear.default(layer_norm_14, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_bias);  layer_norm_14 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc1_bias = None\n",
      "    mul_21 = torch.ops.aten.mul.Tensor(linear_40, b__tensor_constant_14);  b__tensor_constant_14 = None\n",
      "    sigmoid_6 = torch.ops.aten.sigmoid.default(mul_21);  mul_21 = None\n",
      "    mul_22 = torch.ops.aten.mul.Tensor(linear_40, sigmoid_6);  linear_40 = sigmoid_6 = None\n",
      "    linear_41 = torch.ops.aten.linear.default(mul_22, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_bias);  mul_22 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___6___mlp_fc2_bias = None\n",
      "    add_14 = torch.ops.aten.add.Tensor(add_13, linear_41);  add_13 = linear_41 = None\n",
      "    layer_norm_15 = torch.ops.aten.layer_norm.default(add_14, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm1_bias = None\n",
      "    linear_42 = torch.ops.aten.linear.default(layer_norm_15, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_q_proj_bias = None\n",
      "    mul_23 = torch.ops.aten.mul.Tensor(linear_42, b__tensor_constant_15);  linear_42 = b__tensor_constant_15 = None\n",
      "    linear_43 = torch.ops.aten.linear.default(layer_norm_15, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_k_proj_bias = None\n",
      "    view_63 = torch.ops.aten.view.default(linear_43, [1, -1, 16, 64]);  linear_43 = None\n",
      "    transpose_36 = torch.ops.aten.transpose.int(view_63, 1, 2);  view_63 = None\n",
      "    clone_31 = torch.ops.aten.clone.default(transpose_36, memory_format = torch.contiguous_format);  transpose_36 = None\n",
      "    linear_44 = torch.ops.aten.linear.default(layer_norm_15, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_bias);  layer_norm_15 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_v_proj_bias = None\n",
      "    view_64 = torch.ops.aten.view.default(linear_44, [1, -1, 16, 64]);  linear_44 = None\n",
      "    transpose_37 = torch.ops.aten.transpose.int(view_64, 1, 2);  view_64 = None\n",
      "    clone_32 = torch.ops.aten.clone.default(transpose_37, memory_format = torch.contiguous_format);  transpose_37 = None\n",
      "    view_65 = torch.ops.aten.view.default(mul_23, [1, sym_size_int_8, 16, 64]);  mul_23 = None\n",
      "    transpose_38 = torch.ops.aten.transpose.int(view_65, 1, 2);  view_65 = None\n",
      "    clone_33 = torch.ops.aten.clone.default(transpose_38, memory_format = torch.contiguous_format);  transpose_38 = None\n",
      "    view_66 = torch.ops.aten.view.default(clone_33, [16, -1, 64]);  clone_33 = None\n",
      "    view_67 = torch.ops.aten.view.default(clone_31, [16, -1, 64]);  clone_31 = None\n",
      "    view_68 = torch.ops.aten.view.default(clone_32, [16, -1, 64]);  clone_32 = None\n",
      "    transpose_39 = torch.ops.aten.transpose.int(view_67, 1, 2);  view_67 = None\n",
      "    bmm_14 = torch.ops.aten.bmm.default(view_66, transpose_39);  view_66 = transpose_39 = None\n",
      "    softmax_7 = torch.ops.aten.softmax.int(bmm_14, -1);  bmm_14 = None\n",
      "    dropout_7 = torch.ops.aten.dropout.default(softmax_7, 0.0, False);  softmax_7 = None\n",
      "    bmm_15 = torch.ops.aten.bmm.default(dropout_7, view_68);  dropout_7 = view_68 = None\n",
      "    view_69 = torch.ops.aten.view.default(bmm_15, [1, 16, sym_size_int_8, 64]);  bmm_15 = None\n",
      "    transpose_40 = torch.ops.aten.transpose.int(view_69, 1, 2);  view_69 = None\n",
      "    clone_34 = torch.ops.aten.clone.default(transpose_40, memory_format = torch.contiguous_format);  transpose_40 = None\n",
      "    _unsafe_view_7 = torch.ops.aten._unsafe_view.default(clone_34, [1, sym_size_int_8, 1024]);  clone_34 = None\n",
      "    linear_45 = torch.ops.aten.linear.default(_unsafe_view_7, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_bias);  _unsafe_view_7 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___self_attn_out_proj_bias = None\n",
      "    add_15 = torch.ops.aten.add.Tensor(add_14, linear_45);  add_14 = linear_45 = None\n",
      "    layer_norm_16 = torch.ops.aten.layer_norm.default(add_15, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___layer_norm2_bias = None\n",
      "    linear_46 = torch.ops.aten.linear.default(layer_norm_16, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_bias);  layer_norm_16 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc1_bias = None\n",
      "    mul_24 = torch.ops.aten.mul.Tensor(linear_46, b__tensor_constant_16);  b__tensor_constant_16 = None\n",
      "    sigmoid_7 = torch.ops.aten.sigmoid.default(mul_24);  mul_24 = None\n",
      "    mul_25 = torch.ops.aten.mul.Tensor(linear_46, sigmoid_7);  linear_46 = sigmoid_7 = None\n",
      "    linear_47 = torch.ops.aten.linear.default(mul_25, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_bias);  mul_25 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___7___mlp_fc2_bias = None\n",
      "    add_16 = torch.ops.aten.add.Tensor(add_15, linear_47);  add_15 = linear_47 = None\n",
      "    layer_norm_17 = torch.ops.aten.layer_norm.default(add_16, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm1_bias = None\n",
      "    linear_48 = torch.ops.aten.linear.default(layer_norm_17, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_q_proj_bias = None\n",
      "    mul_26 = torch.ops.aten.mul.Tensor(linear_48, b__tensor_constant_17);  linear_48 = b__tensor_constant_17 = None\n",
      "    linear_49 = torch.ops.aten.linear.default(layer_norm_17, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_k_proj_bias = None\n",
      "    view_70 = torch.ops.aten.view.default(linear_49, [1, -1, 16, 64]);  linear_49 = None\n",
      "    transpose_41 = torch.ops.aten.transpose.int(view_70, 1, 2);  view_70 = None\n",
      "    clone_35 = torch.ops.aten.clone.default(transpose_41, memory_format = torch.contiguous_format);  transpose_41 = None\n",
      "    linear_50 = torch.ops.aten.linear.default(layer_norm_17, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_bias);  layer_norm_17 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_v_proj_bias = None\n",
      "    view_71 = torch.ops.aten.view.default(linear_50, [1, -1, 16, 64]);  linear_50 = None\n",
      "    transpose_42 = torch.ops.aten.transpose.int(view_71, 1, 2);  view_71 = None\n",
      "    clone_36 = torch.ops.aten.clone.default(transpose_42, memory_format = torch.contiguous_format);  transpose_42 = None\n",
      "    view_72 = torch.ops.aten.view.default(mul_26, [1, sym_size_int_8, 16, 64]);  mul_26 = None\n",
      "    transpose_43 = torch.ops.aten.transpose.int(view_72, 1, 2);  view_72 = None\n",
      "    clone_37 = torch.ops.aten.clone.default(transpose_43, memory_format = torch.contiguous_format);  transpose_43 = None\n",
      "    view_73 = torch.ops.aten.view.default(clone_37, [16, -1, 64]);  clone_37 = None\n",
      "    view_74 = torch.ops.aten.view.default(clone_35, [16, -1, 64]);  clone_35 = None\n",
      "    view_75 = torch.ops.aten.view.default(clone_36, [16, -1, 64]);  clone_36 = None\n",
      "    transpose_44 = torch.ops.aten.transpose.int(view_74, 1, 2);  view_74 = None\n",
      "    bmm_16 = torch.ops.aten.bmm.default(view_73, transpose_44);  view_73 = transpose_44 = None\n",
      "    softmax_8 = torch.ops.aten.softmax.int(bmm_16, -1);  bmm_16 = None\n",
      "    dropout_8 = torch.ops.aten.dropout.default(softmax_8, 0.0, False);  softmax_8 = None\n",
      "    bmm_17 = torch.ops.aten.bmm.default(dropout_8, view_75);  dropout_8 = view_75 = None\n",
      "    view_76 = torch.ops.aten.view.default(bmm_17, [1, 16, sym_size_int_8, 64]);  bmm_17 = None\n",
      "    transpose_45 = torch.ops.aten.transpose.int(view_76, 1, 2);  view_76 = None\n",
      "    clone_38 = torch.ops.aten.clone.default(transpose_45, memory_format = torch.contiguous_format);  transpose_45 = None\n",
      "    _unsafe_view_8 = torch.ops.aten._unsafe_view.default(clone_38, [1, sym_size_int_8, 1024]);  clone_38 = None\n",
      "    linear_51 = torch.ops.aten.linear.default(_unsafe_view_8, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_bias);  _unsafe_view_8 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___self_attn_out_proj_bias = None\n",
      "    add_17 = torch.ops.aten.add.Tensor(add_16, linear_51);  add_16 = linear_51 = None\n",
      "    layer_norm_18 = torch.ops.aten.layer_norm.default(add_17, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___layer_norm2_bias = None\n",
      "    linear_52 = torch.ops.aten.linear.default(layer_norm_18, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_bias);  layer_norm_18 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc1_bias = None\n",
      "    mul_27 = torch.ops.aten.mul.Tensor(linear_52, b__tensor_constant_18);  b__tensor_constant_18 = None\n",
      "    sigmoid_8 = torch.ops.aten.sigmoid.default(mul_27);  mul_27 = None\n",
      "    mul_28 = torch.ops.aten.mul.Tensor(linear_52, sigmoid_8);  linear_52 = sigmoid_8 = None\n",
      "    linear_53 = torch.ops.aten.linear.default(mul_28, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_bias);  mul_28 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___8___mlp_fc2_bias = None\n",
      "    add_18 = torch.ops.aten.add.Tensor(add_17, linear_53);  add_17 = linear_53 = None\n",
      "    layer_norm_19 = torch.ops.aten.layer_norm.default(add_18, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm1_bias = None\n",
      "    linear_54 = torch.ops.aten.linear.default(layer_norm_19, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_q_proj_bias = None\n",
      "    mul_29 = torch.ops.aten.mul.Tensor(linear_54, b__tensor_constant_19);  linear_54 = b__tensor_constant_19 = None\n",
      "    linear_55 = torch.ops.aten.linear.default(layer_norm_19, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_k_proj_bias = None\n",
      "    view_77 = torch.ops.aten.view.default(linear_55, [1, -1, 16, 64]);  linear_55 = None\n",
      "    transpose_46 = torch.ops.aten.transpose.int(view_77, 1, 2);  view_77 = None\n",
      "    clone_39 = torch.ops.aten.clone.default(transpose_46, memory_format = torch.contiguous_format);  transpose_46 = None\n",
      "    linear_56 = torch.ops.aten.linear.default(layer_norm_19, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_bias);  layer_norm_19 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_v_proj_bias = None\n",
      "    view_78 = torch.ops.aten.view.default(linear_56, [1, -1, 16, 64]);  linear_56 = None\n",
      "    transpose_47 = torch.ops.aten.transpose.int(view_78, 1, 2);  view_78 = None\n",
      "    clone_40 = torch.ops.aten.clone.default(transpose_47, memory_format = torch.contiguous_format);  transpose_47 = None\n",
      "    view_79 = torch.ops.aten.view.default(mul_29, [1, sym_size_int_8, 16, 64]);  mul_29 = None\n",
      "    transpose_48 = torch.ops.aten.transpose.int(view_79, 1, 2);  view_79 = None\n",
      "    clone_41 = torch.ops.aten.clone.default(transpose_48, memory_format = torch.contiguous_format);  transpose_48 = None\n",
      "    view_80 = torch.ops.aten.view.default(clone_41, [16, -1, 64]);  clone_41 = None\n",
      "    view_81 = torch.ops.aten.view.default(clone_39, [16, -1, 64]);  clone_39 = None\n",
      "    view_82 = torch.ops.aten.view.default(clone_40, [16, -1, 64]);  clone_40 = None\n",
      "    transpose_49 = torch.ops.aten.transpose.int(view_81, 1, 2);  view_81 = None\n",
      "    bmm_18 = torch.ops.aten.bmm.default(view_80, transpose_49);  view_80 = transpose_49 = None\n",
      "    softmax_9 = torch.ops.aten.softmax.int(bmm_18, -1);  bmm_18 = None\n",
      "    dropout_9 = torch.ops.aten.dropout.default(softmax_9, 0.0, False);  softmax_9 = None\n",
      "    bmm_19 = torch.ops.aten.bmm.default(dropout_9, view_82);  dropout_9 = view_82 = None\n",
      "    view_83 = torch.ops.aten.view.default(bmm_19, [1, 16, sym_size_int_8, 64]);  bmm_19 = None\n",
      "    transpose_50 = torch.ops.aten.transpose.int(view_83, 1, 2);  view_83 = None\n",
      "    clone_42 = torch.ops.aten.clone.default(transpose_50, memory_format = torch.contiguous_format);  transpose_50 = None\n",
      "    _unsafe_view_9 = torch.ops.aten._unsafe_view.default(clone_42, [1, sym_size_int_8, 1024]);  clone_42 = None\n",
      "    linear_57 = torch.ops.aten.linear.default(_unsafe_view_9, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_bias);  _unsafe_view_9 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___self_attn_out_proj_bias = None\n",
      "    add_19 = torch.ops.aten.add.Tensor(add_18, linear_57);  add_18 = linear_57 = None\n",
      "    layer_norm_20 = torch.ops.aten.layer_norm.default(add_19, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___layer_norm2_bias = None\n",
      "    linear_58 = torch.ops.aten.linear.default(layer_norm_20, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_bias);  layer_norm_20 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc1_bias = None\n",
      "    mul_30 = torch.ops.aten.mul.Tensor(linear_58, b__tensor_constant_20);  b__tensor_constant_20 = None\n",
      "    sigmoid_9 = torch.ops.aten.sigmoid.default(mul_30);  mul_30 = None\n",
      "    mul_31 = torch.ops.aten.mul.Tensor(linear_58, sigmoid_9);  linear_58 = sigmoid_9 = None\n",
      "    linear_59 = torch.ops.aten.linear.default(mul_31, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_bias);  mul_31 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___9___mlp_fc2_bias = None\n",
      "    add_20 = torch.ops.aten.add.Tensor(add_19, linear_59);  add_19 = linear_59 = None\n",
      "    layer_norm_21 = torch.ops.aten.layer_norm.default(add_20, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm1_bias = None\n",
      "    linear_60 = torch.ops.aten.linear.default(layer_norm_21, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_q_proj_bias = None\n",
      "    mul_32 = torch.ops.aten.mul.Tensor(linear_60, b__tensor_constant_21);  linear_60 = b__tensor_constant_21 = None\n",
      "    linear_61 = torch.ops.aten.linear.default(layer_norm_21, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_k_proj_bias = None\n",
      "    view_84 = torch.ops.aten.view.default(linear_61, [1, -1, 16, 64]);  linear_61 = None\n",
      "    transpose_51 = torch.ops.aten.transpose.int(view_84, 1, 2);  view_84 = None\n",
      "    clone_43 = torch.ops.aten.clone.default(transpose_51, memory_format = torch.contiguous_format);  transpose_51 = None\n",
      "    linear_62 = torch.ops.aten.linear.default(layer_norm_21, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_bias);  layer_norm_21 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_v_proj_bias = None\n",
      "    view_85 = torch.ops.aten.view.default(linear_62, [1, -1, 16, 64]);  linear_62 = None\n",
      "    transpose_52 = torch.ops.aten.transpose.int(view_85, 1, 2);  view_85 = None\n",
      "    clone_44 = torch.ops.aten.clone.default(transpose_52, memory_format = torch.contiguous_format);  transpose_52 = None\n",
      "    view_86 = torch.ops.aten.view.default(mul_32, [1, sym_size_int_8, 16, 64]);  mul_32 = None\n",
      "    transpose_53 = torch.ops.aten.transpose.int(view_86, 1, 2);  view_86 = None\n",
      "    clone_45 = torch.ops.aten.clone.default(transpose_53, memory_format = torch.contiguous_format);  transpose_53 = None\n",
      "    view_87 = torch.ops.aten.view.default(clone_45, [16, -1, 64]);  clone_45 = None\n",
      "    view_88 = torch.ops.aten.view.default(clone_43, [16, -1, 64]);  clone_43 = None\n",
      "    view_89 = torch.ops.aten.view.default(clone_44, [16, -1, 64]);  clone_44 = None\n",
      "    transpose_54 = torch.ops.aten.transpose.int(view_88, 1, 2);  view_88 = None\n",
      "    bmm_20 = torch.ops.aten.bmm.default(view_87, transpose_54);  view_87 = transpose_54 = None\n",
      "    softmax_10 = torch.ops.aten.softmax.int(bmm_20, -1);  bmm_20 = None\n",
      "    dropout_10 = torch.ops.aten.dropout.default(softmax_10, 0.0, False);  softmax_10 = None\n",
      "    bmm_21 = torch.ops.aten.bmm.default(dropout_10, view_89);  dropout_10 = view_89 = None\n",
      "    view_90 = torch.ops.aten.view.default(bmm_21, [1, 16, sym_size_int_8, 64]);  bmm_21 = None\n",
      "    transpose_55 = torch.ops.aten.transpose.int(view_90, 1, 2);  view_90 = None\n",
      "    clone_46 = torch.ops.aten.clone.default(transpose_55, memory_format = torch.contiguous_format);  transpose_55 = None\n",
      "    _unsafe_view_10 = torch.ops.aten._unsafe_view.default(clone_46, [1, sym_size_int_8, 1024]);  clone_46 = None\n",
      "    linear_63 = torch.ops.aten.linear.default(_unsafe_view_10, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_bias);  _unsafe_view_10 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___self_attn_out_proj_bias = None\n",
      "    add_21 = torch.ops.aten.add.Tensor(add_20, linear_63);  add_20 = linear_63 = None\n",
      "    layer_norm_22 = torch.ops.aten.layer_norm.default(add_21, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___layer_norm2_bias = None\n",
      "    linear_64 = torch.ops.aten.linear.default(layer_norm_22, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_bias);  layer_norm_22 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc1_bias = None\n",
      "    mul_33 = torch.ops.aten.mul.Tensor(linear_64, b__tensor_constant_22);  b__tensor_constant_22 = None\n",
      "    sigmoid_10 = torch.ops.aten.sigmoid.default(mul_33);  mul_33 = None\n",
      "    mul_34 = torch.ops.aten.mul.Tensor(linear_64, sigmoid_10);  linear_64 = sigmoid_10 = None\n",
      "    linear_65 = torch.ops.aten.linear.default(mul_34, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_bias);  mul_34 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___10___mlp_fc2_bias = None\n",
      "    add_22 = torch.ops.aten.add.Tensor(add_21, linear_65);  add_21 = linear_65 = None\n",
      "    layer_norm_23 = torch.ops.aten.layer_norm.default(add_22, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm1_bias = None\n",
      "    linear_66 = torch.ops.aten.linear.default(layer_norm_23, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_q_proj_bias = None\n",
      "    mul_35 = torch.ops.aten.mul.Tensor(linear_66, b__tensor_constant_23);  linear_66 = b__tensor_constant_23 = None\n",
      "    linear_67 = torch.ops.aten.linear.default(layer_norm_23, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_k_proj_bias = None\n",
      "    view_91 = torch.ops.aten.view.default(linear_67, [1, -1, 16, 64]);  linear_67 = None\n",
      "    transpose_56 = torch.ops.aten.transpose.int(view_91, 1, 2);  view_91 = None\n",
      "    clone_47 = torch.ops.aten.clone.default(transpose_56, memory_format = torch.contiguous_format);  transpose_56 = None\n",
      "    linear_68 = torch.ops.aten.linear.default(layer_norm_23, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_bias);  layer_norm_23 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_v_proj_bias = None\n",
      "    view_92 = torch.ops.aten.view.default(linear_68, [1, -1, 16, 64]);  linear_68 = None\n",
      "    transpose_57 = torch.ops.aten.transpose.int(view_92, 1, 2);  view_92 = None\n",
      "    clone_48 = torch.ops.aten.clone.default(transpose_57, memory_format = torch.contiguous_format);  transpose_57 = None\n",
      "    view_93 = torch.ops.aten.view.default(mul_35, [1, sym_size_int_8, 16, 64]);  mul_35 = None\n",
      "    transpose_58 = torch.ops.aten.transpose.int(view_93, 1, 2);  view_93 = None\n",
      "    clone_49 = torch.ops.aten.clone.default(transpose_58, memory_format = torch.contiguous_format);  transpose_58 = None\n",
      "    view_94 = torch.ops.aten.view.default(clone_49, [16, -1, 64]);  clone_49 = None\n",
      "    view_95 = torch.ops.aten.view.default(clone_47, [16, -1, 64]);  clone_47 = None\n",
      "    view_96 = torch.ops.aten.view.default(clone_48, [16, -1, 64]);  clone_48 = None\n",
      "    transpose_59 = torch.ops.aten.transpose.int(view_95, 1, 2);  view_95 = None\n",
      "    bmm_22 = torch.ops.aten.bmm.default(view_94, transpose_59);  view_94 = transpose_59 = None\n",
      "    softmax_11 = torch.ops.aten.softmax.int(bmm_22, -1);  bmm_22 = None\n",
      "    dropout_11 = torch.ops.aten.dropout.default(softmax_11, 0.0, False);  softmax_11 = None\n",
      "    bmm_23 = torch.ops.aten.bmm.default(dropout_11, view_96);  dropout_11 = view_96 = None\n",
      "    view_97 = torch.ops.aten.view.default(bmm_23, [1, 16, sym_size_int_8, 64]);  bmm_23 = None\n",
      "    transpose_60 = torch.ops.aten.transpose.int(view_97, 1, 2);  view_97 = None\n",
      "    clone_50 = torch.ops.aten.clone.default(transpose_60, memory_format = torch.contiguous_format);  transpose_60 = None\n",
      "    _unsafe_view_11 = torch.ops.aten._unsafe_view.default(clone_50, [1, sym_size_int_8, 1024]);  clone_50 = None\n",
      "    linear_69 = torch.ops.aten.linear.default(_unsafe_view_11, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_bias);  _unsafe_view_11 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___self_attn_out_proj_bias = None\n",
      "    add_23 = torch.ops.aten.add.Tensor(add_22, linear_69);  add_22 = linear_69 = None\n",
      "    layer_norm_24 = torch.ops.aten.layer_norm.default(add_23, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___layer_norm2_bias = None\n",
      "    linear_70 = torch.ops.aten.linear.default(layer_norm_24, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_bias);  layer_norm_24 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc1_bias = None\n",
      "    mul_36 = torch.ops.aten.mul.Tensor(linear_70, b__tensor_constant_24);  b__tensor_constant_24 = None\n",
      "    sigmoid_11 = torch.ops.aten.sigmoid.default(mul_36);  mul_36 = None\n",
      "    mul_37 = torch.ops.aten.mul.Tensor(linear_70, sigmoid_11);  linear_70 = sigmoid_11 = None\n",
      "    linear_71 = torch.ops.aten.linear.default(mul_37, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_bias);  mul_37 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___11___mlp_fc2_bias = None\n",
      "    add_24 = torch.ops.aten.add.Tensor(add_23, linear_71);  add_23 = linear_71 = None\n",
      "    layer_norm_25 = torch.ops.aten.layer_norm.default(add_24, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm1_bias = None\n",
      "    linear_72 = torch.ops.aten.linear.default(layer_norm_25, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_q_proj_bias = None\n",
      "    mul_38 = torch.ops.aten.mul.Tensor(linear_72, b__tensor_constant_25);  linear_72 = b__tensor_constant_25 = None\n",
      "    linear_73 = torch.ops.aten.linear.default(layer_norm_25, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_k_proj_bias = None\n",
      "    view_98 = torch.ops.aten.view.default(linear_73, [1, -1, 16, 64]);  linear_73 = None\n",
      "    transpose_61 = torch.ops.aten.transpose.int(view_98, 1, 2);  view_98 = None\n",
      "    clone_51 = torch.ops.aten.clone.default(transpose_61, memory_format = torch.contiguous_format);  transpose_61 = None\n",
      "    linear_74 = torch.ops.aten.linear.default(layer_norm_25, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_bias);  layer_norm_25 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_v_proj_bias = None\n",
      "    view_99 = torch.ops.aten.view.default(linear_74, [1, -1, 16, 64]);  linear_74 = None\n",
      "    transpose_62 = torch.ops.aten.transpose.int(view_99, 1, 2);  view_99 = None\n",
      "    clone_52 = torch.ops.aten.clone.default(transpose_62, memory_format = torch.contiguous_format);  transpose_62 = None\n",
      "    view_100 = torch.ops.aten.view.default(mul_38, [1, sym_size_int_8, 16, 64]);  mul_38 = None\n",
      "    transpose_63 = torch.ops.aten.transpose.int(view_100, 1, 2);  view_100 = None\n",
      "    clone_53 = torch.ops.aten.clone.default(transpose_63, memory_format = torch.contiguous_format);  transpose_63 = None\n",
      "    view_101 = torch.ops.aten.view.default(clone_53, [16, -1, 64]);  clone_53 = None\n",
      "    view_102 = torch.ops.aten.view.default(clone_51, [16, -1, 64]);  clone_51 = None\n",
      "    view_103 = torch.ops.aten.view.default(clone_52, [16, -1, 64]);  clone_52 = None\n",
      "    transpose_64 = torch.ops.aten.transpose.int(view_102, 1, 2);  view_102 = None\n",
      "    bmm_24 = torch.ops.aten.bmm.default(view_101, transpose_64);  view_101 = transpose_64 = None\n",
      "    softmax_12 = torch.ops.aten.softmax.int(bmm_24, -1);  bmm_24 = None\n",
      "    dropout_12 = torch.ops.aten.dropout.default(softmax_12, 0.0, False);  softmax_12 = None\n",
      "    bmm_25 = torch.ops.aten.bmm.default(dropout_12, view_103);  dropout_12 = view_103 = None\n",
      "    view_104 = torch.ops.aten.view.default(bmm_25, [1, 16, sym_size_int_8, 64]);  bmm_25 = None\n",
      "    transpose_65 = torch.ops.aten.transpose.int(view_104, 1, 2);  view_104 = None\n",
      "    clone_54 = torch.ops.aten.clone.default(transpose_65, memory_format = torch.contiguous_format);  transpose_65 = None\n",
      "    _unsafe_view_12 = torch.ops.aten._unsafe_view.default(clone_54, [1, sym_size_int_8, 1024]);  clone_54 = None\n",
      "    linear_75 = torch.ops.aten.linear.default(_unsafe_view_12, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_bias);  _unsafe_view_12 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___self_attn_out_proj_bias = None\n",
      "    add_25 = torch.ops.aten.add.Tensor(add_24, linear_75);  add_24 = linear_75 = None\n",
      "    layer_norm_26 = torch.ops.aten.layer_norm.default(add_25, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___layer_norm2_bias = None\n",
      "    linear_76 = torch.ops.aten.linear.default(layer_norm_26, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_bias);  layer_norm_26 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc1_bias = None\n",
      "    mul_39 = torch.ops.aten.mul.Tensor(linear_76, b__tensor_constant_26);  b__tensor_constant_26 = None\n",
      "    sigmoid_12 = torch.ops.aten.sigmoid.default(mul_39);  mul_39 = None\n",
      "    mul_40 = torch.ops.aten.mul.Tensor(linear_76, sigmoid_12);  linear_76 = sigmoid_12 = None\n",
      "    linear_77 = torch.ops.aten.linear.default(mul_40, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_bias);  mul_40 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___12___mlp_fc2_bias = None\n",
      "    add_26 = torch.ops.aten.add.Tensor(add_25, linear_77);  add_25 = linear_77 = None\n",
      "    layer_norm_27 = torch.ops.aten.layer_norm.default(add_26, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm1_bias = None\n",
      "    linear_78 = torch.ops.aten.linear.default(layer_norm_27, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_q_proj_bias = None\n",
      "    mul_41 = torch.ops.aten.mul.Tensor(linear_78, b__tensor_constant_27);  linear_78 = b__tensor_constant_27 = None\n",
      "    linear_79 = torch.ops.aten.linear.default(layer_norm_27, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_k_proj_bias = None\n",
      "    view_105 = torch.ops.aten.view.default(linear_79, [1, -1, 16, 64]);  linear_79 = None\n",
      "    transpose_66 = torch.ops.aten.transpose.int(view_105, 1, 2);  view_105 = None\n",
      "    clone_55 = torch.ops.aten.clone.default(transpose_66, memory_format = torch.contiguous_format);  transpose_66 = None\n",
      "    linear_80 = torch.ops.aten.linear.default(layer_norm_27, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_bias);  layer_norm_27 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_v_proj_bias = None\n",
      "    view_106 = torch.ops.aten.view.default(linear_80, [1, -1, 16, 64]);  linear_80 = None\n",
      "    transpose_67 = torch.ops.aten.transpose.int(view_106, 1, 2);  view_106 = None\n",
      "    clone_56 = torch.ops.aten.clone.default(transpose_67, memory_format = torch.contiguous_format);  transpose_67 = None\n",
      "    view_107 = torch.ops.aten.view.default(mul_41, [1, sym_size_int_8, 16, 64]);  mul_41 = None\n",
      "    transpose_68 = torch.ops.aten.transpose.int(view_107, 1, 2);  view_107 = None\n",
      "    clone_57 = torch.ops.aten.clone.default(transpose_68, memory_format = torch.contiguous_format);  transpose_68 = None\n",
      "    view_108 = torch.ops.aten.view.default(clone_57, [16, -1, 64]);  clone_57 = None\n",
      "    view_109 = torch.ops.aten.view.default(clone_55, [16, -1, 64]);  clone_55 = None\n",
      "    view_110 = torch.ops.aten.view.default(clone_56, [16, -1, 64]);  clone_56 = None\n",
      "    transpose_69 = torch.ops.aten.transpose.int(view_109, 1, 2);  view_109 = None\n",
      "    bmm_26 = torch.ops.aten.bmm.default(view_108, transpose_69);  view_108 = transpose_69 = None\n",
      "    softmax_13 = torch.ops.aten.softmax.int(bmm_26, -1);  bmm_26 = None\n",
      "    dropout_13 = torch.ops.aten.dropout.default(softmax_13, 0.0, False);  softmax_13 = None\n",
      "    bmm_27 = torch.ops.aten.bmm.default(dropout_13, view_110);  dropout_13 = view_110 = None\n",
      "    view_111 = torch.ops.aten.view.default(bmm_27, [1, 16, sym_size_int_8, 64]);  bmm_27 = None\n",
      "    transpose_70 = torch.ops.aten.transpose.int(view_111, 1, 2);  view_111 = None\n",
      "    clone_58 = torch.ops.aten.clone.default(transpose_70, memory_format = torch.contiguous_format);  transpose_70 = None\n",
      "    _unsafe_view_13 = torch.ops.aten._unsafe_view.default(clone_58, [1, sym_size_int_8, 1024]);  clone_58 = None\n",
      "    linear_81 = torch.ops.aten.linear.default(_unsafe_view_13, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_bias);  _unsafe_view_13 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___self_attn_out_proj_bias = None\n",
      "    add_27 = torch.ops.aten.add.Tensor(add_26, linear_81);  add_26 = linear_81 = None\n",
      "    layer_norm_28 = torch.ops.aten.layer_norm.default(add_27, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___layer_norm2_bias = None\n",
      "    linear_82 = torch.ops.aten.linear.default(layer_norm_28, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_bias);  layer_norm_28 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc1_bias = None\n",
      "    mul_42 = torch.ops.aten.mul.Tensor(linear_82, b__tensor_constant_28);  b__tensor_constant_28 = None\n",
      "    sigmoid_13 = torch.ops.aten.sigmoid.default(mul_42);  mul_42 = None\n",
      "    mul_43 = torch.ops.aten.mul.Tensor(linear_82, sigmoid_13);  linear_82 = sigmoid_13 = None\n",
      "    linear_83 = torch.ops.aten.linear.default(mul_43, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_bias);  mul_43 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___13___mlp_fc2_bias = None\n",
      "    add_28 = torch.ops.aten.add.Tensor(add_27, linear_83);  add_27 = linear_83 = None\n",
      "    layer_norm_29 = torch.ops.aten.layer_norm.default(add_28, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm1_bias = None\n",
      "    linear_84 = torch.ops.aten.linear.default(layer_norm_29, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_q_proj_bias = None\n",
      "    mul_44 = torch.ops.aten.mul.Tensor(linear_84, b__tensor_constant_29);  linear_84 = b__tensor_constant_29 = None\n",
      "    linear_85 = torch.ops.aten.linear.default(layer_norm_29, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_k_proj_bias = None\n",
      "    view_112 = torch.ops.aten.view.default(linear_85, [1, -1, 16, 64]);  linear_85 = None\n",
      "    transpose_71 = torch.ops.aten.transpose.int(view_112, 1, 2);  view_112 = None\n",
      "    clone_59 = torch.ops.aten.clone.default(transpose_71, memory_format = torch.contiguous_format);  transpose_71 = None\n",
      "    linear_86 = torch.ops.aten.linear.default(layer_norm_29, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_bias);  layer_norm_29 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_v_proj_bias = None\n",
      "    view_113 = torch.ops.aten.view.default(linear_86, [1, -1, 16, 64]);  linear_86 = None\n",
      "    transpose_72 = torch.ops.aten.transpose.int(view_113, 1, 2);  view_113 = None\n",
      "    clone_60 = torch.ops.aten.clone.default(transpose_72, memory_format = torch.contiguous_format);  transpose_72 = None\n",
      "    view_114 = torch.ops.aten.view.default(mul_44, [1, sym_size_int_8, 16, 64]);  mul_44 = None\n",
      "    transpose_73 = torch.ops.aten.transpose.int(view_114, 1, 2);  view_114 = None\n",
      "    clone_61 = torch.ops.aten.clone.default(transpose_73, memory_format = torch.contiguous_format);  transpose_73 = None\n",
      "    view_115 = torch.ops.aten.view.default(clone_61, [16, -1, 64]);  clone_61 = None\n",
      "    view_116 = torch.ops.aten.view.default(clone_59, [16, -1, 64]);  clone_59 = None\n",
      "    view_117 = torch.ops.aten.view.default(clone_60, [16, -1, 64]);  clone_60 = None\n",
      "    transpose_74 = torch.ops.aten.transpose.int(view_116, 1, 2);  view_116 = None\n",
      "    bmm_28 = torch.ops.aten.bmm.default(view_115, transpose_74);  view_115 = transpose_74 = None\n",
      "    softmax_14 = torch.ops.aten.softmax.int(bmm_28, -1);  bmm_28 = None\n",
      "    dropout_14 = torch.ops.aten.dropout.default(softmax_14, 0.0, False);  softmax_14 = None\n",
      "    bmm_29 = torch.ops.aten.bmm.default(dropout_14, view_117);  dropout_14 = view_117 = None\n",
      "    view_118 = torch.ops.aten.view.default(bmm_29, [1, 16, sym_size_int_8, 64]);  bmm_29 = None\n",
      "    transpose_75 = torch.ops.aten.transpose.int(view_118, 1, 2);  view_118 = None\n",
      "    clone_62 = torch.ops.aten.clone.default(transpose_75, memory_format = torch.contiguous_format);  transpose_75 = None\n",
      "    _unsafe_view_14 = torch.ops.aten._unsafe_view.default(clone_62, [1, sym_size_int_8, 1024]);  clone_62 = None\n",
      "    linear_87 = torch.ops.aten.linear.default(_unsafe_view_14, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_bias);  _unsafe_view_14 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___self_attn_out_proj_bias = None\n",
      "    add_29 = torch.ops.aten.add.Tensor(add_28, linear_87);  add_28 = linear_87 = None\n",
      "    layer_norm_30 = torch.ops.aten.layer_norm.default(add_29, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___layer_norm2_bias = None\n",
      "    linear_88 = torch.ops.aten.linear.default(layer_norm_30, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_bias);  layer_norm_30 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc1_bias = None\n",
      "    mul_45 = torch.ops.aten.mul.Tensor(linear_88, b__tensor_constant_30);  b__tensor_constant_30 = None\n",
      "    sigmoid_14 = torch.ops.aten.sigmoid.default(mul_45);  mul_45 = None\n",
      "    mul_46 = torch.ops.aten.mul.Tensor(linear_88, sigmoid_14);  linear_88 = sigmoid_14 = None\n",
      "    linear_89 = torch.ops.aten.linear.default(mul_46, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_bias);  mul_46 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___14___mlp_fc2_bias = None\n",
      "    add_30 = torch.ops.aten.add.Tensor(add_29, linear_89);  add_29 = linear_89 = None\n",
      "    layer_norm_31 = torch.ops.aten.layer_norm.default(add_30, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm1_bias = None\n",
      "    linear_90 = torch.ops.aten.linear.default(layer_norm_31, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_q_proj_bias = None\n",
      "    mul_47 = torch.ops.aten.mul.Tensor(linear_90, b__tensor_constant_31);  linear_90 = b__tensor_constant_31 = None\n",
      "    linear_91 = torch.ops.aten.linear.default(layer_norm_31, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_k_proj_bias = None\n",
      "    view_119 = torch.ops.aten.view.default(linear_91, [1, -1, 16, 64]);  linear_91 = None\n",
      "    transpose_76 = torch.ops.aten.transpose.int(view_119, 1, 2);  view_119 = None\n",
      "    clone_63 = torch.ops.aten.clone.default(transpose_76, memory_format = torch.contiguous_format);  transpose_76 = None\n",
      "    linear_92 = torch.ops.aten.linear.default(layer_norm_31, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_bias);  layer_norm_31 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_v_proj_bias = None\n",
      "    view_120 = torch.ops.aten.view.default(linear_92, [1, -1, 16, 64]);  linear_92 = None\n",
      "    transpose_77 = torch.ops.aten.transpose.int(view_120, 1, 2);  view_120 = None\n",
      "    clone_64 = torch.ops.aten.clone.default(transpose_77, memory_format = torch.contiguous_format);  transpose_77 = None\n",
      "    view_121 = torch.ops.aten.view.default(mul_47, [1, sym_size_int_8, 16, 64]);  mul_47 = None\n",
      "    transpose_78 = torch.ops.aten.transpose.int(view_121, 1, 2);  view_121 = None\n",
      "    clone_65 = torch.ops.aten.clone.default(transpose_78, memory_format = torch.contiguous_format);  transpose_78 = None\n",
      "    view_122 = torch.ops.aten.view.default(clone_65, [16, -1, 64]);  clone_65 = None\n",
      "    view_123 = torch.ops.aten.view.default(clone_63, [16, -1, 64]);  clone_63 = None\n",
      "    view_124 = torch.ops.aten.view.default(clone_64, [16, -1, 64]);  clone_64 = None\n",
      "    transpose_79 = torch.ops.aten.transpose.int(view_123, 1, 2);  view_123 = None\n",
      "    bmm_30 = torch.ops.aten.bmm.default(view_122, transpose_79);  view_122 = transpose_79 = None\n",
      "    softmax_15 = torch.ops.aten.softmax.int(bmm_30, -1);  bmm_30 = None\n",
      "    dropout_15 = torch.ops.aten.dropout.default(softmax_15, 0.0, False);  softmax_15 = None\n",
      "    bmm_31 = torch.ops.aten.bmm.default(dropout_15, view_124);  dropout_15 = view_124 = None\n",
      "    view_125 = torch.ops.aten.view.default(bmm_31, [1, 16, sym_size_int_8, 64]);  bmm_31 = None\n",
      "    transpose_80 = torch.ops.aten.transpose.int(view_125, 1, 2);  view_125 = None\n",
      "    clone_66 = torch.ops.aten.clone.default(transpose_80, memory_format = torch.contiguous_format);  transpose_80 = None\n",
      "    _unsafe_view_15 = torch.ops.aten._unsafe_view.default(clone_66, [1, sym_size_int_8, 1024]);  clone_66 = None\n",
      "    linear_93 = torch.ops.aten.linear.default(_unsafe_view_15, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_bias);  _unsafe_view_15 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___self_attn_out_proj_bias = None\n",
      "    add_31 = torch.ops.aten.add.Tensor(add_30, linear_93);  add_30 = linear_93 = None\n",
      "    layer_norm_32 = torch.ops.aten.layer_norm.default(add_31, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___layer_norm2_bias = None\n",
      "    linear_94 = torch.ops.aten.linear.default(layer_norm_32, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_bias);  layer_norm_32 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc1_bias = None\n",
      "    mul_48 = torch.ops.aten.mul.Tensor(linear_94, b__tensor_constant_32);  b__tensor_constant_32 = None\n",
      "    sigmoid_15 = torch.ops.aten.sigmoid.default(mul_48);  mul_48 = None\n",
      "    mul_49 = torch.ops.aten.mul.Tensor(linear_94, sigmoid_15);  linear_94 = sigmoid_15 = None\n",
      "    linear_95 = torch.ops.aten.linear.default(mul_49, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_bias);  mul_49 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___15___mlp_fc2_bias = None\n",
      "    add_32 = torch.ops.aten.add.Tensor(add_31, linear_95);  add_31 = linear_95 = None\n",
      "    layer_norm_33 = torch.ops.aten.layer_norm.default(add_32, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm1_bias = None\n",
      "    linear_96 = torch.ops.aten.linear.default(layer_norm_33, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_q_proj_bias = None\n",
      "    mul_50 = torch.ops.aten.mul.Tensor(linear_96, b__tensor_constant_33);  linear_96 = b__tensor_constant_33 = None\n",
      "    linear_97 = torch.ops.aten.linear.default(layer_norm_33, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_k_proj_bias = None\n",
      "    view_126 = torch.ops.aten.view.default(linear_97, [1, -1, 16, 64]);  linear_97 = None\n",
      "    transpose_81 = torch.ops.aten.transpose.int(view_126, 1, 2);  view_126 = None\n",
      "    clone_67 = torch.ops.aten.clone.default(transpose_81, memory_format = torch.contiguous_format);  transpose_81 = None\n",
      "    linear_98 = torch.ops.aten.linear.default(layer_norm_33, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_bias);  layer_norm_33 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_v_proj_bias = None\n",
      "    view_127 = torch.ops.aten.view.default(linear_98, [1, -1, 16, 64]);  linear_98 = None\n",
      "    transpose_82 = torch.ops.aten.transpose.int(view_127, 1, 2);  view_127 = None\n",
      "    clone_68 = torch.ops.aten.clone.default(transpose_82, memory_format = torch.contiguous_format);  transpose_82 = None\n",
      "    view_128 = torch.ops.aten.view.default(mul_50, [1, sym_size_int_8, 16, 64]);  mul_50 = None\n",
      "    transpose_83 = torch.ops.aten.transpose.int(view_128, 1, 2);  view_128 = None\n",
      "    clone_69 = torch.ops.aten.clone.default(transpose_83, memory_format = torch.contiguous_format);  transpose_83 = None\n",
      "    view_129 = torch.ops.aten.view.default(clone_69, [16, -1, 64]);  clone_69 = None\n",
      "    view_130 = torch.ops.aten.view.default(clone_67, [16, -1, 64]);  clone_67 = None\n",
      "    view_131 = torch.ops.aten.view.default(clone_68, [16, -1, 64]);  clone_68 = None\n",
      "    transpose_84 = torch.ops.aten.transpose.int(view_130, 1, 2);  view_130 = None\n",
      "    bmm_32 = torch.ops.aten.bmm.default(view_129, transpose_84);  view_129 = transpose_84 = None\n",
      "    softmax_16 = torch.ops.aten.softmax.int(bmm_32, -1);  bmm_32 = None\n",
      "    dropout_16 = torch.ops.aten.dropout.default(softmax_16, 0.0, False);  softmax_16 = None\n",
      "    bmm_33 = torch.ops.aten.bmm.default(dropout_16, view_131);  dropout_16 = view_131 = None\n",
      "    view_132 = torch.ops.aten.view.default(bmm_33, [1, 16, sym_size_int_8, 64]);  bmm_33 = None\n",
      "    transpose_85 = torch.ops.aten.transpose.int(view_132, 1, 2);  view_132 = None\n",
      "    clone_70 = torch.ops.aten.clone.default(transpose_85, memory_format = torch.contiguous_format);  transpose_85 = None\n",
      "    _unsafe_view_16 = torch.ops.aten._unsafe_view.default(clone_70, [1, sym_size_int_8, 1024]);  clone_70 = None\n",
      "    linear_99 = torch.ops.aten.linear.default(_unsafe_view_16, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_bias);  _unsafe_view_16 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___self_attn_out_proj_bias = None\n",
      "    add_33 = torch.ops.aten.add.Tensor(add_32, linear_99);  add_32 = linear_99 = None\n",
      "    layer_norm_34 = torch.ops.aten.layer_norm.default(add_33, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___layer_norm2_bias = None\n",
      "    linear_100 = torch.ops.aten.linear.default(layer_norm_34, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_bias);  layer_norm_34 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc1_bias = None\n",
      "    mul_51 = torch.ops.aten.mul.Tensor(linear_100, b__tensor_constant_34);  b__tensor_constant_34 = None\n",
      "    sigmoid_16 = torch.ops.aten.sigmoid.default(mul_51);  mul_51 = None\n",
      "    mul_52 = torch.ops.aten.mul.Tensor(linear_100, sigmoid_16);  linear_100 = sigmoid_16 = None\n",
      "    linear_101 = torch.ops.aten.linear.default(mul_52, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_bias);  mul_52 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___16___mlp_fc2_bias = None\n",
      "    add_34 = torch.ops.aten.add.Tensor(add_33, linear_101);  add_33 = linear_101 = None\n",
      "    layer_norm_35 = torch.ops.aten.layer_norm.default(add_34, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm1_bias = None\n",
      "    linear_102 = torch.ops.aten.linear.default(layer_norm_35, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_q_proj_bias = None\n",
      "    mul_53 = torch.ops.aten.mul.Tensor(linear_102, b__tensor_constant_35);  linear_102 = b__tensor_constant_35 = None\n",
      "    linear_103 = torch.ops.aten.linear.default(layer_norm_35, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_k_proj_bias = None\n",
      "    view_133 = torch.ops.aten.view.default(linear_103, [1, -1, 16, 64]);  linear_103 = None\n",
      "    transpose_86 = torch.ops.aten.transpose.int(view_133, 1, 2);  view_133 = None\n",
      "    clone_71 = torch.ops.aten.clone.default(transpose_86, memory_format = torch.contiguous_format);  transpose_86 = None\n",
      "    linear_104 = torch.ops.aten.linear.default(layer_norm_35, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_bias);  layer_norm_35 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_v_proj_bias = None\n",
      "    view_134 = torch.ops.aten.view.default(linear_104, [1, -1, 16, 64]);  linear_104 = None\n",
      "    transpose_87 = torch.ops.aten.transpose.int(view_134, 1, 2);  view_134 = None\n",
      "    clone_72 = torch.ops.aten.clone.default(transpose_87, memory_format = torch.contiguous_format);  transpose_87 = None\n",
      "    view_135 = torch.ops.aten.view.default(mul_53, [1, sym_size_int_8, 16, 64]);  mul_53 = None\n",
      "    transpose_88 = torch.ops.aten.transpose.int(view_135, 1, 2);  view_135 = None\n",
      "    clone_73 = torch.ops.aten.clone.default(transpose_88, memory_format = torch.contiguous_format);  transpose_88 = None\n",
      "    view_136 = torch.ops.aten.view.default(clone_73, [16, -1, 64]);  clone_73 = None\n",
      "    view_137 = torch.ops.aten.view.default(clone_71, [16, -1, 64]);  clone_71 = None\n",
      "    view_138 = torch.ops.aten.view.default(clone_72, [16, -1, 64]);  clone_72 = None\n",
      "    transpose_89 = torch.ops.aten.transpose.int(view_137, 1, 2);  view_137 = None\n",
      "    bmm_34 = torch.ops.aten.bmm.default(view_136, transpose_89);  view_136 = transpose_89 = None\n",
      "    softmax_17 = torch.ops.aten.softmax.int(bmm_34, -1);  bmm_34 = None\n",
      "    dropout_17 = torch.ops.aten.dropout.default(softmax_17, 0.0, False);  softmax_17 = None\n",
      "    bmm_35 = torch.ops.aten.bmm.default(dropout_17, view_138);  dropout_17 = view_138 = None\n",
      "    view_139 = torch.ops.aten.view.default(bmm_35, [1, 16, sym_size_int_8, 64]);  bmm_35 = None\n",
      "    transpose_90 = torch.ops.aten.transpose.int(view_139, 1, 2);  view_139 = None\n",
      "    clone_74 = torch.ops.aten.clone.default(transpose_90, memory_format = torch.contiguous_format);  transpose_90 = None\n",
      "    _unsafe_view_17 = torch.ops.aten._unsafe_view.default(clone_74, [1, sym_size_int_8, 1024]);  clone_74 = None\n",
      "    linear_105 = torch.ops.aten.linear.default(_unsafe_view_17, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_bias);  _unsafe_view_17 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___self_attn_out_proj_bias = None\n",
      "    add_35 = torch.ops.aten.add.Tensor(add_34, linear_105);  add_34 = linear_105 = None\n",
      "    layer_norm_36 = torch.ops.aten.layer_norm.default(add_35, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___layer_norm2_bias = None\n",
      "    linear_106 = torch.ops.aten.linear.default(layer_norm_36, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_bias);  layer_norm_36 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc1_bias = None\n",
      "    mul_54 = torch.ops.aten.mul.Tensor(linear_106, b__tensor_constant_36);  b__tensor_constant_36 = None\n",
      "    sigmoid_17 = torch.ops.aten.sigmoid.default(mul_54);  mul_54 = None\n",
      "    mul_55 = torch.ops.aten.mul.Tensor(linear_106, sigmoid_17);  linear_106 = sigmoid_17 = None\n",
      "    linear_107 = torch.ops.aten.linear.default(mul_55, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_bias);  mul_55 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___17___mlp_fc2_bias = None\n",
      "    add_36 = torch.ops.aten.add.Tensor(add_35, linear_107);  add_35 = linear_107 = None\n",
      "    layer_norm_37 = torch.ops.aten.layer_norm.default(add_36, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm1_bias = None\n",
      "    linear_108 = torch.ops.aten.linear.default(layer_norm_37, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_q_proj_bias = None\n",
      "    mul_56 = torch.ops.aten.mul.Tensor(linear_108, b__tensor_constant_37);  linear_108 = b__tensor_constant_37 = None\n",
      "    linear_109 = torch.ops.aten.linear.default(layer_norm_37, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_k_proj_bias = None\n",
      "    view_140 = torch.ops.aten.view.default(linear_109, [1, -1, 16, 64]);  linear_109 = None\n",
      "    transpose_91 = torch.ops.aten.transpose.int(view_140, 1, 2);  view_140 = None\n",
      "    clone_75 = torch.ops.aten.clone.default(transpose_91, memory_format = torch.contiguous_format);  transpose_91 = None\n",
      "    linear_110 = torch.ops.aten.linear.default(layer_norm_37, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_bias);  layer_norm_37 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_v_proj_bias = None\n",
      "    view_141 = torch.ops.aten.view.default(linear_110, [1, -1, 16, 64]);  linear_110 = None\n",
      "    transpose_92 = torch.ops.aten.transpose.int(view_141, 1, 2);  view_141 = None\n",
      "    clone_76 = torch.ops.aten.clone.default(transpose_92, memory_format = torch.contiguous_format);  transpose_92 = None\n",
      "    view_142 = torch.ops.aten.view.default(mul_56, [1, sym_size_int_8, 16, 64]);  mul_56 = None\n",
      "    transpose_93 = torch.ops.aten.transpose.int(view_142, 1, 2);  view_142 = None\n",
      "    clone_77 = torch.ops.aten.clone.default(transpose_93, memory_format = torch.contiguous_format);  transpose_93 = None\n",
      "    view_143 = torch.ops.aten.view.default(clone_77, [16, -1, 64]);  clone_77 = None\n",
      "    view_144 = torch.ops.aten.view.default(clone_75, [16, -1, 64]);  clone_75 = None\n",
      "    view_145 = torch.ops.aten.view.default(clone_76, [16, -1, 64]);  clone_76 = None\n",
      "    transpose_94 = torch.ops.aten.transpose.int(view_144, 1, 2);  view_144 = None\n",
      "    bmm_36 = torch.ops.aten.bmm.default(view_143, transpose_94);  view_143 = transpose_94 = None\n",
      "    softmax_18 = torch.ops.aten.softmax.int(bmm_36, -1);  bmm_36 = None\n",
      "    dropout_18 = torch.ops.aten.dropout.default(softmax_18, 0.0, False);  softmax_18 = None\n",
      "    bmm_37 = torch.ops.aten.bmm.default(dropout_18, view_145);  dropout_18 = view_145 = None\n",
      "    view_146 = torch.ops.aten.view.default(bmm_37, [1, 16, sym_size_int_8, 64]);  bmm_37 = None\n",
      "    transpose_95 = torch.ops.aten.transpose.int(view_146, 1, 2);  view_146 = None\n",
      "    clone_78 = torch.ops.aten.clone.default(transpose_95, memory_format = torch.contiguous_format);  transpose_95 = None\n",
      "    _unsafe_view_18 = torch.ops.aten._unsafe_view.default(clone_78, [1, sym_size_int_8, 1024]);  clone_78 = None\n",
      "    linear_111 = torch.ops.aten.linear.default(_unsafe_view_18, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_bias);  _unsafe_view_18 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___self_attn_out_proj_bias = None\n",
      "    add_37 = torch.ops.aten.add.Tensor(add_36, linear_111);  add_36 = linear_111 = None\n",
      "    layer_norm_38 = torch.ops.aten.layer_norm.default(add_37, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___layer_norm2_bias = None\n",
      "    linear_112 = torch.ops.aten.linear.default(layer_norm_38, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_bias);  layer_norm_38 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc1_bias = None\n",
      "    mul_57 = torch.ops.aten.mul.Tensor(linear_112, b__tensor_constant_38);  b__tensor_constant_38 = None\n",
      "    sigmoid_18 = torch.ops.aten.sigmoid.default(mul_57);  mul_57 = None\n",
      "    mul_58 = torch.ops.aten.mul.Tensor(linear_112, sigmoid_18);  linear_112 = sigmoid_18 = None\n",
      "    linear_113 = torch.ops.aten.linear.default(mul_58, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_bias);  mul_58 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___18___mlp_fc2_bias = None\n",
      "    add_38 = torch.ops.aten.add.Tensor(add_37, linear_113);  add_37 = linear_113 = None\n",
      "    layer_norm_39 = torch.ops.aten.layer_norm.default(add_38, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm1_bias = None\n",
      "    linear_114 = torch.ops.aten.linear.default(layer_norm_39, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_q_proj_bias = None\n",
      "    mul_59 = torch.ops.aten.mul.Tensor(linear_114, b__tensor_constant_39);  linear_114 = b__tensor_constant_39 = None\n",
      "    linear_115 = torch.ops.aten.linear.default(layer_norm_39, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_k_proj_bias = None\n",
      "    view_147 = torch.ops.aten.view.default(linear_115, [1, -1, 16, 64]);  linear_115 = None\n",
      "    transpose_96 = torch.ops.aten.transpose.int(view_147, 1, 2);  view_147 = None\n",
      "    clone_79 = torch.ops.aten.clone.default(transpose_96, memory_format = torch.contiguous_format);  transpose_96 = None\n",
      "    linear_116 = torch.ops.aten.linear.default(layer_norm_39, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_bias);  layer_norm_39 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_v_proj_bias = None\n",
      "    view_148 = torch.ops.aten.view.default(linear_116, [1, -1, 16, 64]);  linear_116 = None\n",
      "    transpose_97 = torch.ops.aten.transpose.int(view_148, 1, 2);  view_148 = None\n",
      "    clone_80 = torch.ops.aten.clone.default(transpose_97, memory_format = torch.contiguous_format);  transpose_97 = None\n",
      "    view_149 = torch.ops.aten.view.default(mul_59, [1, sym_size_int_8, 16, 64]);  mul_59 = None\n",
      "    transpose_98 = torch.ops.aten.transpose.int(view_149, 1, 2);  view_149 = None\n",
      "    clone_81 = torch.ops.aten.clone.default(transpose_98, memory_format = torch.contiguous_format);  transpose_98 = None\n",
      "    view_150 = torch.ops.aten.view.default(clone_81, [16, -1, 64]);  clone_81 = None\n",
      "    view_151 = torch.ops.aten.view.default(clone_79, [16, -1, 64]);  clone_79 = None\n",
      "    view_152 = torch.ops.aten.view.default(clone_80, [16, -1, 64]);  clone_80 = None\n",
      "    transpose_99 = torch.ops.aten.transpose.int(view_151, 1, 2);  view_151 = None\n",
      "    bmm_38 = torch.ops.aten.bmm.default(view_150, transpose_99);  view_150 = transpose_99 = None\n",
      "    softmax_19 = torch.ops.aten.softmax.int(bmm_38, -1);  bmm_38 = None\n",
      "    dropout_19 = torch.ops.aten.dropout.default(softmax_19, 0.0, False);  softmax_19 = None\n",
      "    bmm_39 = torch.ops.aten.bmm.default(dropout_19, view_152);  dropout_19 = view_152 = None\n",
      "    view_153 = torch.ops.aten.view.default(bmm_39, [1, 16, sym_size_int_8, 64]);  bmm_39 = None\n",
      "    transpose_100 = torch.ops.aten.transpose.int(view_153, 1, 2);  view_153 = None\n",
      "    clone_82 = torch.ops.aten.clone.default(transpose_100, memory_format = torch.contiguous_format);  transpose_100 = None\n",
      "    _unsafe_view_19 = torch.ops.aten._unsafe_view.default(clone_82, [1, sym_size_int_8, 1024]);  clone_82 = None\n",
      "    linear_117 = torch.ops.aten.linear.default(_unsafe_view_19, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_bias);  _unsafe_view_19 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___self_attn_out_proj_bias = None\n",
      "    add_39 = torch.ops.aten.add.Tensor(add_38, linear_117);  add_38 = linear_117 = None\n",
      "    layer_norm_40 = torch.ops.aten.layer_norm.default(add_39, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___layer_norm2_bias = None\n",
      "    linear_118 = torch.ops.aten.linear.default(layer_norm_40, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_bias);  layer_norm_40 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc1_bias = None\n",
      "    mul_60 = torch.ops.aten.mul.Tensor(linear_118, b__tensor_constant_40);  b__tensor_constant_40 = None\n",
      "    sigmoid_19 = torch.ops.aten.sigmoid.default(mul_60);  mul_60 = None\n",
      "    mul_61 = torch.ops.aten.mul.Tensor(linear_118, sigmoid_19);  linear_118 = sigmoid_19 = None\n",
      "    linear_119 = torch.ops.aten.linear.default(mul_61, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_bias);  mul_61 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___19___mlp_fc2_bias = None\n",
      "    add_40 = torch.ops.aten.add.Tensor(add_39, linear_119);  add_39 = linear_119 = None\n",
      "    layer_norm_41 = torch.ops.aten.layer_norm.default(add_40, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm1_bias = None\n",
      "    linear_120 = torch.ops.aten.linear.default(layer_norm_41, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_q_proj_bias = None\n",
      "    mul_62 = torch.ops.aten.mul.Tensor(linear_120, b__tensor_constant_41);  linear_120 = b__tensor_constant_41 = None\n",
      "    linear_121 = torch.ops.aten.linear.default(layer_norm_41, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_k_proj_bias = None\n",
      "    view_154 = torch.ops.aten.view.default(linear_121, [1, -1, 16, 64]);  linear_121 = None\n",
      "    transpose_101 = torch.ops.aten.transpose.int(view_154, 1, 2);  view_154 = None\n",
      "    clone_83 = torch.ops.aten.clone.default(transpose_101, memory_format = torch.contiguous_format);  transpose_101 = None\n",
      "    linear_122 = torch.ops.aten.linear.default(layer_norm_41, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_bias);  layer_norm_41 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_v_proj_bias = None\n",
      "    view_155 = torch.ops.aten.view.default(linear_122, [1, -1, 16, 64]);  linear_122 = None\n",
      "    transpose_102 = torch.ops.aten.transpose.int(view_155, 1, 2);  view_155 = None\n",
      "    clone_84 = torch.ops.aten.clone.default(transpose_102, memory_format = torch.contiguous_format);  transpose_102 = None\n",
      "    view_156 = torch.ops.aten.view.default(mul_62, [1, sym_size_int_8, 16, 64]);  mul_62 = None\n",
      "    transpose_103 = torch.ops.aten.transpose.int(view_156, 1, 2);  view_156 = None\n",
      "    clone_85 = torch.ops.aten.clone.default(transpose_103, memory_format = torch.contiguous_format);  transpose_103 = None\n",
      "    view_157 = torch.ops.aten.view.default(clone_85, [16, -1, 64]);  clone_85 = None\n",
      "    view_158 = torch.ops.aten.view.default(clone_83, [16, -1, 64]);  clone_83 = None\n",
      "    view_159 = torch.ops.aten.view.default(clone_84, [16, -1, 64]);  clone_84 = None\n",
      "    transpose_104 = torch.ops.aten.transpose.int(view_158, 1, 2);  view_158 = None\n",
      "    bmm_40 = torch.ops.aten.bmm.default(view_157, transpose_104);  view_157 = transpose_104 = None\n",
      "    softmax_20 = torch.ops.aten.softmax.int(bmm_40, -1);  bmm_40 = None\n",
      "    dropout_20 = torch.ops.aten.dropout.default(softmax_20, 0.0, False);  softmax_20 = None\n",
      "    bmm_41 = torch.ops.aten.bmm.default(dropout_20, view_159);  dropout_20 = view_159 = None\n",
      "    view_160 = torch.ops.aten.view.default(bmm_41, [1, 16, sym_size_int_8, 64]);  bmm_41 = None\n",
      "    transpose_105 = torch.ops.aten.transpose.int(view_160, 1, 2);  view_160 = None\n",
      "    clone_86 = torch.ops.aten.clone.default(transpose_105, memory_format = torch.contiguous_format);  transpose_105 = None\n",
      "    _unsafe_view_20 = torch.ops.aten._unsafe_view.default(clone_86, [1, sym_size_int_8, 1024]);  clone_86 = None\n",
      "    linear_123 = torch.ops.aten.linear.default(_unsafe_view_20, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_bias);  _unsafe_view_20 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___self_attn_out_proj_bias = None\n",
      "    add_41 = torch.ops.aten.add.Tensor(add_40, linear_123);  add_40 = linear_123 = None\n",
      "    layer_norm_42 = torch.ops.aten.layer_norm.default(add_41, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___layer_norm2_bias = None\n",
      "    linear_124 = torch.ops.aten.linear.default(layer_norm_42, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_bias);  layer_norm_42 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc1_bias = None\n",
      "    mul_63 = torch.ops.aten.mul.Tensor(linear_124, b__tensor_constant_42);  b__tensor_constant_42 = None\n",
      "    sigmoid_20 = torch.ops.aten.sigmoid.default(mul_63);  mul_63 = None\n",
      "    mul_64 = torch.ops.aten.mul.Tensor(linear_124, sigmoid_20);  linear_124 = sigmoid_20 = None\n",
      "    linear_125 = torch.ops.aten.linear.default(mul_64, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_bias);  mul_64 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___20___mlp_fc2_bias = None\n",
      "    add_42 = torch.ops.aten.add.Tensor(add_41, linear_125);  add_41 = linear_125 = None\n",
      "    layer_norm_43 = torch.ops.aten.layer_norm.default(add_42, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm1_bias = None\n",
      "    linear_126 = torch.ops.aten.linear.default(layer_norm_43, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_q_proj_bias = None\n",
      "    mul_65 = torch.ops.aten.mul.Tensor(linear_126, b__tensor_constant_43);  linear_126 = b__tensor_constant_43 = None\n",
      "    linear_127 = torch.ops.aten.linear.default(layer_norm_43, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_k_proj_bias = None\n",
      "    view_161 = torch.ops.aten.view.default(linear_127, [1, -1, 16, 64]);  linear_127 = None\n",
      "    transpose_106 = torch.ops.aten.transpose.int(view_161, 1, 2);  view_161 = None\n",
      "    clone_87 = torch.ops.aten.clone.default(transpose_106, memory_format = torch.contiguous_format);  transpose_106 = None\n",
      "    linear_128 = torch.ops.aten.linear.default(layer_norm_43, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_bias);  layer_norm_43 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_v_proj_bias = None\n",
      "    view_162 = torch.ops.aten.view.default(linear_128, [1, -1, 16, 64]);  linear_128 = None\n",
      "    transpose_107 = torch.ops.aten.transpose.int(view_162, 1, 2);  view_162 = None\n",
      "    clone_88 = torch.ops.aten.clone.default(transpose_107, memory_format = torch.contiguous_format);  transpose_107 = None\n",
      "    view_163 = torch.ops.aten.view.default(mul_65, [1, sym_size_int_8, 16, 64]);  mul_65 = None\n",
      "    transpose_108 = torch.ops.aten.transpose.int(view_163, 1, 2);  view_163 = None\n",
      "    clone_89 = torch.ops.aten.clone.default(transpose_108, memory_format = torch.contiguous_format);  transpose_108 = None\n",
      "    view_164 = torch.ops.aten.view.default(clone_89, [16, -1, 64]);  clone_89 = None\n",
      "    view_165 = torch.ops.aten.view.default(clone_87, [16, -1, 64]);  clone_87 = None\n",
      "    view_166 = torch.ops.aten.view.default(clone_88, [16, -1, 64]);  clone_88 = None\n",
      "    transpose_109 = torch.ops.aten.transpose.int(view_165, 1, 2);  view_165 = None\n",
      "    bmm_42 = torch.ops.aten.bmm.default(view_164, transpose_109);  view_164 = transpose_109 = None\n",
      "    softmax_21 = torch.ops.aten.softmax.int(bmm_42, -1);  bmm_42 = None\n",
      "    dropout_21 = torch.ops.aten.dropout.default(softmax_21, 0.0, False);  softmax_21 = None\n",
      "    bmm_43 = torch.ops.aten.bmm.default(dropout_21, view_166);  dropout_21 = view_166 = None\n",
      "    view_167 = torch.ops.aten.view.default(bmm_43, [1, 16, sym_size_int_8, 64]);  bmm_43 = None\n",
      "    transpose_110 = torch.ops.aten.transpose.int(view_167, 1, 2);  view_167 = None\n",
      "    clone_90 = torch.ops.aten.clone.default(transpose_110, memory_format = torch.contiguous_format);  transpose_110 = None\n",
      "    _unsafe_view_21 = torch.ops.aten._unsafe_view.default(clone_90, [1, sym_size_int_8, 1024]);  clone_90 = None\n",
      "    linear_129 = torch.ops.aten.linear.default(_unsafe_view_21, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_bias);  _unsafe_view_21 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___self_attn_out_proj_bias = None\n",
      "    add_43 = torch.ops.aten.add.Tensor(add_42, linear_129);  add_42 = linear_129 = None\n",
      "    layer_norm_44 = torch.ops.aten.layer_norm.default(add_43, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___layer_norm2_bias = None\n",
      "    linear_130 = torch.ops.aten.linear.default(layer_norm_44, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_bias);  layer_norm_44 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc1_bias = None\n",
      "    mul_66 = torch.ops.aten.mul.Tensor(linear_130, b__tensor_constant_44);  b__tensor_constant_44 = None\n",
      "    sigmoid_21 = torch.ops.aten.sigmoid.default(mul_66);  mul_66 = None\n",
      "    mul_67 = torch.ops.aten.mul.Tensor(linear_130, sigmoid_21);  linear_130 = sigmoid_21 = None\n",
      "    linear_131 = torch.ops.aten.linear.default(mul_67, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_bias);  mul_67 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___21___mlp_fc2_bias = None\n",
      "    add_44 = torch.ops.aten.add.Tensor(add_43, linear_131);  add_43 = linear_131 = None\n",
      "    layer_norm_45 = torch.ops.aten.layer_norm.default(add_44, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm1_bias = None\n",
      "    linear_132 = torch.ops.aten.linear.default(layer_norm_45, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_q_proj_bias = None\n",
      "    mul_68 = torch.ops.aten.mul.Tensor(linear_132, b__tensor_constant_45);  linear_132 = b__tensor_constant_45 = None\n",
      "    linear_133 = torch.ops.aten.linear.default(layer_norm_45, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_k_proj_bias = None\n",
      "    view_168 = torch.ops.aten.view.default(linear_133, [1, -1, 16, 64]);  linear_133 = None\n",
      "    transpose_111 = torch.ops.aten.transpose.int(view_168, 1, 2);  view_168 = None\n",
      "    clone_91 = torch.ops.aten.clone.default(transpose_111, memory_format = torch.contiguous_format);  transpose_111 = None\n",
      "    linear_134 = torch.ops.aten.linear.default(layer_norm_45, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_bias);  layer_norm_45 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_v_proj_bias = None\n",
      "    view_169 = torch.ops.aten.view.default(linear_134, [1, -1, 16, 64]);  linear_134 = None\n",
      "    transpose_112 = torch.ops.aten.transpose.int(view_169, 1, 2);  view_169 = None\n",
      "    clone_92 = torch.ops.aten.clone.default(transpose_112, memory_format = torch.contiguous_format);  transpose_112 = None\n",
      "    view_170 = torch.ops.aten.view.default(mul_68, [1, sym_size_int_8, 16, 64]);  mul_68 = None\n",
      "    transpose_113 = torch.ops.aten.transpose.int(view_170, 1, 2);  view_170 = None\n",
      "    clone_93 = torch.ops.aten.clone.default(transpose_113, memory_format = torch.contiguous_format);  transpose_113 = None\n",
      "    view_171 = torch.ops.aten.view.default(clone_93, [16, -1, 64]);  clone_93 = None\n",
      "    view_172 = torch.ops.aten.view.default(clone_91, [16, -1, 64]);  clone_91 = None\n",
      "    view_173 = torch.ops.aten.view.default(clone_92, [16, -1, 64]);  clone_92 = None\n",
      "    transpose_114 = torch.ops.aten.transpose.int(view_172, 1, 2);  view_172 = None\n",
      "    bmm_44 = torch.ops.aten.bmm.default(view_171, transpose_114);  view_171 = transpose_114 = None\n",
      "    softmax_22 = torch.ops.aten.softmax.int(bmm_44, -1);  bmm_44 = None\n",
      "    dropout_22 = torch.ops.aten.dropout.default(softmax_22, 0.0, False);  softmax_22 = None\n",
      "    bmm_45 = torch.ops.aten.bmm.default(dropout_22, view_173);  dropout_22 = view_173 = None\n",
      "    view_174 = torch.ops.aten.view.default(bmm_45, [1, 16, sym_size_int_8, 64]);  bmm_45 = None\n",
      "    transpose_115 = torch.ops.aten.transpose.int(view_174, 1, 2);  view_174 = None\n",
      "    clone_94 = torch.ops.aten.clone.default(transpose_115, memory_format = torch.contiguous_format);  transpose_115 = None\n",
      "    _unsafe_view_22 = torch.ops.aten._unsafe_view.default(clone_94, [1, sym_size_int_8, 1024]);  clone_94 = sym_size_int_8 = None\n",
      "    linear_135 = torch.ops.aten.linear.default(_unsafe_view_22, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_bias);  _unsafe_view_22 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___self_attn_out_proj_bias = None\n",
      "    add_45 = torch.ops.aten.add.Tensor(add_44, linear_135);  add_44 = linear_135 = None\n",
      "    layer_norm_46 = torch.ops.aten.layer_norm.default(add_45, [1024], p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_bias);  p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___layer_norm2_bias = None\n",
      "    linear_136 = torch.ops.aten.linear.default(layer_norm_46, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_bias);  layer_norm_46 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc1_bias = None\n",
      "    mul_69 = torch.ops.aten.mul.Tensor(linear_136, b__tensor_constant_46);  b__tensor_constant_46 = None\n",
      "    sigmoid_22 = torch.ops.aten.sigmoid.default(mul_69);  mul_69 = None\n",
      "    mul_70 = torch.ops.aten.mul.Tensor(linear_136, sigmoid_22);  linear_136 = sigmoid_22 = None\n",
      "    linear_137 = torch.ops.aten.linear.default(mul_70, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_weight, p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_bias);  mul_70 = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_weight = p_getattr_l__self___llava_vision_tower_vision_tower_vision_model_encoder_layers___22___mlp_fc2_bias = None\n",
      "    add_46 = torch.ops.aten.add.Tensor(add_45, linear_137);  add_45 = linear_137 = None\n",
      "    slice_9 = torch.ops.aten.slice.Tensor(add_46, 0, 0, 9223372036854775807);  add_46 = None\n",
      "    slice_10 = torch.ops.aten.slice.Tensor(slice_9, 1, 1, 9223372036854775807);  slice_9 = None\n",
      "    _to_copy_4 = torch.ops.aten._to_copy.default(slice_10, dtype = torch.float32);  slice_10 = None\n",
      "    linear_138 = torch.ops.aten.linear.default(_to_copy_4, p_getattr_l__self___llava_mm_projector___0___weight, p_getattr_l__self___llava_mm_projector___0___bias);  _to_copy_4 = p_getattr_l__self___llava_mm_projector___0___weight = p_getattr_l__self___llava_mm_projector___0___bias = None\n",
      "    gelu = torch.ops.aten.gelu.default(linear_138);  linear_138 = None\n",
      "    linear_139 = torch.ops.aten.linear.default(gelu, p_getattr_l__self___llava_mm_projector___2___weight, p_getattr_l__self___llava_mm_projector___2___bias);  gelu = p_getattr_l__self___llava_mm_projector___2___weight = p_getattr_l__self___llava_mm_projector___2___bias = None\n",
      "    return (linear_139,)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(image_encoder_ep.graph_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2371,  0.3631, -0.0441,  ..., -0.1353,  0.2472, -0.2302],\n",
       "         [-0.3388,  0.1704, -0.1123,  ..., -0.2558,  0.3026, -0.2548],\n",
       "         [ 0.0499,  0.3224, -0.8425,  ...,  0.2822,  0.1548,  0.1321],\n",
       "         ...,\n",
       "         [ 0.4325,  0.0073, -0.8408,  ...,  0.1987,  0.3378,  0.3019],\n",
       "         [-0.1202,  0.4336, -0.4758,  ..., -0.1029,  0.4463, -0.2296],\n",
       "         [-0.2647,  0.1652, -0.2276,  ..., -0.4157,  0.5271, -0.3791]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llava_image_encode(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[program.cpp:130] InternalConsistency verification requested but not available\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:536] Missing operator: [13] llama::sdpa_with_kv_cache.out\n",
      "[method.cpp:724] There are 32 instructions don't have corresponding operator registered. See logs for details\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "loading method text_model failed with error 0x14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexecutorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpybindings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mportable_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m _load_for_executorch_from_buffer\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexecutorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexamples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllama2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcustom_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m sdpa_with_kv_cache\n\u001b[0;32m----> 4\u001b[0m llava \u001b[39m=\u001b[39m _load_for_executorch_from_buffer(executorch_program\u001b[39m.\u001b[39;49mbuffer)\n\u001b[1;32m      5\u001b[0m llava\u001b[39m.\u001b[39mrun_method(\u001b[39m\"\u001b[39m\u001b[39mimage_encoder\u001b[39m\u001b[39m\"\u001b[39m, (resized, ))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: loading method text_model failed with error 0x14"
     ]
    }
   ],
   "source": [
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch_from_buffer\n",
    "from executorch.examples.models.llama2.custom_ops import sdpa_with_kv_cache\n",
    "\n",
    "llava = _load_for_executorch_from_buffer(executorch_program.buffer)\n",
    "llava.run_method(\"image_encoder\", (resized, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"llava_combined.pte\", \"wb\") as f:\n",
    "    executorch_program.write_to_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'executorch_program' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexecutorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpybindings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mportable_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m _load_for_executorch_from_buffer\n\u001b[0;32m----> 3\u001b[0m mod \u001b[39m=\u001b[39m _load_for_executorch_from_buffer(executorch_program\u001b[39m.\u001b[39mexport_program\u001b[39m.\u001b[39mbuffer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'executorch_program' is not defined"
     ]
    }
   ],
   "source": [
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch_from_buffer\n",
    "\n",
    "mod = _load_for_executorch_from_buffer(executorch_program.export_program.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefill_logits = mod.forward((embeddings, torch.tensor([0], dtype=torch.int64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "executorch_program.save_to_pte(\"llava_text_model.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 1.6735,  0.1196, -0.4820,  ...,  2.1009,  2.9855,  1.8944],\n",
      "         [-9.3342, -5.7767, -1.6815,  ..., -7.3758, -8.0255, -8.2427],\n",
      "         [-6.2474, -8.4929,  8.0868,  ..., -3.9906, -2.6139, -2.8941],\n",
      "         ...,\n",
      "         [-6.6372, -2.0630,  9.0358,  ..., -1.6830, -3.7572, -3.1622],\n",
      "         [-3.4966, -2.5555,  7.4756,  ..., -0.0967, -0.2558,  1.3910],\n",
      "         [-1.6580, -2.6137,  9.7109,  ...,  1.1886,  1.6523,  2.0759]]])]\n"
     ]
    }
   ],
   "source": [
    "print(prefill_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefill_logits = prefill_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizer(name_or_path='liuhaotian/llava-v1.5-7b', vocab_size=32000, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./tokenizer.model',)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer)\n",
    "tokenizer.save_vocabulary(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.exir import to_edge, EdgeCompileConfig\n",
    "\n",
    "class LlavaTokenEmbedding(torch.nn.Module):\n",
    "    \"\"\" Takes a token and returns the token embedding. Result will be sent to the text model LlavaTextModel.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, token):\n",
    "        return llava.token_embedding(token)\n",
    "    \n",
    "llava_token_embedding = LlavaTokenEmbedding()\n",
    "token = torch.tensor([0])\n",
    "token_embedding_ep = torch.export.export(llava_token_embedding, (token,), strict=False)\n",
    "embedding_program = to_edge(token_embedding_ep, compile_config=EdgeCompileConfig(_check_ir_validity=False)).to_executorch()\n",
    "with open(\"llava_embedding.pte\", \"wb\") as f:\n",
    "    embedding_program.write_to_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[program.cpp:130] InternalConsistency verification requested but not available\n",
      "[program.cpp:130] InternalConsistency verification requested but not available\n"
     ]
    }
   ],
   "source": [
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "\n",
    "image_encoder = _load_for_executorch(\"./llava_prefill.pte\")\n",
    "embedding = _load_for_executorch(\"./llava_embedding.pte\")\n",
    "text_model = _load_for_executorch(\"./llava_text_model.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tok_emb = embedding.forward((torch.tensor([0], dtype=torch.int64), ))\n",
    "logits = text_model.forward((tok_emb[0], torch.tensor([0], dtype=torch.int64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[pybindings.cpp:553] In function run_method(), assert failed (false): Execution should not reach this point. <class 'list'>"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "context_len = prefill_logits.shape[1]\n",
    "print(prefill_logits)\n",
    "# first token\n",
    "new_tokens = [torch.argmax(prefill_logits[..., -1, :]).item()]\n",
    "# print(tokenizer.decode(new_tokens))\n",
    "for i in range(512):\n",
    "    print(i, tokenizer.decode(new_tokens[i]))\n",
    "    tok_emb = embedding.forward((torch.tensor([new_tokens[i]], dtype=torch.int64), ))\n",
    "    logits = text_model.forward((tok_emb[0], torch.tensor([context_len + i], dtype=torch.int64)))\n",
    "    new_tokens.append(torch.argmax(logits[-1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantizer\n",
    "linear_quantizer = XNNPACKQuantizer()\n",
    "operator_config_dynamic = get_symmetric_quantization_config(\n",
    "    is_per_channel=True, is_dynamic=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/export/_unlift.py:59: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer\n",
      "  getattr_node = gm.graph.get_attr(lifted_node)\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_0 target lifted_tensor_0 lifted_tensor_0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_1 target lifted_tensor_1 lifted_tensor_1 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/torch/fx/graph.py:1568: UserWarning: Node lifted_tensor_2 target lifted_tensor_2 lifted_tensor_2 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "[INFO 2024-07-11 00:59:24,214 builder.py:179] Using pt2e [<torch.ao.quantization.quantizer.xnnpack_quantizer.XNNPACKQuantizer object at 0x4aec67a90>] to quantizing the model...\n"
     ]
    }
   ],
   "source": [
    "image_encoder_ep = LlavaEdgeManager(\n",
    "    model=llava_image_encode,\n",
    "    modelname=\"llava_image_encoder\",\n",
    "    weight_type=WeightType.LLAMA,\n",
    "    dtype=DType.fp32,\n",
    "    use_kv_cache=True,\n",
    "    use_sdpa_with_kv_cache=True,\n",
    "    example_inputs=(resized,),\n",
    "    dynamic_shapes=image_dynamic_shapes,\n",
    ").capture_pre_autograd_graph().pt2e_quantize([linear_quantizer]).export_to_edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 2024-07-11 00:59:51,668 xnnpack_partitioner.py:558] Nothing can be partitioned!\n",
      "[INFO 2024-07-11 00:59:58,052 builder.py:276] Required memory for activation in bytes: [0, 313970944]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LlavaEdgeManager at 0x4ae96a6d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_encoder_ep.to_backend([XnnpackDynamicallyQuantizedPartitioner()]).to_executorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-07-11 01:01:15,823 utils.py:115] Saved exported program to llava_text_model.pte\n"
     ]
    }
   ],
   "source": [
    "image_encoder_ep.save_to_pte(\"llava_text_model.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[program.cpp:130] InternalConsistency verification requested but not available\n"
     ]
    }
   ],
   "source": [
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "\n",
    "mod = _load_for_executorch(\"llava_text_model.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39;49mforward((resized,))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = mod.forward((resized,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float):\n",
    "    freqs = 1.0 / (\n",
    "        theta ** (torch.arange(0, dim, 2, device=\"cpu\")[: (dim // 2)].float() / dim)\n",
    "    )\n",
    "    t = torch.arange(end, device=freqs.device, dtype=torch.int64).type_as(\n",
    "        freqs\n",
    "    )  # pyre-ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # pyre-ignore\n",
    "    emb = torch.cat((freqs, freqs), dim=-1)\n",
    "    freqs_cos = torch.cos(emb)\n",
    "    freqs_sin = torch.sin(emb)\n",
    "    return freqs_cos, freqs_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_cos, freqs_sin = precompute_freqs_cis(4096 // 32, 2048, 10000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 128])\n"
     ]
    }
   ],
   "source": [
    "print(freqs_cos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
