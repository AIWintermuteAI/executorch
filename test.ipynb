{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0.dev20240505\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.examples.models.llama2.source_transformation.quantize import dynamically_quantize_per_channel, WeightOnlyInt8Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_min = -128\n",
    "range_max = 127\n",
    "\n",
    "weight_float = torch.randn(4, 4)\n",
    "activation = torch.randn(4, 4)\n",
    "weight, scales, _ = dynamically_quantize_per_channel(\n",
    "    weight_float, range_min, range_max, torch.int8, None, scales_dtype=weight_float.dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = scales.squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  76,   14,  127,  -66],\n",
      "        [ 127,   65,   64,  -12],\n",
      "        [-128,   87,  -11,  -81],\n",
      "        [ -15,  -15, -128,  -46]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0102, 0.0142, 0.0177, 0.0196])\n"
     ]
    }
   ],
   "source": [
    "print(scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7735,  0.1411,  1.3022, -0.6775],\n",
      "        [ 1.8120,  0.9258,  0.9135, -0.1759],\n",
      "        [-2.2527,  1.5385, -0.1945, -1.4349],\n",
      "        [-0.2999, -0.2957, -2.5002, -0.9040]])\n"
     ]
    }
   ],
   "source": [
    "print(weight_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5251,  2.7241, -0.4740,  0.3813],\n",
      "        [-0.9735, -0.1196, -1.0898,  1.3676],\n",
      "        [ 0.6301,  0.2436,  0.8839, -0.4392],\n",
      "        [-1.7449, -0.7084, -0.4021, -1.0763]])\n"
     ]
    }
   ],
   "source": [
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = F.linear(activation, weight.to(dtype=activation.dtype)) * scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6662, -0.7324,  7.1829,  0.4931],\n",
      "        [-3.1083, -3.0920,  0.2722,  1.8234],\n",
      "        [ 1.9665,  2.2411, -0.5937, -2.0793],\n",
      "        [-1.2517, -3.9859,  4.4758,  2.7017]])\n"
     ]
    }
   ],
   "source": [
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch._C import DispatchKey\n",
    "torch.ops.aten._weight_int8pack_mm.default.has_kernel_for_dispatch_key(DispatchKey.MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6662, -0.7324,  7.1829,  0.4931],\n",
      "        [-3.1083, -3.0920,  0.2722,  1.8234],\n",
      "        [ 1.9665,  2.2411, -0.5937, -2.0793],\n",
      "        [-1.2517, -3.9859,  4.4758,  2.7017]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "res2 = torch.ops.aten._weight_int8pack_mm(activation.to(device='mps'), weight.to(device='mps'), scales=scales.to(device='mps'))\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6301,  0.2436,  0.8839, -0.4392])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8120,  0.9258,  0.9135, -0.1759])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_float[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5703)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(activation[2, :], weight_float[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1271, -1.0495, -1.1300,  0.1153],\n",
       "        [ 5.1776,  3.3572,  3.4860, -0.3586],\n",
       "        [ 0.8612,  2.5703, -2.0016,  0.2567],\n",
       "        [-1.1237,  0.8256, -3.4993, -0.1149]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(activation, weight_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from executorch.examples.models.llama2.builder import load_llama_model, DType\n",
    "from executorch.examples.models.llama2.source_transformation.quantize import WeightOnlyInt8QuantHandler\n",
    "from executorch.examples.models.llama2.source_transformation.sdpa import replace_sdpa_with_simple_sdpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 14:39:00,259 builder.py:84] Loading model with checkpoint=stories110M.pt, params=params.json, use_kv_cache=True, weight_type=WeightType.LLAMA\n",
      "[INFO 2024-05-08 14:39:00,340 builder.py:105] Loaded model with dtype=torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantize * ('layers.0.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('output', Linear(in_features=768, out_features=32000, bias=False)) with group_size None, bitwidth 8\n"
     ]
    }
   ],
   "source": [
    "# stories110M\n",
    "\n",
    "checkpoint = \"stories110M.pt\"\n",
    "params = \"params.json\"\n",
    "transforms = [\n",
    "    lambda m: WeightOnlyInt8QuantHandler(m).quantized_model(),\n",
    "    replace_sdpa_with_simple_sdpa,\n",
    "]\n",
    "\n",
    "model = load_llama_model(\n",
    "    checkpoint=checkpoint,\n",
    "    params_path=params,\n",
    "    use_kv_cache=True,\n",
    ").to_dtype(DType.fp32).source_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.backends.apple.mps.partition.mps_partitioner import (\n",
    "    MPSPartitioner,\n",
    ")\n",
    "from executorch.exir.backend.backend_details import CompileSpec\n",
    "compile_specs = [CompileSpec(\"use_fp16\", bytes([True]))]\n",
    "\n",
    "partitioners = [\n",
    "    MPSPartitioner(compile_specs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
      "# All rights reserved.\n",
      "#\n",
      "# This source code is licensed under the BSD-style license found in the\n",
      "# LICENSE file in the root directory of this source tree.\n",
      "\n",
      "import json\n",
      "import os\n",
      "import tempfile\n",
      "\n",
      "import pkg_resources\n",
      "from executorch.backends.apple.mps.serialization.mps_graph_schema import MPSGraph\n",
      "from executorch.exir._serialize._dataclass import _DataclassEncoder\n",
      "from executorch.exir._serialize._flatbuffer import _flatc_compile\n",
      "\n",
      "\n",
      "def convert_to_flatbuffer(mps_graph: MPSGraph) -> bytes:\n",
      "    mps_graph_json = json.dumps(mps_graph, cls=_DataclassEncoder)\n",
      "    with tempfile.TemporaryDirectory() as d:\n",
      "        schema_path = os.path.join(d, \"schema.fbs\")\n",
      "        with open(schema_path, \"wb\") as schema_file:\n",
      "            schema_file.write(pkg_resources.resource_string(__name__, \"schema.fbs\"))\n",
      "        json_path = os.path.join(d, \"schema.json\")\n",
      "        with open(json_path, \"wb\") as json_file:\n",
      "            json_file.write(mps_graph_json.encode(\"ascii\"))\n",
      "\n",
      "        _flatc_compile(d, schema_path, json_path)\n",
      "        output_path = os.path.join(d, \"schema.bin\")\n",
      "        with open(output_path, \"rb\") as output_file:\n",
      "            return output_file.read()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from executorch.backends.apple.mps.serialization import mps_graph_serialize\n",
    "import inspect\n",
    "print(inspect.getsource(mps_graph_serialize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 14:39:13,238 mps_partitioner.py:120] Found 13 subgraphs to be partitioned.\n",
      "[INFO 2024-05-08 14:39:13,241 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,241 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,242 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,243 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,244 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,244 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,245 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,246 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,247 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,247 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,249 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,249 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,250 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,250 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,252 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,252 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,254 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,254 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,256 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,256 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,258 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,258 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,259 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,260 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 14:39:13,392 mps_preprocess.py:115] Visiting: aten_view_copy_default_385, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,393 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_94, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:13,393 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_95, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:13,393 mps_preprocess.py:115] Visiting: aten__to_copy_default_88, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:13,393 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_92, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:13,394 mps_preprocess.py:115] Visiting: aten__to_copy_default_92, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:13,394 mps_preprocess.py:115] Visiting: aten__to_copy_default_93, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:13,394 mps_preprocess.py:115] Visiting: aten__to_copy_default_94, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:13,395 mps_preprocess.py:115] Visiting: aten__to_copy_default_95, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:13,395 mps_preprocess.py:115] Visiting: aten__to_copy_default_96, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:13,396 mps_preprocess.py:115] Visiting: aten_expand_copy_default_88, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:13,396 mps_preprocess.py:115] Visiting: aten_expand_copy_default_89, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:13,396 mps_preprocess.py:115] Visiting: aten_permute_copy_default_132, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,396 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_93, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:13,397 mps_preprocess.py:115] Visiting: aten_permute_copy_default_140, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,397 mps_preprocess.py:115] Visiting: aten_permute_copy_default_141, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,397 mps_preprocess.py:115] Visiting: aten_permute_copy_default_142, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,397 mps_preprocess.py:115] Visiting: aten_permute_copy_default_143, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,397 mps_preprocess.py:115] Visiting: aten_permute_copy_default_144, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,398 mps_preprocess.py:115] Visiting: aten_clone_default_22, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:13,398 mps_preprocess.py:115] Visiting: aten_clone_default_23, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:13,398 mps_preprocess.py:115] Visiting: aten_mm_default_66, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:13,398 mps_preprocess.py:115] Visiting: aten_index_tensor_13, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:13,398 mps_preprocess.py:115] Visiting: aten_expand_copy_default_95, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:13,399 mps_preprocess.py:115] Visiting: aten_view_copy_default_402, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,399 mps_preprocess.py:115] Visiting: aten_view_copy_default_403, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,399 mps_preprocess.py:115] Visiting: aten_view_copy_default_386, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,399 mps_preprocess.py:115] Visiting: aten__to_copy_default_91, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:13,400 mps_preprocess.py:115] Visiting: aten_view_copy_default_412, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,400 mps_preprocess.py:115] Visiting: aten_permute_copy_default_138, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,400 mps_preprocess.py:115] Visiting: aten_expand_copy_default_93, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:13,401 mps_preprocess.py:115] Visiting: aten_mul_tensor_267, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,401 mps_preprocess.py:115] Visiting: aten_expand_copy_default_91, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:13,401 mps_preprocess.py:115] Visiting: aten_view_copy_default_408, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,402 mps_preprocess.py:115] Visiting: aten_view_copy_default_391, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,402 mps_preprocess.py:115] Visiting: aten_view_copy_default_405, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,402 mps_preprocess.py:115] Visiting: aten_view_copy_default_394, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,402 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_44, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:13,403 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_45, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:13,403 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_44, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:13,403 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_45, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:13,403 mps_preprocess.py:115] Visiting: aten_mul_tensor_270, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,403 mps_preprocess.py:115] Visiting: aten_mul_tensor_272, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,404 mps_preprocess.py:115] Visiting: aten_mul_tensor_271, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,404 mps_preprocess.py:115] Visiting: aten_mul_tensor_273, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,404 mps_preprocess.py:115] Visiting: aten_sub_tensor_22, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:13,404 mps_preprocess.py:115] Visiting: aten_add_tensor_78, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:13,405 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_88, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:13,405 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_89, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:13,405 mps_preprocess.py:115] Visiting: aten_cat_default_22, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:13,406 mps_preprocess.py:115] Visiting: aten_view_copy_default_398, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,406 mps_preprocess.py:115] Visiting: aten_permute_copy_default_135, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,406 mps_preprocess.py:115] Visiting: aten_expand_copy_default_90, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:13,406 mps_preprocess.py:115] Visiting: aten_view_copy_default_404, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,407 mps_preprocess.py:115] Visiting: aten_bmm_default_33, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:13,407 mps_preprocess.py:115] Visiting: aten_view_copy_default_406, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,407 mps_preprocess.py:115] Visiting: aten_mul_tensor_278, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,408 mps_preprocess.py:115] Visiting: aten_add_tensor_80, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:13,408 mps_preprocess.py:115] Visiting: aten__softmax_default_11, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:13,408 mps_preprocess.py:115] Visiting: aten_expand_copy_default_92, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:13,409 mps_preprocess.py:115] Visiting: aten_view_copy_default_407, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,409 mps_preprocess.py:115] Visiting: aten_bmm_default_34, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:13,409 mps_preprocess.py:115] Visiting: aten_view_copy_default_409, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,409 mps_preprocess.py:115] Visiting: aten_permute_copy_default_139, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:13,410 mps_preprocess.py:115] Visiting: aten_view_copy_default_410, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,410 mps_preprocess.py:115] Visiting: aten_expand_copy_default_94, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:13,410 mps_preprocess.py:115] Visiting: aten_view_copy_default_411, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,410 mps_preprocess.py:115] Visiting: aten_bmm_default_35, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:13,411 mps_preprocess.py:115] Visiting: aten_view_copy_default_413, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,411 mps_preprocess.py:115] Visiting: aten_mul_tensor_279, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,411 mps_preprocess.py:115] Visiting: aten_add_tensor_81, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:13,412 mps_preprocess.py:115] Visiting: aten_mul_tensor_280, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,412 mps_preprocess.py:115] Visiting: aten_mean_dim_23, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:13,412 mps_preprocess.py:115] Visiting: aten_add_tensor_82, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:13,412 mps_preprocess.py:115] Visiting: aten_rsqrt_default_23, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:13,412 mps_preprocess.py:115] Visiting: aten_mul_tensor_281, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,413 mps_preprocess.py:115] Visiting: aten_mul_tensor_282, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,413 mps_preprocess.py:115] Visiting: aten_view_copy_default_414, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,413 mps_preprocess.py:115] Visiting: aten_view_copy_default_416, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,413 mps_preprocess.py:115] Visiting: aten_mm_default_69, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:13,413 mps_preprocess.py:115] Visiting: aten_mm_default_70, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:13,414 mps_preprocess.py:115] Visiting: aten_view_copy_default_415, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,414 mps_preprocess.py:115] Visiting: aten_view_copy_default_417, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,414 mps_preprocess.py:115] Visiting: aten_mul_tensor_283, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,414 mps_preprocess.py:115] Visiting: aten_mul_tensor_285, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,415 mps_preprocess.py:115] Visiting: aten_sigmoid_default_11, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:13,415 mps_preprocess.py:115] Visiting: aten_mul_tensor_284, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,415 mps_preprocess.py:115] Visiting: aten_mul_tensor_286, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,415 mps_preprocess.py:115] Visiting: aten_view_copy_default_418, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,415 mps_preprocess.py:115] Visiting: aten_mm_default_71, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:13,416 mps_preprocess.py:115] Visiting: aten_view_copy_default_419, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,416 mps_preprocess.py:115] Visiting: aten_mul_tensor_287, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,416 mps_preprocess.py:115] Visiting: aten_add_tensor_83, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:13,416 mps_preprocess.py:115] Visiting: aten_mul_tensor_288, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,417 mps_preprocess.py:115] Visiting: aten_mean_dim_24, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:13,417 mps_preprocess.py:115] Visiting: aten_add_tensor_84, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:13,417 mps_preprocess.py:115] Visiting: aten_rsqrt_default_24, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:13,418 mps_preprocess.py:115] Visiting: aten_mul_tensor_289, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,418 mps_preprocess.py:115] Visiting: aten_mul_tensor_290, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:13,418 mps_preprocess.py:115] Visiting: aten_view_copy_default_420, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,419 mps_preprocess.py:115] Visiting: aten_mm_default_72, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:13,419 mps_preprocess.py:115] Visiting: aten_view_copy_default_421, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:13,419 mps_preprocess.py:115] Visiting: aten_mul_tensor_291, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,570 mps_preprocess.py:115] Visiting: aten_view_copy_default_396, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,571 mps_preprocess.py:115] Visiting: aten_view_copy_default_397, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,571 mps_preprocess.py:115] Visiting: aten_view_copy_default_350, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,571 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_87, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:18,571 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_86, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:18,572 mps_preprocess.py:115] Visiting: aten__to_copy_default_80, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:18,572 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_84, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:18,572 mps_preprocess.py:115] Visiting: aten__to_copy_default_84, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:18,573 mps_preprocess.py:115] Visiting: aten__to_copy_default_85, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:18,573 mps_preprocess.py:115] Visiting: aten__to_copy_default_86, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:18,573 mps_preprocess.py:115] Visiting: aten__to_copy_default_87, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:18,573 mps_preprocess.py:115] Visiting: aten__to_copy_default_89, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:18,574 mps_preprocess.py:115] Visiting: aten__to_copy_default_90, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:18,574 mps_preprocess.py:115] Visiting: aten_expand_copy_default_81, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:18,574 mps_preprocess.py:115] Visiting: aten_expand_copy_default_80, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:18,574 mps_preprocess.py:115] Visiting: aten_permute_copy_default_120, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,574 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_85, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:18,575 mps_preprocess.py:115] Visiting: aten_permute_copy_default_128, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,575 mps_preprocess.py:115] Visiting: aten_permute_copy_default_129, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,575 mps_preprocess.py:115] Visiting: aten_permute_copy_default_130, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,575 mps_preprocess.py:115] Visiting: aten_permute_copy_default_131, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,575 mps_preprocess.py:115] Visiting: aten_permute_copy_default_133, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,576 mps_preprocess.py:115] Visiting: aten_permute_copy_default_134, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,576 mps_preprocess.py:115] Visiting: aten_clone_default_21, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:18,576 mps_preprocess.py:115] Visiting: aten_clone_default_20, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:18,576 mps_preprocess.py:115] Visiting: aten_mm_default_60, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:18,577 mps_preprocess.py:115] Visiting: aten_index_tensor_12, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:18,577 mps_preprocess.py:115] Visiting: aten_expand_copy_default_87, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:18,577 mps_preprocess.py:115] Visiting: aten_view_copy_default_368, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,577 mps_preprocess.py:115] Visiting: aten_view_copy_default_367, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,577 mps_preprocess.py:115] Visiting: aten_view_copy_default_351, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,578 mps_preprocess.py:115] Visiting: aten__to_copy_default_83, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:18,578 mps_preprocess.py:115] Visiting: aten_view_copy_default_377, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,578 mps_preprocess.py:115] Visiting: aten_expand_copy_default_85, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:18,578 mps_preprocess.py:115] Visiting: aten_permute_copy_default_126, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,578 mps_preprocess.py:115] Visiting: aten_mul_tensor_243, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,578 mps_preprocess.py:115] Visiting: aten_view_copy_default_373, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,579 mps_preprocess.py:115] Visiting: aten_expand_copy_default_83, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:18,579 mps_preprocess.py:115] Visiting: aten_view_copy_default_356, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,579 mps_preprocess.py:115] Visiting: aten_view_copy_default_370, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,579 mps_preprocess.py:115] Visiting: aten_view_copy_default_359, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,579 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_40, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:18,580 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_41, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:18,580 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_40, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:18,580 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_41, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:18,580 mps_preprocess.py:115] Visiting: aten_mul_tensor_246, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,580 mps_preprocess.py:115] Visiting: aten_mul_tensor_248, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,581 mps_preprocess.py:115] Visiting: aten_mul_tensor_247, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,581 mps_preprocess.py:115] Visiting: aten_mul_tensor_249, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,581 mps_preprocess.py:115] Visiting: aten_sub_tensor_20, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:18,581 mps_preprocess.py:115] Visiting: aten_add_tensor_71, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:18,581 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_80, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:18,582 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_81, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:18,582 mps_preprocess.py:115] Visiting: aten_cat_default_20, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:18,582 mps_preprocess.py:115] Visiting: aten_view_copy_default_363, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,582 mps_preprocess.py:115] Visiting: aten_permute_copy_default_123, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,583 mps_preprocess.py:115] Visiting: aten_expand_copy_default_82, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:18,583 mps_preprocess.py:115] Visiting: aten_view_copy_default_369, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,583 mps_preprocess.py:115] Visiting: aten_bmm_default_30, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:18,583 mps_preprocess.py:115] Visiting: aten_view_copy_default_371, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,584 mps_preprocess.py:115] Visiting: aten_mul_tensor_254, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,584 mps_preprocess.py:115] Visiting: aten_add_tensor_73, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:18,584 mps_preprocess.py:115] Visiting: aten__softmax_default_10, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:18,584 mps_preprocess.py:115] Visiting: aten_expand_copy_default_84, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:18,585 mps_preprocess.py:115] Visiting: aten_view_copy_default_372, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,585 mps_preprocess.py:115] Visiting: aten_bmm_default_31, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:18,585 mps_preprocess.py:115] Visiting: aten_view_copy_default_374, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,585 mps_preprocess.py:115] Visiting: aten_permute_copy_default_127, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,586 mps_preprocess.py:115] Visiting: aten_view_copy_default_375, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,586 mps_preprocess.py:115] Visiting: aten_expand_copy_default_86, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:18,586 mps_preprocess.py:115] Visiting: aten_view_copy_default_376, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,586 mps_preprocess.py:115] Visiting: aten_bmm_default_32, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:18,587 mps_preprocess.py:115] Visiting: aten_view_copy_default_378, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,587 mps_preprocess.py:115] Visiting: aten_mul_tensor_255, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,587 mps_preprocess.py:115] Visiting: aten_add_tensor_74, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:18,587 mps_preprocess.py:115] Visiting: aten_mul_tensor_256, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,588 mps_preprocess.py:115] Visiting: aten_mean_dim_21, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:18,588 mps_preprocess.py:115] Visiting: aten_add_tensor_75, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:18,588 mps_preprocess.py:115] Visiting: aten_rsqrt_default_21, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:18,589 mps_preprocess.py:115] Visiting: aten_mul_tensor_257, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,589 mps_preprocess.py:115] Visiting: aten_mul_tensor_258, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,589 mps_preprocess.py:115] Visiting: aten_view_copy_default_379, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,589 mps_preprocess.py:115] Visiting: aten_view_copy_default_381, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,590 mps_preprocess.py:115] Visiting: aten_mm_default_63, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:18,590 mps_preprocess.py:115] Visiting: aten_mm_default_64, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:18,590 mps_preprocess.py:115] Visiting: aten_view_copy_default_380, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,590 mps_preprocess.py:115] Visiting: aten_view_copy_default_382, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,590 mps_preprocess.py:115] Visiting: aten_mul_tensor_259, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,591 mps_preprocess.py:115] Visiting: aten_mul_tensor_261, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,591 mps_preprocess.py:115] Visiting: aten_sigmoid_default_10, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:18,591 mps_preprocess.py:115] Visiting: aten_mul_tensor_260, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,591 mps_preprocess.py:115] Visiting: aten_mul_tensor_262, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,591 mps_preprocess.py:115] Visiting: aten_view_copy_default_383, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,592 mps_preprocess.py:115] Visiting: aten_mm_default_65, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:18,592 mps_preprocess.py:115] Visiting: aten_view_copy_default_384, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,592 mps_preprocess.py:115] Visiting: aten_mul_tensor_263, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,593 mps_preprocess.py:115] Visiting: aten_add_tensor_76, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:18,593 mps_preprocess.py:115] Visiting: aten_mul_tensor_264, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,594 mps_preprocess.py:115] Visiting: aten_mean_dim_22, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:18,594 mps_preprocess.py:115] Visiting: aten_add_tensor_77, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:18,594 mps_preprocess.py:115] Visiting: aten_rsqrt_default_22, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:18,594 mps_preprocess.py:115] Visiting: aten_mul_tensor_265, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,595 mps_preprocess.py:115] Visiting: aten_mul_tensor_266, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,595 mps_preprocess.py:115] Visiting: aten_view_copy_default_387, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,595 mps_preprocess.py:115] Visiting: aten_view_copy_default_389, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,595 mps_preprocess.py:115] Visiting: aten_mm_default_67, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:18,596 mps_preprocess.py:115] Visiting: aten_mm_default_68, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:18,596 mps_preprocess.py:115] Visiting: aten_view_copy_default_388, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,596 mps_preprocess.py:115] Visiting: aten_view_copy_default_390, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,596 mps_preprocess.py:115] Visiting: aten_mul_tensor_268, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,597 mps_preprocess.py:115] Visiting: aten_mul_tensor_269, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,597 mps_preprocess.py:115] Visiting: aten_view_copy_default_392, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,597 mps_preprocess.py:115] Visiting: aten_view_copy_default_393, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,597 mps_preprocess.py:115] Visiting: aten_view_copy_default_395, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,597 mps_preprocess.py:115] Visiting: aten_permute_copy_default_137, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,598 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_46, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:18,598 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_47, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:18,598 mps_preprocess.py:115] Visiting: aten_view_copy_default_401, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,598 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_46, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:18,599 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_47, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:18,599 mps_preprocess.py:115] Visiting: aten_mul_tensor_274, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,599 mps_preprocess.py:115] Visiting: aten_mul_tensor_276, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,599 mps_preprocess.py:115] Visiting: aten_mul_tensor_275, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,600 mps_preprocess.py:115] Visiting: aten_mul_tensor_277, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:18,600 mps_preprocess.py:115] Visiting: aten_sub_tensor_23, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:18,600 mps_preprocess.py:115] Visiting: aten_add_tensor_79, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:18,600 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_90, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:18,601 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_91, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:18,601 mps_preprocess.py:115] Visiting: aten_cat_default_23, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:18,601 mps_preprocess.py:115] Visiting: aten_view_copy_default_399, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:18,602 mps_preprocess.py:115] Visiting: aten_permute_copy_default_136, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:18,602 mps_preprocess.py:115] Visiting: aten_view_copy_default_400, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,727 mps_preprocess.py:115] Visiting: aten_view_copy_default_361, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,728 mps_preprocess.py:115] Visiting: aten_view_copy_default_362, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,728 mps_preprocess.py:115] Visiting: aten_view_copy_default_315, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,729 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_79, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:19,729 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_78, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:19,729 mps_preprocess.py:115] Visiting: aten__to_copy_default_72, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:19,730 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_76, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:19,730 mps_preprocess.py:115] Visiting: aten__to_copy_default_76, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:19,730 mps_preprocess.py:115] Visiting: aten__to_copy_default_77, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:19,730 mps_preprocess.py:115] Visiting: aten__to_copy_default_78, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:19,730 mps_preprocess.py:115] Visiting: aten__to_copy_default_79, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:19,731 mps_preprocess.py:115] Visiting: aten__to_copy_default_81, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:19,731 mps_preprocess.py:115] Visiting: aten__to_copy_default_82, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:19,731 mps_preprocess.py:115] Visiting: aten_expand_copy_default_73, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:19,731 mps_preprocess.py:115] Visiting: aten_expand_copy_default_72, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:19,732 mps_preprocess.py:115] Visiting: aten_permute_copy_default_108, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,732 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_77, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:19,732 mps_preprocess.py:115] Visiting: aten_permute_copy_default_116, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,732 mps_preprocess.py:115] Visiting: aten_permute_copy_default_117, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,733 mps_preprocess.py:115] Visiting: aten_permute_copy_default_118, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,733 mps_preprocess.py:115] Visiting: aten_permute_copy_default_119, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,733 mps_preprocess.py:115] Visiting: aten_permute_copy_default_121, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,733 mps_preprocess.py:115] Visiting: aten_permute_copy_default_122, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,733 mps_preprocess.py:115] Visiting: aten_clone_default_19, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:19,734 mps_preprocess.py:115] Visiting: aten_clone_default_18, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:19,734 mps_preprocess.py:115] Visiting: aten_mm_default_54, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:19,734 mps_preprocess.py:115] Visiting: aten_index_tensor_11, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:19,735 mps_preprocess.py:115] Visiting: aten_expand_copy_default_79, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:19,735 mps_preprocess.py:115] Visiting: aten_view_copy_default_333, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,735 mps_preprocess.py:115] Visiting: aten_view_copy_default_332, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,735 mps_preprocess.py:115] Visiting: aten_view_copy_default_316, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,735 mps_preprocess.py:115] Visiting: aten__to_copy_default_75, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:19,736 mps_preprocess.py:115] Visiting: aten_view_copy_default_342, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,736 mps_preprocess.py:115] Visiting: aten_expand_copy_default_77, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:19,736 mps_preprocess.py:115] Visiting: aten_permute_copy_default_114, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,736 mps_preprocess.py:115] Visiting: aten_mul_tensor_219, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,736 mps_preprocess.py:115] Visiting: aten_view_copy_default_338, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,737 mps_preprocess.py:115] Visiting: aten_expand_copy_default_75, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:19,737 mps_preprocess.py:115] Visiting: aten_view_copy_default_321, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,737 mps_preprocess.py:115] Visiting: aten_view_copy_default_335, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,737 mps_preprocess.py:115] Visiting: aten_view_copy_default_324, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,737 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_36, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:19,738 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_37, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:19,738 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_36, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:19,738 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_37, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:19,738 mps_preprocess.py:115] Visiting: aten_mul_tensor_222, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,738 mps_preprocess.py:115] Visiting: aten_mul_tensor_224, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,739 mps_preprocess.py:115] Visiting: aten_mul_tensor_223, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,739 mps_preprocess.py:115] Visiting: aten_mul_tensor_225, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,739 mps_preprocess.py:115] Visiting: aten_sub_tensor_18, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:19,739 mps_preprocess.py:115] Visiting: aten_add_tensor_64, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:19,740 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_72, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:19,740 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_73, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:19,740 mps_preprocess.py:115] Visiting: aten_cat_default_18, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:19,740 mps_preprocess.py:115] Visiting: aten_view_copy_default_328, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,741 mps_preprocess.py:115] Visiting: aten_permute_copy_default_111, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,741 mps_preprocess.py:115] Visiting: aten_expand_copy_default_74, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:19,741 mps_preprocess.py:115] Visiting: aten_view_copy_default_334, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,741 mps_preprocess.py:115] Visiting: aten_bmm_default_27, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:19,741 mps_preprocess.py:115] Visiting: aten_view_copy_default_336, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,741 mps_preprocess.py:115] Visiting: aten_mul_tensor_230, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,742 mps_preprocess.py:115] Visiting: aten_add_tensor_66, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:19,742 mps_preprocess.py:115] Visiting: aten__softmax_default_9, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:19,742 mps_preprocess.py:115] Visiting: aten_expand_copy_default_76, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:19,742 mps_preprocess.py:115] Visiting: aten_view_copy_default_337, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,742 mps_preprocess.py:115] Visiting: aten_bmm_default_28, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:19,743 mps_preprocess.py:115] Visiting: aten_view_copy_default_339, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,743 mps_preprocess.py:115] Visiting: aten_permute_copy_default_115, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,743 mps_preprocess.py:115] Visiting: aten_view_copy_default_340, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,743 mps_preprocess.py:115] Visiting: aten_expand_copy_default_78, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:19,743 mps_preprocess.py:115] Visiting: aten_view_copy_default_341, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,744 mps_preprocess.py:115] Visiting: aten_bmm_default_29, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:19,744 mps_preprocess.py:115] Visiting: aten_view_copy_default_343, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,744 mps_preprocess.py:115] Visiting: aten_mul_tensor_231, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,744 mps_preprocess.py:115] Visiting: aten_add_tensor_67, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:19,744 mps_preprocess.py:115] Visiting: aten_mul_tensor_232, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,745 mps_preprocess.py:115] Visiting: aten_mean_dim_19, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:19,745 mps_preprocess.py:115] Visiting: aten_add_tensor_68, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:19,745 mps_preprocess.py:115] Visiting: aten_rsqrt_default_19, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:19,746 mps_preprocess.py:115] Visiting: aten_mul_tensor_233, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,746 mps_preprocess.py:115] Visiting: aten_mul_tensor_234, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,746 mps_preprocess.py:115] Visiting: aten_view_copy_default_344, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,747 mps_preprocess.py:115] Visiting: aten_view_copy_default_346, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,747 mps_preprocess.py:115] Visiting: aten_mm_default_57, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:19,747 mps_preprocess.py:115] Visiting: aten_mm_default_58, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:19,747 mps_preprocess.py:115] Visiting: aten_view_copy_default_345, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,747 mps_preprocess.py:115] Visiting: aten_view_copy_default_347, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,748 mps_preprocess.py:115] Visiting: aten_mul_tensor_235, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,748 mps_preprocess.py:115] Visiting: aten_mul_tensor_237, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,748 mps_preprocess.py:115] Visiting: aten_sigmoid_default_9, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:19,748 mps_preprocess.py:115] Visiting: aten_mul_tensor_236, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,748 mps_preprocess.py:115] Visiting: aten_mul_tensor_238, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,748 mps_preprocess.py:115] Visiting: aten_view_copy_default_348, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,749 mps_preprocess.py:115] Visiting: aten_mm_default_59, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:19,749 mps_preprocess.py:115] Visiting: aten_view_copy_default_349, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,749 mps_preprocess.py:115] Visiting: aten_mul_tensor_239, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,749 mps_preprocess.py:115] Visiting: aten_add_tensor_69, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:19,750 mps_preprocess.py:115] Visiting: aten_mul_tensor_240, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,750 mps_preprocess.py:115] Visiting: aten_mean_dim_20, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:19,750 mps_preprocess.py:115] Visiting: aten_add_tensor_70, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:19,750 mps_preprocess.py:115] Visiting: aten_rsqrt_default_20, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:19,751 mps_preprocess.py:115] Visiting: aten_mul_tensor_241, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,751 mps_preprocess.py:115] Visiting: aten_mul_tensor_242, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,751 mps_preprocess.py:115] Visiting: aten_view_copy_default_352, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,751 mps_preprocess.py:115] Visiting: aten_view_copy_default_354, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,751 mps_preprocess.py:115] Visiting: aten_mm_default_61, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:19,752 mps_preprocess.py:115] Visiting: aten_mm_default_62, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:19,752 mps_preprocess.py:115] Visiting: aten_view_copy_default_353, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,752 mps_preprocess.py:115] Visiting: aten_view_copy_default_355, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,752 mps_preprocess.py:115] Visiting: aten_mul_tensor_244, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,753 mps_preprocess.py:115] Visiting: aten_mul_tensor_245, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,753 mps_preprocess.py:115] Visiting: aten_view_copy_default_357, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,753 mps_preprocess.py:115] Visiting: aten_view_copy_default_358, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,754 mps_preprocess.py:115] Visiting: aten_view_copy_default_360, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,754 mps_preprocess.py:115] Visiting: aten_permute_copy_default_125, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,754 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_42, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:19,754 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_43, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:19,754 mps_preprocess.py:115] Visiting: aten_view_copy_default_366, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,755 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_42, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:19,755 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_43, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:19,755 mps_preprocess.py:115] Visiting: aten_mul_tensor_250, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,756 mps_preprocess.py:115] Visiting: aten_mul_tensor_252, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,756 mps_preprocess.py:115] Visiting: aten_mul_tensor_251, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,756 mps_preprocess.py:115] Visiting: aten_mul_tensor_253, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:19,756 mps_preprocess.py:115] Visiting: aten_sub_tensor_21, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:19,756 mps_preprocess.py:115] Visiting: aten_add_tensor_72, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:19,757 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_82, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:19,757 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_83, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:19,757 mps_preprocess.py:115] Visiting: aten_cat_default_21, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:19,757 mps_preprocess.py:115] Visiting: aten_view_copy_default_364, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:19,757 mps_preprocess.py:115] Visiting: aten_permute_copy_default_124, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:19,758 mps_preprocess.py:115] Visiting: aten_view_copy_default_365, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,888 mps_preprocess.py:115] Visiting: aten_view_copy_default_326, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,889 mps_preprocess.py:115] Visiting: aten_view_copy_default_327, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,889 mps_preprocess.py:115] Visiting: aten_view_copy_default_280, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,890 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_71, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:20,890 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_70, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:20,890 mps_preprocess.py:115] Visiting: aten__to_copy_default_64, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:20,890 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_68, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:20,891 mps_preprocess.py:115] Visiting: aten__to_copy_default_68, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:20,891 mps_preprocess.py:115] Visiting: aten__to_copy_default_69, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:20,891 mps_preprocess.py:115] Visiting: aten__to_copy_default_70, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:20,891 mps_preprocess.py:115] Visiting: aten__to_copy_default_71, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:20,891 mps_preprocess.py:115] Visiting: aten__to_copy_default_73, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:20,892 mps_preprocess.py:115] Visiting: aten__to_copy_default_74, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:20,892 mps_preprocess.py:115] Visiting: aten_expand_copy_default_65, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:20,892 mps_preprocess.py:115] Visiting: aten_expand_copy_default_64, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:20,892 mps_preprocess.py:115] Visiting: aten_permute_copy_default_96, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,893 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_69, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:20,893 mps_preprocess.py:115] Visiting: aten_permute_copy_default_104, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,893 mps_preprocess.py:115] Visiting: aten_permute_copy_default_105, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,893 mps_preprocess.py:115] Visiting: aten_permute_copy_default_106, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,894 mps_preprocess.py:115] Visiting: aten_permute_copy_default_107, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,894 mps_preprocess.py:115] Visiting: aten_permute_copy_default_109, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,894 mps_preprocess.py:115] Visiting: aten_permute_copy_default_110, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,894 mps_preprocess.py:115] Visiting: aten_clone_default_17, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:20,894 mps_preprocess.py:115] Visiting: aten_clone_default_16, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:20,895 mps_preprocess.py:115] Visiting: aten_mm_default_48, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:20,895 mps_preprocess.py:115] Visiting: aten_index_tensor_10, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:20,895 mps_preprocess.py:115] Visiting: aten_expand_copy_default_71, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:20,895 mps_preprocess.py:115] Visiting: aten_view_copy_default_298, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,896 mps_preprocess.py:115] Visiting: aten_view_copy_default_297, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,896 mps_preprocess.py:115] Visiting: aten_view_copy_default_281, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,896 mps_preprocess.py:115] Visiting: aten__to_copy_default_67, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:20,896 mps_preprocess.py:115] Visiting: aten_view_copy_default_307, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,896 mps_preprocess.py:115] Visiting: aten_expand_copy_default_69, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:20,896 mps_preprocess.py:115] Visiting: aten_permute_copy_default_102, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,897 mps_preprocess.py:115] Visiting: aten_mul_tensor_195, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,897 mps_preprocess.py:115] Visiting: aten_view_copy_default_303, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,897 mps_preprocess.py:115] Visiting: aten_expand_copy_default_67, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:20,897 mps_preprocess.py:115] Visiting: aten_view_copy_default_286, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,897 mps_preprocess.py:115] Visiting: aten_view_copy_default_300, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,898 mps_preprocess.py:115] Visiting: aten_view_copy_default_289, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,898 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_32, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:20,898 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_33, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:20,898 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_32, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:20,898 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_33, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:20,899 mps_preprocess.py:115] Visiting: aten_mul_tensor_198, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,899 mps_preprocess.py:115] Visiting: aten_mul_tensor_200, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,899 mps_preprocess.py:115] Visiting: aten_mul_tensor_199, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,899 mps_preprocess.py:115] Visiting: aten_mul_tensor_201, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,900 mps_preprocess.py:115] Visiting: aten_sub_tensor_16, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:20,900 mps_preprocess.py:115] Visiting: aten_add_tensor_57, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:20,900 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_64, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:20,900 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_65, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:20,901 mps_preprocess.py:115] Visiting: aten_cat_default_16, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:20,901 mps_preprocess.py:115] Visiting: aten_view_copy_default_293, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,901 mps_preprocess.py:115] Visiting: aten_permute_copy_default_99, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,901 mps_preprocess.py:115] Visiting: aten_expand_copy_default_66, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:20,902 mps_preprocess.py:115] Visiting: aten_view_copy_default_299, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,902 mps_preprocess.py:115] Visiting: aten_bmm_default_24, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:20,902 mps_preprocess.py:115] Visiting: aten_view_copy_default_301, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,902 mps_preprocess.py:115] Visiting: aten_mul_tensor_206, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,902 mps_preprocess.py:115] Visiting: aten_add_tensor_59, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:20,903 mps_preprocess.py:115] Visiting: aten__softmax_default_8, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:20,903 mps_preprocess.py:115] Visiting: aten_expand_copy_default_68, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:20,903 mps_preprocess.py:115] Visiting: aten_view_copy_default_302, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,903 mps_preprocess.py:115] Visiting: aten_bmm_default_25, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:20,904 mps_preprocess.py:115] Visiting: aten_view_copy_default_304, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,904 mps_preprocess.py:115] Visiting: aten_permute_copy_default_103, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,904 mps_preprocess.py:115] Visiting: aten_view_copy_default_305, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,904 mps_preprocess.py:115] Visiting: aten_expand_copy_default_70, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:20,904 mps_preprocess.py:115] Visiting: aten_view_copy_default_306, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,905 mps_preprocess.py:115] Visiting: aten_bmm_default_26, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:20,905 mps_preprocess.py:115] Visiting: aten_view_copy_default_308, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,905 mps_preprocess.py:115] Visiting: aten_mul_tensor_207, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,905 mps_preprocess.py:115] Visiting: aten_add_tensor_60, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:20,906 mps_preprocess.py:115] Visiting: aten_mul_tensor_208, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,906 mps_preprocess.py:115] Visiting: aten_mean_dim_17, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:20,906 mps_preprocess.py:115] Visiting: aten_add_tensor_61, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:20,906 mps_preprocess.py:115] Visiting: aten_rsqrt_default_17, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:20,907 mps_preprocess.py:115] Visiting: aten_mul_tensor_209, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,907 mps_preprocess.py:115] Visiting: aten_mul_tensor_210, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,907 mps_preprocess.py:115] Visiting: aten_view_copy_default_309, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,907 mps_preprocess.py:115] Visiting: aten_view_copy_default_311, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,908 mps_preprocess.py:115] Visiting: aten_mm_default_51, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:20,908 mps_preprocess.py:115] Visiting: aten_mm_default_52, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:20,908 mps_preprocess.py:115] Visiting: aten_view_copy_default_310, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,908 mps_preprocess.py:115] Visiting: aten_view_copy_default_312, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,909 mps_preprocess.py:115] Visiting: aten_mul_tensor_211, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,909 mps_preprocess.py:115] Visiting: aten_mul_tensor_213, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,909 mps_preprocess.py:115] Visiting: aten_sigmoid_default_8, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:20,909 mps_preprocess.py:115] Visiting: aten_mul_tensor_212, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,909 mps_preprocess.py:115] Visiting: aten_mul_tensor_214, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,910 mps_preprocess.py:115] Visiting: aten_view_copy_default_313, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,910 mps_preprocess.py:115] Visiting: aten_mm_default_53, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:20,910 mps_preprocess.py:115] Visiting: aten_view_copy_default_314, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,911 mps_preprocess.py:115] Visiting: aten_mul_tensor_215, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,911 mps_preprocess.py:115] Visiting: aten_add_tensor_62, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:20,911 mps_preprocess.py:115] Visiting: aten_mul_tensor_216, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,911 mps_preprocess.py:115] Visiting: aten_mean_dim_18, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:20,911 mps_preprocess.py:115] Visiting: aten_add_tensor_63, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:20,912 mps_preprocess.py:115] Visiting: aten_rsqrt_default_18, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:20,912 mps_preprocess.py:115] Visiting: aten_mul_tensor_217, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,912 mps_preprocess.py:115] Visiting: aten_mul_tensor_218, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,912 mps_preprocess.py:115] Visiting: aten_view_copy_default_317, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,913 mps_preprocess.py:115] Visiting: aten_view_copy_default_319, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,913 mps_preprocess.py:115] Visiting: aten_mm_default_55, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:20,913 mps_preprocess.py:115] Visiting: aten_mm_default_56, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:20,913 mps_preprocess.py:115] Visiting: aten_view_copy_default_318, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,914 mps_preprocess.py:115] Visiting: aten_view_copy_default_320, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,914 mps_preprocess.py:115] Visiting: aten_mul_tensor_220, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,914 mps_preprocess.py:115] Visiting: aten_mul_tensor_221, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,914 mps_preprocess.py:115] Visiting: aten_view_copy_default_322, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,914 mps_preprocess.py:115] Visiting: aten_view_copy_default_323, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,915 mps_preprocess.py:115] Visiting: aten_view_copy_default_325, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,915 mps_preprocess.py:115] Visiting: aten_permute_copy_default_113, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,915 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_38, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:20,915 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_39, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:20,916 mps_preprocess.py:115] Visiting: aten_view_copy_default_331, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,916 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_38, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:20,916 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_39, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:20,917 mps_preprocess.py:115] Visiting: aten_mul_tensor_226, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,917 mps_preprocess.py:115] Visiting: aten_mul_tensor_228, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,917 mps_preprocess.py:115] Visiting: aten_mul_tensor_227, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,917 mps_preprocess.py:115] Visiting: aten_mul_tensor_229, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:20,918 mps_preprocess.py:115] Visiting: aten_sub_tensor_19, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:20,918 mps_preprocess.py:115] Visiting: aten_add_tensor_65, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:20,918 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_74, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:20,918 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_75, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:20,918 mps_preprocess.py:115] Visiting: aten_cat_default_19, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:20,919 mps_preprocess.py:115] Visiting: aten_view_copy_default_329, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:20,919 mps_preprocess.py:115] Visiting: aten_permute_copy_default_112, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:20,919 mps_preprocess.py:115] Visiting: aten_view_copy_default_330, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:21,995 mps_preprocess.py:115] Visiting: aten_view_copy_default_291, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:21,996 mps_preprocess.py:115] Visiting: aten_view_copy_default_292, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:21,996 mps_preprocess.py:115] Visiting: aten_view_copy_default_245, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:21,996 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_63, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:21,997 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_62, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:21,997 mps_preprocess.py:115] Visiting: aten__to_copy_default_56, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:21,997 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_60, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:21,997 mps_preprocess.py:115] Visiting: aten__to_copy_default_60, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:21,998 mps_preprocess.py:115] Visiting: aten__to_copy_default_61, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:21,998 mps_preprocess.py:115] Visiting: aten__to_copy_default_62, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:21,998 mps_preprocess.py:115] Visiting: aten__to_copy_default_63, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:21,998 mps_preprocess.py:115] Visiting: aten__to_copy_default_65, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:21,999 mps_preprocess.py:115] Visiting: aten__to_copy_default_66, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:21,999 mps_preprocess.py:115] Visiting: aten_expand_copy_default_57, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:21,999 mps_preprocess.py:115] Visiting: aten_expand_copy_default_56, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:21,999 mps_preprocess.py:115] Visiting: aten_permute_copy_default_84, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:21,999 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_61, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:22,000 mps_preprocess.py:115] Visiting: aten_permute_copy_default_92, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,000 mps_preprocess.py:115] Visiting: aten_permute_copy_default_93, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,000 mps_preprocess.py:115] Visiting: aten_permute_copy_default_94, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,001 mps_preprocess.py:115] Visiting: aten_permute_copy_default_95, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,001 mps_preprocess.py:115] Visiting: aten_permute_copy_default_97, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,001 mps_preprocess.py:115] Visiting: aten_permute_copy_default_98, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,001 mps_preprocess.py:115] Visiting: aten_clone_default_15, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:22,002 mps_preprocess.py:115] Visiting: aten_clone_default_14, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:22,002 mps_preprocess.py:115] Visiting: aten_mm_default_42, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:22,002 mps_preprocess.py:115] Visiting: aten_index_tensor_9, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:22,003 mps_preprocess.py:115] Visiting: aten_expand_copy_default_63, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:22,003 mps_preprocess.py:115] Visiting: aten_view_copy_default_263, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,003 mps_preprocess.py:115] Visiting: aten_view_copy_default_262, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,003 mps_preprocess.py:115] Visiting: aten_view_copy_default_246, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,003 mps_preprocess.py:115] Visiting: aten__to_copy_default_59, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:22,004 mps_preprocess.py:115] Visiting: aten_view_copy_default_272, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,004 mps_preprocess.py:115] Visiting: aten_expand_copy_default_61, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:22,004 mps_preprocess.py:115] Visiting: aten_permute_copy_default_90, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,004 mps_preprocess.py:115] Visiting: aten_mul_tensor_171, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,005 mps_preprocess.py:115] Visiting: aten_view_copy_default_268, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,005 mps_preprocess.py:115] Visiting: aten_expand_copy_default_59, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:22,005 mps_preprocess.py:115] Visiting: aten_view_copy_default_251, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,005 mps_preprocess.py:115] Visiting: aten_view_copy_default_265, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,005 mps_preprocess.py:115] Visiting: aten_view_copy_default_254, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,006 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_28, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:22,006 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_29, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:22,006 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_28, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:22,006 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_29, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:22,007 mps_preprocess.py:115] Visiting: aten_mul_tensor_174, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,007 mps_preprocess.py:115] Visiting: aten_mul_tensor_176, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,007 mps_preprocess.py:115] Visiting: aten_mul_tensor_175, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,007 mps_preprocess.py:115] Visiting: aten_mul_tensor_177, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,008 mps_preprocess.py:115] Visiting: aten_sub_tensor_14, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:22,008 mps_preprocess.py:115] Visiting: aten_add_tensor_50, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:22,008 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_56, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:22,008 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_57, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:22,009 mps_preprocess.py:115] Visiting: aten_cat_default_14, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:22,009 mps_preprocess.py:115] Visiting: aten_view_copy_default_258, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,009 mps_preprocess.py:115] Visiting: aten_permute_copy_default_87, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,009 mps_preprocess.py:115] Visiting: aten_expand_copy_default_58, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:22,009 mps_preprocess.py:115] Visiting: aten_view_copy_default_264, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,010 mps_preprocess.py:115] Visiting: aten_bmm_default_21, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:22,010 mps_preprocess.py:115] Visiting: aten_view_copy_default_266, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,010 mps_preprocess.py:115] Visiting: aten_mul_tensor_182, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,010 mps_preprocess.py:115] Visiting: aten_add_tensor_52, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:22,010 mps_preprocess.py:115] Visiting: aten__softmax_default_7, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:22,011 mps_preprocess.py:115] Visiting: aten_expand_copy_default_60, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:22,011 mps_preprocess.py:115] Visiting: aten_view_copy_default_267, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,011 mps_preprocess.py:115] Visiting: aten_bmm_default_22, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:22,011 mps_preprocess.py:115] Visiting: aten_view_copy_default_269, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,011 mps_preprocess.py:115] Visiting: aten_permute_copy_default_91, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,012 mps_preprocess.py:115] Visiting: aten_view_copy_default_270, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,012 mps_preprocess.py:115] Visiting: aten_expand_copy_default_62, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:22,012 mps_preprocess.py:115] Visiting: aten_view_copy_default_271, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,012 mps_preprocess.py:115] Visiting: aten_bmm_default_23, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:22,013 mps_preprocess.py:115] Visiting: aten_view_copy_default_273, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,013 mps_preprocess.py:115] Visiting: aten_mul_tensor_183, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,013 mps_preprocess.py:115] Visiting: aten_add_tensor_53, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:22,013 mps_preprocess.py:115] Visiting: aten_mul_tensor_184, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,013 mps_preprocess.py:115] Visiting: aten_mean_dim_15, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:22,014 mps_preprocess.py:115] Visiting: aten_add_tensor_54, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:22,014 mps_preprocess.py:115] Visiting: aten_rsqrt_default_15, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:22,014 mps_preprocess.py:115] Visiting: aten_mul_tensor_185, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,015 mps_preprocess.py:115] Visiting: aten_mul_tensor_186, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,017 mps_preprocess.py:115] Visiting: aten_view_copy_default_274, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,021 mps_preprocess.py:115] Visiting: aten_view_copy_default_276, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,024 mps_preprocess.py:115] Visiting: aten_mm_default_45, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:22,026 mps_preprocess.py:115] Visiting: aten_mm_default_46, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:22,027 mps_preprocess.py:115] Visiting: aten_view_copy_default_275, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,028 mps_preprocess.py:115] Visiting: aten_view_copy_default_277, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,029 mps_preprocess.py:115] Visiting: aten_mul_tensor_187, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,029 mps_preprocess.py:115] Visiting: aten_mul_tensor_189, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,031 mps_preprocess.py:115] Visiting: aten_sigmoid_default_7, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:22,031 mps_preprocess.py:115] Visiting: aten_mul_tensor_188, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,031 mps_preprocess.py:115] Visiting: aten_mul_tensor_190, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,032 mps_preprocess.py:115] Visiting: aten_view_copy_default_278, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,032 mps_preprocess.py:115] Visiting: aten_mm_default_47, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:22,032 mps_preprocess.py:115] Visiting: aten_view_copy_default_279, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,033 mps_preprocess.py:115] Visiting: aten_mul_tensor_191, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,034 mps_preprocess.py:115] Visiting: aten_add_tensor_55, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:22,035 mps_preprocess.py:115] Visiting: aten_mul_tensor_192, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,036 mps_preprocess.py:115] Visiting: aten_mean_dim_16, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:22,037 mps_preprocess.py:115] Visiting: aten_add_tensor_56, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:22,038 mps_preprocess.py:115] Visiting: aten_rsqrt_default_16, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:22,038 mps_preprocess.py:115] Visiting: aten_mul_tensor_193, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,040 mps_preprocess.py:115] Visiting: aten_mul_tensor_194, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,040 mps_preprocess.py:115] Visiting: aten_view_copy_default_282, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,041 mps_preprocess.py:115] Visiting: aten_view_copy_default_284, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,049 mps_preprocess.py:115] Visiting: aten_mm_default_49, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:22,053 mps_preprocess.py:115] Visiting: aten_mm_default_50, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:22,056 mps_preprocess.py:115] Visiting: aten_view_copy_default_283, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,059 mps_preprocess.py:115] Visiting: aten_view_copy_default_285, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,059 mps_preprocess.py:115] Visiting: aten_mul_tensor_196, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,059 mps_preprocess.py:115] Visiting: aten_mul_tensor_197, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,060 mps_preprocess.py:115] Visiting: aten_view_copy_default_287, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,060 mps_preprocess.py:115] Visiting: aten_view_copy_default_288, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,061 mps_preprocess.py:115] Visiting: aten_view_copy_default_290, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,061 mps_preprocess.py:115] Visiting: aten_permute_copy_default_101, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,061 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_34, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:22,061 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_35, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:22,061 mps_preprocess.py:115] Visiting: aten_view_copy_default_296, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,062 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_34, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:22,062 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_35, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:22,062 mps_preprocess.py:115] Visiting: aten_mul_tensor_202, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,063 mps_preprocess.py:115] Visiting: aten_mul_tensor_204, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,063 mps_preprocess.py:115] Visiting: aten_mul_tensor_203, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,064 mps_preprocess.py:115] Visiting: aten_mul_tensor_205, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:22,064 mps_preprocess.py:115] Visiting: aten_sub_tensor_17, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:22,065 mps_preprocess.py:115] Visiting: aten_add_tensor_58, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:22,065 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_66, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:22,065 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_67, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:22,066 mps_preprocess.py:115] Visiting: aten_cat_default_17, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:22,066 mps_preprocess.py:115] Visiting: aten_view_copy_default_294, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:22,067 mps_preprocess.py:115] Visiting: aten_permute_copy_default_100, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:22,067 mps_preprocess.py:115] Visiting: aten_view_copy_default_295, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,126 mps_preprocess.py:115] Visiting: aten_view_copy_default_256, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,127 mps_preprocess.py:115] Visiting: aten_view_copy_default_257, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,127 mps_preprocess.py:115] Visiting: aten_view_copy_default_210, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,127 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_55, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:23,128 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_54, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:23,128 mps_preprocess.py:115] Visiting: aten__to_copy_default_48, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:23,128 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_52, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:23,128 mps_preprocess.py:115] Visiting: aten__to_copy_default_52, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:23,129 mps_preprocess.py:115] Visiting: aten__to_copy_default_53, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:23,129 mps_preprocess.py:115] Visiting: aten__to_copy_default_54, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:23,129 mps_preprocess.py:115] Visiting: aten__to_copy_default_55, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:23,129 mps_preprocess.py:115] Visiting: aten__to_copy_default_57, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:23,130 mps_preprocess.py:115] Visiting: aten__to_copy_default_58, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:23,130 mps_preprocess.py:115] Visiting: aten_expand_copy_default_49, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:23,130 mps_preprocess.py:115] Visiting: aten_expand_copy_default_48, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:23,130 mps_preprocess.py:115] Visiting: aten_permute_copy_default_72, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,130 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_53, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:23,131 mps_preprocess.py:115] Visiting: aten_permute_copy_default_80, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,131 mps_preprocess.py:115] Visiting: aten_permute_copy_default_81, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,131 mps_preprocess.py:115] Visiting: aten_permute_copy_default_82, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,131 mps_preprocess.py:115] Visiting: aten_permute_copy_default_83, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,131 mps_preprocess.py:115] Visiting: aten_permute_copy_default_85, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,131 mps_preprocess.py:115] Visiting: aten_permute_copy_default_86, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,132 mps_preprocess.py:115] Visiting: aten_clone_default_13, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:23,132 mps_preprocess.py:115] Visiting: aten_clone_default_12, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:23,132 mps_preprocess.py:115] Visiting: aten_mm_default_36, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:23,132 mps_preprocess.py:115] Visiting: aten_index_tensor_8, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:23,133 mps_preprocess.py:115] Visiting: aten_expand_copy_default_55, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:23,133 mps_preprocess.py:115] Visiting: aten_view_copy_default_228, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,133 mps_preprocess.py:115] Visiting: aten_view_copy_default_227, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,134 mps_preprocess.py:115] Visiting: aten_view_copy_default_211, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,134 mps_preprocess.py:115] Visiting: aten__to_copy_default_51, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:23,134 mps_preprocess.py:115] Visiting: aten_view_copy_default_237, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,134 mps_preprocess.py:115] Visiting: aten_expand_copy_default_53, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:23,135 mps_preprocess.py:115] Visiting: aten_permute_copy_default_78, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,135 mps_preprocess.py:115] Visiting: aten_mul_tensor_147, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,135 mps_preprocess.py:115] Visiting: aten_view_copy_default_233, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,135 mps_preprocess.py:115] Visiting: aten_expand_copy_default_51, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:23,135 mps_preprocess.py:115] Visiting: aten_view_copy_default_216, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,135 mps_preprocess.py:115] Visiting: aten_view_copy_default_230, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,136 mps_preprocess.py:115] Visiting: aten_view_copy_default_219, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,136 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_24, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:23,136 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_25, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:23,137 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_24, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:23,137 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_25, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:23,137 mps_preprocess.py:115] Visiting: aten_mul_tensor_150, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,137 mps_preprocess.py:115] Visiting: aten_mul_tensor_152, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,137 mps_preprocess.py:115] Visiting: aten_mul_tensor_151, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,137 mps_preprocess.py:115] Visiting: aten_mul_tensor_153, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,138 mps_preprocess.py:115] Visiting: aten_sub_tensor_12, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:23,138 mps_preprocess.py:115] Visiting: aten_add_tensor_43, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:23,138 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_48, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:23,138 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_49, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:23,138 mps_preprocess.py:115] Visiting: aten_cat_default_12, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:23,139 mps_preprocess.py:115] Visiting: aten_view_copy_default_223, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,139 mps_preprocess.py:115] Visiting: aten_permute_copy_default_75, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,139 mps_preprocess.py:115] Visiting: aten_expand_copy_default_50, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:23,139 mps_preprocess.py:115] Visiting: aten_view_copy_default_229, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,140 mps_preprocess.py:115] Visiting: aten_bmm_default_18, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:23,140 mps_preprocess.py:115] Visiting: aten_view_copy_default_231, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,140 mps_preprocess.py:115] Visiting: aten_mul_tensor_158, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,140 mps_preprocess.py:115] Visiting: aten_add_tensor_45, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:23,140 mps_preprocess.py:115] Visiting: aten__softmax_default_6, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:23,141 mps_preprocess.py:115] Visiting: aten_expand_copy_default_52, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:23,141 mps_preprocess.py:115] Visiting: aten_view_copy_default_232, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,141 mps_preprocess.py:115] Visiting: aten_bmm_default_19, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:23,141 mps_preprocess.py:115] Visiting: aten_view_copy_default_234, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,142 mps_preprocess.py:115] Visiting: aten_permute_copy_default_79, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,142 mps_preprocess.py:115] Visiting: aten_view_copy_default_235, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,142 mps_preprocess.py:115] Visiting: aten_expand_copy_default_54, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:23,142 mps_preprocess.py:115] Visiting: aten_view_copy_default_236, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,143 mps_preprocess.py:115] Visiting: aten_bmm_default_20, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:23,143 mps_preprocess.py:115] Visiting: aten_view_copy_default_238, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,143 mps_preprocess.py:115] Visiting: aten_mul_tensor_159, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,143 mps_preprocess.py:115] Visiting: aten_add_tensor_46, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:23,143 mps_preprocess.py:115] Visiting: aten_mul_tensor_160, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,144 mps_preprocess.py:115] Visiting: aten_mean_dim_13, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:23,144 mps_preprocess.py:115] Visiting: aten_add_tensor_47, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:23,144 mps_preprocess.py:115] Visiting: aten_rsqrt_default_13, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:23,144 mps_preprocess.py:115] Visiting: aten_mul_tensor_161, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,144 mps_preprocess.py:115] Visiting: aten_mul_tensor_162, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,145 mps_preprocess.py:115] Visiting: aten_view_copy_default_239, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,145 mps_preprocess.py:115] Visiting: aten_view_copy_default_241, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,146 mps_preprocess.py:115] Visiting: aten_mm_default_39, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:23,146 mps_preprocess.py:115] Visiting: aten_mm_default_40, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:23,146 mps_preprocess.py:115] Visiting: aten_view_copy_default_240, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,147 mps_preprocess.py:115] Visiting: aten_view_copy_default_242, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,147 mps_preprocess.py:115] Visiting: aten_mul_tensor_163, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,147 mps_preprocess.py:115] Visiting: aten_mul_tensor_165, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,147 mps_preprocess.py:115] Visiting: aten_sigmoid_default_6, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:23,148 mps_preprocess.py:115] Visiting: aten_mul_tensor_164, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,148 mps_preprocess.py:115] Visiting: aten_mul_tensor_166, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,148 mps_preprocess.py:115] Visiting: aten_view_copy_default_243, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,149 mps_preprocess.py:115] Visiting: aten_mm_default_41, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:23,149 mps_preprocess.py:115] Visiting: aten_view_copy_default_244, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,149 mps_preprocess.py:115] Visiting: aten_mul_tensor_167, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,149 mps_preprocess.py:115] Visiting: aten_add_tensor_48, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:23,150 mps_preprocess.py:115] Visiting: aten_mul_tensor_168, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,150 mps_preprocess.py:115] Visiting: aten_mean_dim_14, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:23,150 mps_preprocess.py:115] Visiting: aten_add_tensor_49, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:23,150 mps_preprocess.py:115] Visiting: aten_rsqrt_default_14, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:23,151 mps_preprocess.py:115] Visiting: aten_mul_tensor_169, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,151 mps_preprocess.py:115] Visiting: aten_mul_tensor_170, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,151 mps_preprocess.py:115] Visiting: aten_view_copy_default_247, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,151 mps_preprocess.py:115] Visiting: aten_view_copy_default_249, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,152 mps_preprocess.py:115] Visiting: aten_mm_default_43, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:23,152 mps_preprocess.py:115] Visiting: aten_mm_default_44, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:23,152 mps_preprocess.py:115] Visiting: aten_view_copy_default_248, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,152 mps_preprocess.py:115] Visiting: aten_view_copy_default_250, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,153 mps_preprocess.py:115] Visiting: aten_mul_tensor_172, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,153 mps_preprocess.py:115] Visiting: aten_mul_tensor_173, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,153 mps_preprocess.py:115] Visiting: aten_view_copy_default_252, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,154 mps_preprocess.py:115] Visiting: aten_view_copy_default_253, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,154 mps_preprocess.py:115] Visiting: aten_view_copy_default_255, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,156 mps_preprocess.py:115] Visiting: aten_permute_copy_default_89, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,157 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_30, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:23,158 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_31, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:23,159 mps_preprocess.py:115] Visiting: aten_view_copy_default_261, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,161 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_30, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:23,162 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_31, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:23,162 mps_preprocess.py:115] Visiting: aten_mul_tensor_178, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,162 mps_preprocess.py:115] Visiting: aten_mul_tensor_180, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,163 mps_preprocess.py:115] Visiting: aten_mul_tensor_179, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,163 mps_preprocess.py:115] Visiting: aten_mul_tensor_181, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:23,163 mps_preprocess.py:115] Visiting: aten_sub_tensor_15, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:23,164 mps_preprocess.py:115] Visiting: aten_add_tensor_51, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:23,164 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_58, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:23,164 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_59, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:23,165 mps_preprocess.py:115] Visiting: aten_cat_default_15, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:23,165 mps_preprocess.py:115] Visiting: aten_view_copy_default_259, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:23,165 mps_preprocess.py:115] Visiting: aten_permute_copy_default_88, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:23,165 mps_preprocess.py:115] Visiting: aten_view_copy_default_260, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,231 mps_preprocess.py:115] Visiting: aten_view_copy_default_221, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,231 mps_preprocess.py:115] Visiting: aten_view_copy_default_222, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,232 mps_preprocess.py:115] Visiting: aten_view_copy_default_175, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,232 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_47, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:24,233 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_46, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:24,233 mps_preprocess.py:115] Visiting: aten__to_copy_default_40, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:24,233 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_44, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:24,233 mps_preprocess.py:115] Visiting: aten__to_copy_default_44, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:24,234 mps_preprocess.py:115] Visiting: aten__to_copy_default_45, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:24,234 mps_preprocess.py:115] Visiting: aten__to_copy_default_46, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:24,234 mps_preprocess.py:115] Visiting: aten__to_copy_default_47, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:24,234 mps_preprocess.py:115] Visiting: aten__to_copy_default_49, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:24,235 mps_preprocess.py:115] Visiting: aten__to_copy_default_50, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:24,235 mps_preprocess.py:115] Visiting: aten_expand_copy_default_41, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:24,235 mps_preprocess.py:115] Visiting: aten_expand_copy_default_40, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:24,235 mps_preprocess.py:115] Visiting: aten_permute_copy_default_60, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,236 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_45, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:24,236 mps_preprocess.py:115] Visiting: aten_permute_copy_default_68, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,236 mps_preprocess.py:115] Visiting: aten_permute_copy_default_69, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,236 mps_preprocess.py:115] Visiting: aten_permute_copy_default_70, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,236 mps_preprocess.py:115] Visiting: aten_permute_copy_default_71, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,237 mps_preprocess.py:115] Visiting: aten_permute_copy_default_73, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,237 mps_preprocess.py:115] Visiting: aten_permute_copy_default_74, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,237 mps_preprocess.py:115] Visiting: aten_clone_default_11, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:24,237 mps_preprocess.py:115] Visiting: aten_clone_default_10, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:24,238 mps_preprocess.py:115] Visiting: aten_mm_default_30, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:24,238 mps_preprocess.py:115] Visiting: aten_index_tensor_7, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:24,238 mps_preprocess.py:115] Visiting: aten_expand_copy_default_47, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:24,238 mps_preprocess.py:115] Visiting: aten_view_copy_default_193, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,238 mps_preprocess.py:115] Visiting: aten_view_copy_default_192, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,239 mps_preprocess.py:115] Visiting: aten_view_copy_default_176, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,239 mps_preprocess.py:115] Visiting: aten__to_copy_default_43, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:24,239 mps_preprocess.py:115] Visiting: aten_view_copy_default_202, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,239 mps_preprocess.py:115] Visiting: aten_expand_copy_default_45, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:24,239 mps_preprocess.py:115] Visiting: aten_permute_copy_default_66, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,240 mps_preprocess.py:115] Visiting: aten_mul_tensor_123, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,240 mps_preprocess.py:115] Visiting: aten_view_copy_default_198, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,240 mps_preprocess.py:115] Visiting: aten_expand_copy_default_43, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:24,240 mps_preprocess.py:115] Visiting: aten_view_copy_default_181, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,240 mps_preprocess.py:115] Visiting: aten_view_copy_default_195, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,241 mps_preprocess.py:115] Visiting: aten_view_copy_default_184, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,241 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_20, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:24,241 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_21, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:24,241 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_20, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:24,241 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_21, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:24,241 mps_preprocess.py:115] Visiting: aten_mul_tensor_126, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,242 mps_preprocess.py:115] Visiting: aten_mul_tensor_128, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,242 mps_preprocess.py:115] Visiting: aten_mul_tensor_127, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,242 mps_preprocess.py:115] Visiting: aten_mul_tensor_129, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,242 mps_preprocess.py:115] Visiting: aten_sub_tensor_10, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:24,242 mps_preprocess.py:115] Visiting: aten_add_tensor_36, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:24,243 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_40, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:24,243 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_41, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:24,243 mps_preprocess.py:115] Visiting: aten_cat_default_10, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:24,244 mps_preprocess.py:115] Visiting: aten_view_copy_default_188, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,244 mps_preprocess.py:115] Visiting: aten_permute_copy_default_63, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,244 mps_preprocess.py:115] Visiting: aten_expand_copy_default_42, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:24,244 mps_preprocess.py:115] Visiting: aten_view_copy_default_194, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,244 mps_preprocess.py:115] Visiting: aten_bmm_default_15, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:24,244 mps_preprocess.py:115] Visiting: aten_view_copy_default_196, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,245 mps_preprocess.py:115] Visiting: aten_mul_tensor_134, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,245 mps_preprocess.py:115] Visiting: aten_add_tensor_38, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:24,245 mps_preprocess.py:115] Visiting: aten__softmax_default_5, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:24,245 mps_preprocess.py:115] Visiting: aten_expand_copy_default_44, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:24,245 mps_preprocess.py:115] Visiting: aten_view_copy_default_197, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,246 mps_preprocess.py:115] Visiting: aten_bmm_default_16, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:24,246 mps_preprocess.py:115] Visiting: aten_view_copy_default_199, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,246 mps_preprocess.py:115] Visiting: aten_permute_copy_default_67, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,246 mps_preprocess.py:115] Visiting: aten_view_copy_default_200, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,247 mps_preprocess.py:115] Visiting: aten_expand_copy_default_46, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:24,247 mps_preprocess.py:115] Visiting: aten_view_copy_default_201, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,247 mps_preprocess.py:115] Visiting: aten_bmm_default_17, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:24,247 mps_preprocess.py:115] Visiting: aten_view_copy_default_203, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,247 mps_preprocess.py:115] Visiting: aten_mul_tensor_135, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,248 mps_preprocess.py:115] Visiting: aten_add_tensor_39, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:24,248 mps_preprocess.py:115] Visiting: aten_mul_tensor_136, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,248 mps_preprocess.py:115] Visiting: aten_mean_dim_11, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:24,248 mps_preprocess.py:115] Visiting: aten_add_tensor_40, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:24,249 mps_preprocess.py:115] Visiting: aten_rsqrt_default_11, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:24,249 mps_preprocess.py:115] Visiting: aten_mul_tensor_137, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,249 mps_preprocess.py:115] Visiting: aten_mul_tensor_138, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,249 mps_preprocess.py:115] Visiting: aten_view_copy_default_204, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,250 mps_preprocess.py:115] Visiting: aten_view_copy_default_206, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,250 mps_preprocess.py:115] Visiting: aten_mm_default_33, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:24,250 mps_preprocess.py:115] Visiting: aten_mm_default_34, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:24,250 mps_preprocess.py:115] Visiting: aten_view_copy_default_205, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,251 mps_preprocess.py:115] Visiting: aten_view_copy_default_207, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,251 mps_preprocess.py:115] Visiting: aten_mul_tensor_139, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,251 mps_preprocess.py:115] Visiting: aten_mul_tensor_141, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,251 mps_preprocess.py:115] Visiting: aten_sigmoid_default_5, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:24,251 mps_preprocess.py:115] Visiting: aten_mul_tensor_140, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,252 mps_preprocess.py:115] Visiting: aten_mul_tensor_142, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,252 mps_preprocess.py:115] Visiting: aten_view_copy_default_208, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,252 mps_preprocess.py:115] Visiting: aten_mm_default_35, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:24,253 mps_preprocess.py:115] Visiting: aten_view_copy_default_209, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,253 mps_preprocess.py:115] Visiting: aten_mul_tensor_143, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,253 mps_preprocess.py:115] Visiting: aten_add_tensor_41, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:24,254 mps_preprocess.py:115] Visiting: aten_mul_tensor_144, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,254 mps_preprocess.py:115] Visiting: aten_mean_dim_12, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:24,254 mps_preprocess.py:115] Visiting: aten_add_tensor_42, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:24,254 mps_preprocess.py:115] Visiting: aten_rsqrt_default_12, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:24,255 mps_preprocess.py:115] Visiting: aten_mul_tensor_145, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,255 mps_preprocess.py:115] Visiting: aten_mul_tensor_146, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,255 mps_preprocess.py:115] Visiting: aten_view_copy_default_212, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,256 mps_preprocess.py:115] Visiting: aten_view_copy_default_214, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,256 mps_preprocess.py:115] Visiting: aten_mm_default_37, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:24,256 mps_preprocess.py:115] Visiting: aten_mm_default_38, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:24,256 mps_preprocess.py:115] Visiting: aten_view_copy_default_213, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,257 mps_preprocess.py:115] Visiting: aten_view_copy_default_215, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,257 mps_preprocess.py:115] Visiting: aten_mul_tensor_148, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,257 mps_preprocess.py:115] Visiting: aten_mul_tensor_149, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,258 mps_preprocess.py:115] Visiting: aten_view_copy_default_217, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,259 mps_preprocess.py:115] Visiting: aten_view_copy_default_218, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,260 mps_preprocess.py:115] Visiting: aten_view_copy_default_220, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,261 mps_preprocess.py:115] Visiting: aten_permute_copy_default_77, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,261 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_26, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:24,262 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_27, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:24,262 mps_preprocess.py:115] Visiting: aten_view_copy_default_226, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,262 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_26, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:24,263 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_27, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:24,263 mps_preprocess.py:115] Visiting: aten_mul_tensor_154, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,263 mps_preprocess.py:115] Visiting: aten_mul_tensor_156, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,264 mps_preprocess.py:115] Visiting: aten_mul_tensor_155, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,265 mps_preprocess.py:115] Visiting: aten_mul_tensor_157, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:24,265 mps_preprocess.py:115] Visiting: aten_sub_tensor_13, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:24,265 mps_preprocess.py:115] Visiting: aten_add_tensor_44, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:24,265 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_50, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:24,266 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_51, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:24,266 mps_preprocess.py:115] Visiting: aten_cat_default_13, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:24,267 mps_preprocess.py:115] Visiting: aten_view_copy_default_224, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:24,267 mps_preprocess.py:115] Visiting: aten_permute_copy_default_76, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:24,267 mps_preprocess.py:115] Visiting: aten_view_copy_default_225, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,471 mps_preprocess.py:115] Visiting: aten_view_copy_default_186, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,472 mps_preprocess.py:115] Visiting: aten_view_copy_default_187, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,472 mps_preprocess.py:115] Visiting: aten_view_copy_default_140, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,472 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_39, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:25,472 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_38, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:25,473 mps_preprocess.py:115] Visiting: aten__to_copy_default_32, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:25,473 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_36, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:25,473 mps_preprocess.py:115] Visiting: aten__to_copy_default_36, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:25,473 mps_preprocess.py:115] Visiting: aten__to_copy_default_37, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:25,473 mps_preprocess.py:115] Visiting: aten__to_copy_default_38, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:25,474 mps_preprocess.py:115] Visiting: aten__to_copy_default_39, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:25,474 mps_preprocess.py:115] Visiting: aten__to_copy_default_41, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:25,474 mps_preprocess.py:115] Visiting: aten__to_copy_default_42, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:25,474 mps_preprocess.py:115] Visiting: aten_expand_copy_default_33, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:25,475 mps_preprocess.py:115] Visiting: aten_expand_copy_default_32, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:25,475 mps_preprocess.py:115] Visiting: aten_permute_copy_default_48, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,475 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_37, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:25,475 mps_preprocess.py:115] Visiting: aten_permute_copy_default_56, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,475 mps_preprocess.py:115] Visiting: aten_permute_copy_default_57, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,476 mps_preprocess.py:115] Visiting: aten_permute_copy_default_58, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,476 mps_preprocess.py:115] Visiting: aten_permute_copy_default_59, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,476 mps_preprocess.py:115] Visiting: aten_permute_copy_default_61, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,476 mps_preprocess.py:115] Visiting: aten_permute_copy_default_62, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,476 mps_preprocess.py:115] Visiting: aten_clone_default_9, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:25,476 mps_preprocess.py:115] Visiting: aten_clone_default_8, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:25,477 mps_preprocess.py:115] Visiting: aten_mm_default_24, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:25,477 mps_preprocess.py:115] Visiting: aten_index_tensor_6, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:25,477 mps_preprocess.py:115] Visiting: aten_expand_copy_default_39, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:25,477 mps_preprocess.py:115] Visiting: aten_view_copy_default_158, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,478 mps_preprocess.py:115] Visiting: aten_view_copy_default_157, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,478 mps_preprocess.py:115] Visiting: aten_view_copy_default_141, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,478 mps_preprocess.py:115] Visiting: aten__to_copy_default_35, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:25,478 mps_preprocess.py:115] Visiting: aten_view_copy_default_167, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,478 mps_preprocess.py:115] Visiting: aten_expand_copy_default_37, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:25,479 mps_preprocess.py:115] Visiting: aten_permute_copy_default_54, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,479 mps_preprocess.py:115] Visiting: aten_mul_tensor_99, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,479 mps_preprocess.py:115] Visiting: aten_view_copy_default_163, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,479 mps_preprocess.py:115] Visiting: aten_expand_copy_default_35, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:25,479 mps_preprocess.py:115] Visiting: aten_view_copy_default_146, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,479 mps_preprocess.py:115] Visiting: aten_view_copy_default_160, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,480 mps_preprocess.py:115] Visiting: aten_view_copy_default_149, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,480 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_16, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:25,480 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_17, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:25,480 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_16, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:25,480 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_17, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:25,481 mps_preprocess.py:115] Visiting: aten_mul_tensor_102, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,481 mps_preprocess.py:115] Visiting: aten_mul_tensor_104, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,481 mps_preprocess.py:115] Visiting: aten_mul_tensor_103, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,481 mps_preprocess.py:115] Visiting: aten_mul_tensor_105, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,481 mps_preprocess.py:115] Visiting: aten_sub_tensor_8, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:25,482 mps_preprocess.py:115] Visiting: aten_add_tensor_29, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:25,482 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_32, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:25,482 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_33, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:25,482 mps_preprocess.py:115] Visiting: aten_cat_default_8, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:25,482 mps_preprocess.py:115] Visiting: aten_view_copy_default_153, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,482 mps_preprocess.py:115] Visiting: aten_permute_copy_default_51, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,483 mps_preprocess.py:115] Visiting: aten_expand_copy_default_34, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:25,483 mps_preprocess.py:115] Visiting: aten_view_copy_default_159, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,483 mps_preprocess.py:115] Visiting: aten_bmm_default_12, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:25,483 mps_preprocess.py:115] Visiting: aten_view_copy_default_161, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,483 mps_preprocess.py:115] Visiting: aten_mul_tensor_110, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,483 mps_preprocess.py:115] Visiting: aten_add_tensor_31, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:25,484 mps_preprocess.py:115] Visiting: aten__softmax_default_4, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:25,484 mps_preprocess.py:115] Visiting: aten_expand_copy_default_36, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:25,484 mps_preprocess.py:115] Visiting: aten_view_copy_default_162, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,484 mps_preprocess.py:115] Visiting: aten_bmm_default_13, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:25,484 mps_preprocess.py:115] Visiting: aten_view_copy_default_164, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,485 mps_preprocess.py:115] Visiting: aten_permute_copy_default_55, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,485 mps_preprocess.py:115] Visiting: aten_view_copy_default_165, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,485 mps_preprocess.py:115] Visiting: aten_expand_copy_default_38, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:25,485 mps_preprocess.py:115] Visiting: aten_view_copy_default_166, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,485 mps_preprocess.py:115] Visiting: aten_bmm_default_14, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:25,486 mps_preprocess.py:115] Visiting: aten_view_copy_default_168, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,486 mps_preprocess.py:115] Visiting: aten_mul_tensor_111, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,486 mps_preprocess.py:115] Visiting: aten_add_tensor_32, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:25,486 mps_preprocess.py:115] Visiting: aten_mul_tensor_112, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,486 mps_preprocess.py:115] Visiting: aten_mean_dim_9, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:25,487 mps_preprocess.py:115] Visiting: aten_add_tensor_33, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:25,487 mps_preprocess.py:115] Visiting: aten_rsqrt_default_9, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:25,487 mps_preprocess.py:115] Visiting: aten_mul_tensor_113, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,487 mps_preprocess.py:115] Visiting: aten_mul_tensor_114, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,487 mps_preprocess.py:115] Visiting: aten_view_copy_default_169, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,488 mps_preprocess.py:115] Visiting: aten_view_copy_default_171, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,488 mps_preprocess.py:115] Visiting: aten_mm_default_27, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:25,488 mps_preprocess.py:115] Visiting: aten_mm_default_28, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:25,488 mps_preprocess.py:115] Visiting: aten_view_copy_default_170, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,488 mps_preprocess.py:115] Visiting: aten_view_copy_default_172, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,488 mps_preprocess.py:115] Visiting: aten_mul_tensor_115, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,489 mps_preprocess.py:115] Visiting: aten_mul_tensor_117, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,489 mps_preprocess.py:115] Visiting: aten_sigmoid_default_4, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:25,489 mps_preprocess.py:115] Visiting: aten_mul_tensor_116, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,489 mps_preprocess.py:115] Visiting: aten_mul_tensor_118, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,489 mps_preprocess.py:115] Visiting: aten_view_copy_default_173, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,490 mps_preprocess.py:115] Visiting: aten_mm_default_29, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:25,490 mps_preprocess.py:115] Visiting: aten_view_copy_default_174, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,490 mps_preprocess.py:115] Visiting: aten_mul_tensor_119, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,491 mps_preprocess.py:115] Visiting: aten_add_tensor_34, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:25,491 mps_preprocess.py:115] Visiting: aten_mul_tensor_120, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,491 mps_preprocess.py:115] Visiting: aten_mean_dim_10, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:25,491 mps_preprocess.py:115] Visiting: aten_add_tensor_35, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:25,491 mps_preprocess.py:115] Visiting: aten_rsqrt_default_10, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:25,492 mps_preprocess.py:115] Visiting: aten_mul_tensor_121, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,492 mps_preprocess.py:115] Visiting: aten_mul_tensor_122, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,492 mps_preprocess.py:115] Visiting: aten_view_copy_default_177, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,492 mps_preprocess.py:115] Visiting: aten_view_copy_default_179, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,493 mps_preprocess.py:115] Visiting: aten_mm_default_31, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:25,493 mps_preprocess.py:115] Visiting: aten_mm_default_32, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:25,493 mps_preprocess.py:115] Visiting: aten_view_copy_default_178, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,493 mps_preprocess.py:115] Visiting: aten_view_copy_default_180, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,493 mps_preprocess.py:115] Visiting: aten_mul_tensor_124, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,494 mps_preprocess.py:115] Visiting: aten_mul_tensor_125, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,494 mps_preprocess.py:115] Visiting: aten_view_copy_default_182, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,494 mps_preprocess.py:115] Visiting: aten_view_copy_default_183, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,494 mps_preprocess.py:115] Visiting: aten_view_copy_default_185, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,494 mps_preprocess.py:115] Visiting: aten_permute_copy_default_65, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,495 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_22, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:25,495 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_23, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:25,495 mps_preprocess.py:115] Visiting: aten_view_copy_default_191, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,495 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_22, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:25,495 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_23, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:25,495 mps_preprocess.py:115] Visiting: aten_mul_tensor_130, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,496 mps_preprocess.py:115] Visiting: aten_mul_tensor_132, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,496 mps_preprocess.py:115] Visiting: aten_mul_tensor_131, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,496 mps_preprocess.py:115] Visiting: aten_mul_tensor_133, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:25,496 mps_preprocess.py:115] Visiting: aten_sub_tensor_11, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:25,496 mps_preprocess.py:115] Visiting: aten_add_tensor_37, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:25,497 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_42, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:25,497 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_43, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:25,497 mps_preprocess.py:115] Visiting: aten_cat_default_11, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:25,497 mps_preprocess.py:115] Visiting: aten_view_copy_default_189, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:25,497 mps_preprocess.py:115] Visiting: aten_permute_copy_default_64, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:25,497 mps_preprocess.py:115] Visiting: aten_view_copy_default_190, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,585 mps_preprocess.py:115] Visiting: aten_view_copy_default_151, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,586 mps_preprocess.py:115] Visiting: aten_view_copy_default_152, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,587 mps_preprocess.py:115] Visiting: aten_view_copy_default_105, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,587 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_31, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:26,587 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_30, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:26,587 mps_preprocess.py:115] Visiting: aten__to_copy_default_24, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:26,588 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_28, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:26,588 mps_preprocess.py:115] Visiting: aten__to_copy_default_28, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:26,588 mps_preprocess.py:115] Visiting: aten__to_copy_default_29, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:26,588 mps_preprocess.py:115] Visiting: aten__to_copy_default_30, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:26,588 mps_preprocess.py:115] Visiting: aten__to_copy_default_31, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:26,589 mps_preprocess.py:115] Visiting: aten__to_copy_default_33, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:26,589 mps_preprocess.py:115] Visiting: aten__to_copy_default_34, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:26,589 mps_preprocess.py:115] Visiting: aten_expand_copy_default_25, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:26,589 mps_preprocess.py:115] Visiting: aten_expand_copy_default_24, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:26,590 mps_preprocess.py:115] Visiting: aten_permute_copy_default_36, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,590 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_29, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:26,590 mps_preprocess.py:115] Visiting: aten_permute_copy_default_44, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,590 mps_preprocess.py:115] Visiting: aten_permute_copy_default_45, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,591 mps_preprocess.py:115] Visiting: aten_permute_copy_default_46, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,591 mps_preprocess.py:115] Visiting: aten_permute_copy_default_47, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,591 mps_preprocess.py:115] Visiting: aten_permute_copy_default_49, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,591 mps_preprocess.py:115] Visiting: aten_permute_copy_default_50, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,592 mps_preprocess.py:115] Visiting: aten_clone_default_7, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:26,592 mps_preprocess.py:115] Visiting: aten_clone_default_6, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:26,592 mps_preprocess.py:115] Visiting: aten_mm_default_18, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:26,592 mps_preprocess.py:115] Visiting: aten_index_tensor_5, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:26,593 mps_preprocess.py:115] Visiting: aten_expand_copy_default_31, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:26,593 mps_preprocess.py:115] Visiting: aten_view_copy_default_123, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,593 mps_preprocess.py:115] Visiting: aten_view_copy_default_122, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,593 mps_preprocess.py:115] Visiting: aten_view_copy_default_106, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,593 mps_preprocess.py:115] Visiting: aten__to_copy_default_27, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:26,593 mps_preprocess.py:115] Visiting: aten_view_copy_default_132, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,594 mps_preprocess.py:115] Visiting: aten_expand_copy_default_29, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:26,594 mps_preprocess.py:115] Visiting: aten_permute_copy_default_42, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,594 mps_preprocess.py:115] Visiting: aten_mul_tensor_75, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,594 mps_preprocess.py:115] Visiting: aten_view_copy_default_128, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,594 mps_preprocess.py:115] Visiting: aten_expand_copy_default_27, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:26,595 mps_preprocess.py:115] Visiting: aten_view_copy_default_111, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,595 mps_preprocess.py:115] Visiting: aten_view_copy_default_125, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,595 mps_preprocess.py:115] Visiting: aten_view_copy_default_114, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,595 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_12, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:26,596 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_13, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:26,596 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_12, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:26,596 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_13, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:26,596 mps_preprocess.py:115] Visiting: aten_mul_tensor_78, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,596 mps_preprocess.py:115] Visiting: aten_mul_tensor_80, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,597 mps_preprocess.py:115] Visiting: aten_mul_tensor_79, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,597 mps_preprocess.py:115] Visiting: aten_mul_tensor_81, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,597 mps_preprocess.py:115] Visiting: aten_sub_tensor_6, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:26,597 mps_preprocess.py:115] Visiting: aten_add_tensor_22, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:26,597 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_24, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:26,598 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_25, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:26,598 mps_preprocess.py:115] Visiting: aten_cat_default_6, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:26,598 mps_preprocess.py:115] Visiting: aten_view_copy_default_118, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,598 mps_preprocess.py:115] Visiting: aten_permute_copy_default_39, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,599 mps_preprocess.py:115] Visiting: aten_expand_copy_default_26, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:26,599 mps_preprocess.py:115] Visiting: aten_view_copy_default_124, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,599 mps_preprocess.py:115] Visiting: aten_bmm_default_9, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:26,599 mps_preprocess.py:115] Visiting: aten_view_copy_default_126, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,600 mps_preprocess.py:115] Visiting: aten_mul_tensor_86, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,600 mps_preprocess.py:115] Visiting: aten_add_tensor_24, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:26,600 mps_preprocess.py:115] Visiting: aten__softmax_default_3, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:26,600 mps_preprocess.py:115] Visiting: aten_expand_copy_default_28, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:26,600 mps_preprocess.py:115] Visiting: aten_view_copy_default_127, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,601 mps_preprocess.py:115] Visiting: aten_bmm_default_10, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:26,601 mps_preprocess.py:115] Visiting: aten_view_copy_default_129, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,601 mps_preprocess.py:115] Visiting: aten_permute_copy_default_43, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,601 mps_preprocess.py:115] Visiting: aten_view_copy_default_130, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,602 mps_preprocess.py:115] Visiting: aten_expand_copy_default_30, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:26,602 mps_preprocess.py:115] Visiting: aten_view_copy_default_131, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,602 mps_preprocess.py:115] Visiting: aten_bmm_default_11, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:26,602 mps_preprocess.py:115] Visiting: aten_view_copy_default_133, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,602 mps_preprocess.py:115] Visiting: aten_mul_tensor_87, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,603 mps_preprocess.py:115] Visiting: aten_add_tensor_25, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:26,603 mps_preprocess.py:115] Visiting: aten_mul_tensor_88, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,603 mps_preprocess.py:115] Visiting: aten_mean_dim_7, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:26,603 mps_preprocess.py:115] Visiting: aten_add_tensor_26, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:26,604 mps_preprocess.py:115] Visiting: aten_rsqrt_default_7, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:26,604 mps_preprocess.py:115] Visiting: aten_mul_tensor_89, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,604 mps_preprocess.py:115] Visiting: aten_mul_tensor_90, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,604 mps_preprocess.py:115] Visiting: aten_view_copy_default_134, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,605 mps_preprocess.py:115] Visiting: aten_view_copy_default_136, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,605 mps_preprocess.py:115] Visiting: aten_mm_default_21, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:26,605 mps_preprocess.py:115] Visiting: aten_mm_default_22, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:26,605 mps_preprocess.py:115] Visiting: aten_view_copy_default_135, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,605 mps_preprocess.py:115] Visiting: aten_view_copy_default_137, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,605 mps_preprocess.py:115] Visiting: aten_mul_tensor_91, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,606 mps_preprocess.py:115] Visiting: aten_mul_tensor_93, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,606 mps_preprocess.py:115] Visiting: aten_sigmoid_default_3, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:26,606 mps_preprocess.py:115] Visiting: aten_mul_tensor_92, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,606 mps_preprocess.py:115] Visiting: aten_mul_tensor_94, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,606 mps_preprocess.py:115] Visiting: aten_view_copy_default_138, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,607 mps_preprocess.py:115] Visiting: aten_mm_default_23, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:26,607 mps_preprocess.py:115] Visiting: aten_view_copy_default_139, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,607 mps_preprocess.py:115] Visiting: aten_mul_tensor_95, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,607 mps_preprocess.py:115] Visiting: aten_add_tensor_27, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:26,608 mps_preprocess.py:115] Visiting: aten_mul_tensor_96, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,608 mps_preprocess.py:115] Visiting: aten_mean_dim_8, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:26,608 mps_preprocess.py:115] Visiting: aten_add_tensor_28, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:26,608 mps_preprocess.py:115] Visiting: aten_rsqrt_default_8, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:26,609 mps_preprocess.py:115] Visiting: aten_mul_tensor_97, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,609 mps_preprocess.py:115] Visiting: aten_mul_tensor_98, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,609 mps_preprocess.py:115] Visiting: aten_view_copy_default_142, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,609 mps_preprocess.py:115] Visiting: aten_view_copy_default_144, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,609 mps_preprocess.py:115] Visiting: aten_mm_default_25, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:26,610 mps_preprocess.py:115] Visiting: aten_mm_default_26, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:26,610 mps_preprocess.py:115] Visiting: aten_view_copy_default_143, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,610 mps_preprocess.py:115] Visiting: aten_view_copy_default_145, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,611 mps_preprocess.py:115] Visiting: aten_mul_tensor_100, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,611 mps_preprocess.py:115] Visiting: aten_mul_tensor_101, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,611 mps_preprocess.py:115] Visiting: aten_view_copy_default_147, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,612 mps_preprocess.py:115] Visiting: aten_view_copy_default_148, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,612 mps_preprocess.py:115] Visiting: aten_view_copy_default_150, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,612 mps_preprocess.py:115] Visiting: aten_permute_copy_default_53, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,612 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_18, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:26,613 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_19, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:26,613 mps_preprocess.py:115] Visiting: aten_view_copy_default_156, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,613 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_18, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:26,613 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_19, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:26,614 mps_preprocess.py:115] Visiting: aten_mul_tensor_106, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,614 mps_preprocess.py:115] Visiting: aten_mul_tensor_108, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,614 mps_preprocess.py:115] Visiting: aten_mul_tensor_107, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,614 mps_preprocess.py:115] Visiting: aten_mul_tensor_109, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:26,615 mps_preprocess.py:115] Visiting: aten_sub_tensor_9, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:26,615 mps_preprocess.py:115] Visiting: aten_add_tensor_30, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:26,615 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_34, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:26,616 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_35, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:26,618 mps_preprocess.py:115] Visiting: aten_cat_default_9, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:26,619 mps_preprocess.py:115] Visiting: aten_view_copy_default_154, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:26,619 mps_preprocess.py:115] Visiting: aten_permute_copy_default_52, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:26,619 mps_preprocess.py:115] Visiting: aten_view_copy_default_155, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,708 mps_preprocess.py:115] Visiting: aten_view_copy_default_116, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,709 mps_preprocess.py:115] Visiting: aten_view_copy_default_117, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,709 mps_preprocess.py:115] Visiting: aten_view_copy_default_70, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,709 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_23, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:27,709 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_22, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:27,710 mps_preprocess.py:115] Visiting: aten__to_copy_default_16, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:27,710 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_20, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:27,710 mps_preprocess.py:115] Visiting: aten__to_copy_default_20, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:27,710 mps_preprocess.py:115] Visiting: aten__to_copy_default_21, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:27,710 mps_preprocess.py:115] Visiting: aten__to_copy_default_22, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:27,711 mps_preprocess.py:115] Visiting: aten__to_copy_default_23, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:27,711 mps_preprocess.py:115] Visiting: aten__to_copy_default_25, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:27,711 mps_preprocess.py:115] Visiting: aten__to_copy_default_26, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:27,711 mps_preprocess.py:115] Visiting: aten_expand_copy_default_17, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:27,711 mps_preprocess.py:115] Visiting: aten_expand_copy_default_16, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:27,712 mps_preprocess.py:115] Visiting: aten_permute_copy_default_24, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,712 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_21, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:27,712 mps_preprocess.py:115] Visiting: aten_permute_copy_default_32, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,712 mps_preprocess.py:115] Visiting: aten_permute_copy_default_33, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,712 mps_preprocess.py:115] Visiting: aten_permute_copy_default_34, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,713 mps_preprocess.py:115] Visiting: aten_permute_copy_default_35, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,713 mps_preprocess.py:115] Visiting: aten_permute_copy_default_37, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,713 mps_preprocess.py:115] Visiting: aten_permute_copy_default_38, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,713 mps_preprocess.py:115] Visiting: aten_clone_default_5, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:27,713 mps_preprocess.py:115] Visiting: aten_clone_default_4, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:27,714 mps_preprocess.py:115] Visiting: aten_mm_default_12, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:27,714 mps_preprocess.py:115] Visiting: aten_index_tensor_4, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:27,714 mps_preprocess.py:115] Visiting: aten_expand_copy_default_23, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:27,714 mps_preprocess.py:115] Visiting: aten_view_copy_default_88, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,715 mps_preprocess.py:115] Visiting: aten_view_copy_default_87, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,715 mps_preprocess.py:115] Visiting: aten_view_copy_default_71, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,715 mps_preprocess.py:115] Visiting: aten__to_copy_default_19, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:27,715 mps_preprocess.py:115] Visiting: aten_view_copy_default_97, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,715 mps_preprocess.py:115] Visiting: aten_expand_copy_default_21, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:27,716 mps_preprocess.py:115] Visiting: aten_permute_copy_default_30, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,716 mps_preprocess.py:115] Visiting: aten_mul_tensor_51, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,716 mps_preprocess.py:115] Visiting: aten_view_copy_default_93, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,716 mps_preprocess.py:115] Visiting: aten_expand_copy_default_19, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:27,717 mps_preprocess.py:115] Visiting: aten_view_copy_default_76, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,717 mps_preprocess.py:115] Visiting: aten_view_copy_default_90, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,717 mps_preprocess.py:115] Visiting: aten_view_copy_default_79, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,717 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_8, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:27,717 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_9, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:27,718 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_8, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:27,718 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_9, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:27,718 mps_preprocess.py:115] Visiting: aten_mul_tensor_54, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,718 mps_preprocess.py:115] Visiting: aten_mul_tensor_56, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,718 mps_preprocess.py:115] Visiting: aten_mul_tensor_55, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,719 mps_preprocess.py:115] Visiting: aten_mul_tensor_57, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,719 mps_preprocess.py:115] Visiting: aten_sub_tensor_4, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:27,719 mps_preprocess.py:115] Visiting: aten_add_tensor_15, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:27,719 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_16, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:27,719 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_17, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:27,720 mps_preprocess.py:115] Visiting: aten_cat_default_4, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:27,720 mps_preprocess.py:115] Visiting: aten_view_copy_default_83, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,720 mps_preprocess.py:115] Visiting: aten_permute_copy_default_27, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,720 mps_preprocess.py:115] Visiting: aten_expand_copy_default_18, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:27,720 mps_preprocess.py:115] Visiting: aten_view_copy_default_89, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,721 mps_preprocess.py:115] Visiting: aten_bmm_default_6, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:27,721 mps_preprocess.py:115] Visiting: aten_view_copy_default_91, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,721 mps_preprocess.py:115] Visiting: aten_mul_tensor_62, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,721 mps_preprocess.py:115] Visiting: aten_add_tensor_17, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:27,722 mps_preprocess.py:115] Visiting: aten__softmax_default_2, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:27,722 mps_preprocess.py:115] Visiting: aten_expand_copy_default_20, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:27,722 mps_preprocess.py:115] Visiting: aten_view_copy_default_92, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,722 mps_preprocess.py:115] Visiting: aten_bmm_default_7, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:27,722 mps_preprocess.py:115] Visiting: aten_view_copy_default_94, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,722 mps_preprocess.py:115] Visiting: aten_permute_copy_default_31, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,723 mps_preprocess.py:115] Visiting: aten_view_copy_default_95, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,723 mps_preprocess.py:115] Visiting: aten_expand_copy_default_22, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:27,723 mps_preprocess.py:115] Visiting: aten_view_copy_default_96, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,723 mps_preprocess.py:115] Visiting: aten_bmm_default_8, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:27,724 mps_preprocess.py:115] Visiting: aten_view_copy_default_98, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,724 mps_preprocess.py:115] Visiting: aten_mul_tensor_63, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,724 mps_preprocess.py:115] Visiting: aten_add_tensor_18, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:27,725 mps_preprocess.py:115] Visiting: aten_mul_tensor_64, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,725 mps_preprocess.py:115] Visiting: aten_mean_dim_5, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:27,725 mps_preprocess.py:115] Visiting: aten_add_tensor_19, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:27,725 mps_preprocess.py:115] Visiting: aten_rsqrt_default_5, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:27,725 mps_preprocess.py:115] Visiting: aten_mul_tensor_65, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,726 mps_preprocess.py:115] Visiting: aten_mul_tensor_66, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,726 mps_preprocess.py:115] Visiting: aten_view_copy_default_99, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,726 mps_preprocess.py:115] Visiting: aten_view_copy_default_101, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,726 mps_preprocess.py:115] Visiting: aten_mm_default_15, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:27,726 mps_preprocess.py:115] Visiting: aten_mm_default_16, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:27,727 mps_preprocess.py:115] Visiting: aten_view_copy_default_100, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,727 mps_preprocess.py:115] Visiting: aten_view_copy_default_102, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,727 mps_preprocess.py:115] Visiting: aten_mul_tensor_67, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,728 mps_preprocess.py:115] Visiting: aten_mul_tensor_69, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,728 mps_preprocess.py:115] Visiting: aten_sigmoid_default_2, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:27,728 mps_preprocess.py:115] Visiting: aten_mul_tensor_68, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,728 mps_preprocess.py:115] Visiting: aten_mul_tensor_70, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,728 mps_preprocess.py:115] Visiting: aten_view_copy_default_103, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,729 mps_preprocess.py:115] Visiting: aten_mm_default_17, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:27,729 mps_preprocess.py:115] Visiting: aten_view_copy_default_104, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,729 mps_preprocess.py:115] Visiting: aten_mul_tensor_71, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,729 mps_preprocess.py:115] Visiting: aten_add_tensor_20, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:27,730 mps_preprocess.py:115] Visiting: aten_mul_tensor_72, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,730 mps_preprocess.py:115] Visiting: aten_mean_dim_6, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:27,730 mps_preprocess.py:115] Visiting: aten_add_tensor_21, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:27,731 mps_preprocess.py:115] Visiting: aten_rsqrt_default_6, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:27,731 mps_preprocess.py:115] Visiting: aten_mul_tensor_73, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,731 mps_preprocess.py:115] Visiting: aten_mul_tensor_74, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,731 mps_preprocess.py:115] Visiting: aten_view_copy_default_107, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,732 mps_preprocess.py:115] Visiting: aten_view_copy_default_109, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,732 mps_preprocess.py:115] Visiting: aten_mm_default_19, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:27,732 mps_preprocess.py:115] Visiting: aten_mm_default_20, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:27,733 mps_preprocess.py:115] Visiting: aten_view_copy_default_108, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,733 mps_preprocess.py:115] Visiting: aten_view_copy_default_110, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,734 mps_preprocess.py:115] Visiting: aten_mul_tensor_76, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,734 mps_preprocess.py:115] Visiting: aten_mul_tensor_77, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,734 mps_preprocess.py:115] Visiting: aten_view_copy_default_112, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,734 mps_preprocess.py:115] Visiting: aten_view_copy_default_113, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,735 mps_preprocess.py:115] Visiting: aten_view_copy_default_115, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,735 mps_preprocess.py:115] Visiting: aten_permute_copy_default_41, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,735 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_14, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:27,735 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_15, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:27,736 mps_preprocess.py:115] Visiting: aten_view_copy_default_121, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,736 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_14, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:27,736 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_15, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:27,737 mps_preprocess.py:115] Visiting: aten_mul_tensor_82, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,737 mps_preprocess.py:115] Visiting: aten_mul_tensor_84, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,737 mps_preprocess.py:115] Visiting: aten_mul_tensor_83, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,737 mps_preprocess.py:115] Visiting: aten_mul_tensor_85, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:27,738 mps_preprocess.py:115] Visiting: aten_sub_tensor_7, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:27,738 mps_preprocess.py:115] Visiting: aten_add_tensor_23, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:27,738 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_26, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:27,738 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_27, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:27,739 mps_preprocess.py:115] Visiting: aten_cat_default_7, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:27,739 mps_preprocess.py:115] Visiting: aten_view_copy_default_119, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:27,739 mps_preprocess.py:115] Visiting: aten_permute_copy_default_40, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:27,739 mps_preprocess.py:115] Visiting: aten_view_copy_default_120, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,817 mps_preprocess.py:115] Visiting: aten_view_copy_default_81, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,818 mps_preprocess.py:115] Visiting: aten_view_copy_default_82, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,818 mps_preprocess.py:115] Visiting: aten_view_copy_default_35, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,818 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_15, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:28,819 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_14, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:28,819 mps_preprocess.py:115] Visiting: aten__to_copy_default_8, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:28,819 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_12, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:28,819 mps_preprocess.py:115] Visiting: aten__to_copy_default_12, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:28,819 mps_preprocess.py:115] Visiting: aten__to_copy_default_13, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:28,819 mps_preprocess.py:115] Visiting: aten__to_copy_default_14, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:28,820 mps_preprocess.py:115] Visiting: aten__to_copy_default_15, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:28,820 mps_preprocess.py:115] Visiting: aten__to_copy_default_17, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:28,820 mps_preprocess.py:115] Visiting: aten__to_copy_default_18, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:28,820 mps_preprocess.py:115] Visiting: aten_expand_copy_default_9, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:28,820 mps_preprocess.py:115] Visiting: aten_expand_copy_default_8, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:28,821 mps_preprocess.py:115] Visiting: aten_permute_copy_default_12, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,821 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_13, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:28,821 mps_preprocess.py:115] Visiting: aten_permute_copy_default_20, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,821 mps_preprocess.py:115] Visiting: aten_permute_copy_default_21, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,821 mps_preprocess.py:115] Visiting: aten_permute_copy_default_22, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,822 mps_preprocess.py:115] Visiting: aten_permute_copy_default_23, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,822 mps_preprocess.py:115] Visiting: aten_permute_copy_default_25, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,822 mps_preprocess.py:115] Visiting: aten_permute_copy_default_26, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,822 mps_preprocess.py:115] Visiting: aten_clone_default_3, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:28,822 mps_preprocess.py:115] Visiting: aten_clone_default_2, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:28,822 mps_preprocess.py:115] Visiting: aten_mm_default_6, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:28,823 mps_preprocess.py:115] Visiting: aten_index_tensor_3, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:28,823 mps_preprocess.py:115] Visiting: aten_expand_copy_default_15, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:28,823 mps_preprocess.py:115] Visiting: aten_view_copy_default_53, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,823 mps_preprocess.py:115] Visiting: aten_view_copy_default_52, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,823 mps_preprocess.py:115] Visiting: aten_view_copy_default_36, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,824 mps_preprocess.py:115] Visiting: aten__to_copy_default_11, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:28,824 mps_preprocess.py:115] Visiting: aten_view_copy_default_62, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,824 mps_preprocess.py:115] Visiting: aten_expand_copy_default_13, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:28,824 mps_preprocess.py:115] Visiting: aten_permute_copy_default_18, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,824 mps_preprocess.py:115] Visiting: aten_mul_tensor_27, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,825 mps_preprocess.py:115] Visiting: aten_view_copy_default_58, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,825 mps_preprocess.py:115] Visiting: aten_expand_copy_default_11, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:28,825 mps_preprocess.py:115] Visiting: aten_view_copy_default_41, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,825 mps_preprocess.py:115] Visiting: aten_view_copy_default_55, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,825 mps_preprocess.py:115] Visiting: aten_view_copy_default_44, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,826 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_4, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:28,826 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_5, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:28,826 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_4, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:28,826 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_5, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:28,827 mps_preprocess.py:115] Visiting: aten_mul_tensor_30, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,827 mps_preprocess.py:115] Visiting: aten_mul_tensor_32, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,827 mps_preprocess.py:115] Visiting: aten_mul_tensor_31, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,827 mps_preprocess.py:115] Visiting: aten_mul_tensor_33, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,828 mps_preprocess.py:115] Visiting: aten_sub_tensor_2, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:28,828 mps_preprocess.py:115] Visiting: aten_add_tensor_8, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:28,828 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_8, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:28,828 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_9, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:28,829 mps_preprocess.py:115] Visiting: aten_cat_default_2, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:28,829 mps_preprocess.py:115] Visiting: aten_view_copy_default_48, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,829 mps_preprocess.py:115] Visiting: aten_permute_copy_default_15, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,830 mps_preprocess.py:115] Visiting: aten_expand_copy_default_10, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:28,830 mps_preprocess.py:115] Visiting: aten_view_copy_default_54, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,830 mps_preprocess.py:115] Visiting: aten_bmm_default_3, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:28,831 mps_preprocess.py:115] Visiting: aten_view_copy_default_56, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,831 mps_preprocess.py:115] Visiting: aten_mul_tensor_38, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,831 mps_preprocess.py:115] Visiting: aten_add_tensor_10, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:28,831 mps_preprocess.py:115] Visiting: aten__softmax_default_1, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:28,832 mps_preprocess.py:115] Visiting: aten_expand_copy_default_12, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:28,832 mps_preprocess.py:115] Visiting: aten_view_copy_default_57, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,832 mps_preprocess.py:115] Visiting: aten_bmm_default_4, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:28,832 mps_preprocess.py:115] Visiting: aten_view_copy_default_59, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,833 mps_preprocess.py:115] Visiting: aten_permute_copy_default_19, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,833 mps_preprocess.py:115] Visiting: aten_view_copy_default_60, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,833 mps_preprocess.py:115] Visiting: aten_expand_copy_default_14, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:28,834 mps_preprocess.py:115] Visiting: aten_view_copy_default_61, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,834 mps_preprocess.py:115] Visiting: aten_bmm_default_5, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:28,834 mps_preprocess.py:115] Visiting: aten_view_copy_default_63, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,835 mps_preprocess.py:115] Visiting: aten_mul_tensor_39, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,835 mps_preprocess.py:115] Visiting: aten_add_tensor_11, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:28,835 mps_preprocess.py:115] Visiting: aten_mul_tensor_40, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,835 mps_preprocess.py:115] Visiting: aten_mean_dim_3, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:28,835 mps_preprocess.py:115] Visiting: aten_add_tensor_12, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:28,836 mps_preprocess.py:115] Visiting: aten_rsqrt_default_3, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:28,836 mps_preprocess.py:115] Visiting: aten_mul_tensor_41, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,836 mps_preprocess.py:115] Visiting: aten_mul_tensor_42, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,837 mps_preprocess.py:115] Visiting: aten_view_copy_default_64, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,837 mps_preprocess.py:115] Visiting: aten_view_copy_default_66, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,837 mps_preprocess.py:115] Visiting: aten_mm_default_9, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:28,837 mps_preprocess.py:115] Visiting: aten_mm_default_10, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:28,837 mps_preprocess.py:115] Visiting: aten_view_copy_default_65, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,837 mps_preprocess.py:115] Visiting: aten_view_copy_default_67, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,838 mps_preprocess.py:115] Visiting: aten_mul_tensor_43, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,838 mps_preprocess.py:115] Visiting: aten_mul_tensor_45, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,838 mps_preprocess.py:115] Visiting: aten_sigmoid_default_1, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:28,838 mps_preprocess.py:115] Visiting: aten_mul_tensor_44, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,838 mps_preprocess.py:115] Visiting: aten_mul_tensor_46, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,839 mps_preprocess.py:115] Visiting: aten_view_copy_default_68, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,839 mps_preprocess.py:115] Visiting: aten_mm_default_11, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:28,839 mps_preprocess.py:115] Visiting: aten_view_copy_default_69, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,839 mps_preprocess.py:115] Visiting: aten_mul_tensor_47, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,839 mps_preprocess.py:115] Visiting: aten_add_tensor_13, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:28,840 mps_preprocess.py:115] Visiting: aten_mul_tensor_48, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,840 mps_preprocess.py:115] Visiting: aten_mean_dim_4, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:28,840 mps_preprocess.py:115] Visiting: aten_add_tensor_14, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:28,840 mps_preprocess.py:115] Visiting: aten_rsqrt_default_4, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:28,841 mps_preprocess.py:115] Visiting: aten_mul_tensor_49, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,841 mps_preprocess.py:115] Visiting: aten_mul_tensor_50, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,841 mps_preprocess.py:115] Visiting: aten_view_copy_default_72, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,841 mps_preprocess.py:115] Visiting: aten_view_copy_default_74, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,841 mps_preprocess.py:115] Visiting: aten_mm_default_13, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:28,842 mps_preprocess.py:115] Visiting: aten_mm_default_14, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:28,842 mps_preprocess.py:115] Visiting: aten_view_copy_default_73, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,842 mps_preprocess.py:115] Visiting: aten_view_copy_default_75, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,842 mps_preprocess.py:115] Visiting: aten_mul_tensor_52, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,843 mps_preprocess.py:115] Visiting: aten_mul_tensor_53, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,843 mps_preprocess.py:115] Visiting: aten_view_copy_default_77, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,843 mps_preprocess.py:115] Visiting: aten_view_copy_default_78, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,844 mps_preprocess.py:115] Visiting: aten_view_copy_default_80, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,844 mps_preprocess.py:115] Visiting: aten_permute_copy_default_29, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,844 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_10, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:28,844 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_11, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:28,845 mps_preprocess.py:115] Visiting: aten_view_copy_default_86, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,845 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_10, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:28,845 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_11, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:28,846 mps_preprocess.py:115] Visiting: aten_mul_tensor_58, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,846 mps_preprocess.py:115] Visiting: aten_mul_tensor_60, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,847 mps_preprocess.py:115] Visiting: aten_mul_tensor_59, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,848 mps_preprocess.py:115] Visiting: aten_mul_tensor_61, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:28,849 mps_preprocess.py:115] Visiting: aten_sub_tensor_5, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:28,850 mps_preprocess.py:115] Visiting: aten_add_tensor_16, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:28,852 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_18, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:28,853 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_19, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:28,854 mps_preprocess.py:115] Visiting: aten_cat_default_5, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:28,855 mps_preprocess.py:115] Visiting: aten_view_copy_default_84, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:28,859 mps_preprocess.py:115] Visiting: aten_permute_copy_default_28, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:28,860 mps_preprocess.py:115] Visiting: aten_view_copy_default_85, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,934 mps_preprocess.py:115] Visiting: aten_view_copy_default_46, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,935 mps_preprocess.py:115] Visiting: aten_view_copy_default_47, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,935 mps_preprocess.py:115] Visiting: aten_view_copy_default, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,935 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_7, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:29,936 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_6, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:29,936 mps_preprocess.py:115] Visiting: aten__to_copy_default, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:29,936 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_4, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:29,936 mps_preprocess.py:115] Visiting: aten__to_copy_default_4, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:29,936 mps_preprocess.py:115] Visiting: aten__to_copy_default_5, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:29,937 mps_preprocess.py:115] Visiting: aten__to_copy_default_6, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:29,937 mps_preprocess.py:115] Visiting: aten__to_copy_default_7, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:29,937 mps_preprocess.py:115] Visiting: aten__to_copy_default_9, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:29,937 mps_preprocess.py:115] Visiting: aten__to_copy_default_10, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:29,938 mps_preprocess.py:115] Visiting: aten_expand_copy_default_1, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:29,938 mps_preprocess.py:115] Visiting: aten_expand_copy_default, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:29,938 mps_preprocess.py:115] Visiting: aten_permute_copy_default, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,938 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_5, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:29,939 mps_preprocess.py:115] Visiting: aten_permute_copy_default_8, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,939 mps_preprocess.py:115] Visiting: aten_permute_copy_default_9, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,939 mps_preprocess.py:115] Visiting: aten_permute_copy_default_10, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,939 mps_preprocess.py:115] Visiting: aten_permute_copy_default_11, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,940 mps_preprocess.py:115] Visiting: aten_permute_copy_default_13, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,940 mps_preprocess.py:115] Visiting: aten_permute_copy_default_14, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,940 mps_preprocess.py:115] Visiting: aten_clone_default_1, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:29,940 mps_preprocess.py:115] Visiting: aten_clone_default, aten.clone.default\n",
      "[INFO 2024-05-08 14:39:29,941 mps_preprocess.py:115] Visiting: aten_mm_default, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:29,941 mps_preprocess.py:115] Visiting: aten_index_tensor_2, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:29,941 mps_preprocess.py:115] Visiting: aten_expand_copy_default_7, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:29,941 mps_preprocess.py:115] Visiting: aten_view_copy_default_18, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,941 mps_preprocess.py:115] Visiting: aten_view_copy_default_17, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,941 mps_preprocess.py:115] Visiting: aten_view_copy_default_1, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,942 mps_preprocess.py:115] Visiting: aten__to_copy_default_3, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:29,942 mps_preprocess.py:115] Visiting: aten_view_copy_default_27, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,942 mps_preprocess.py:115] Visiting: aten_expand_copy_default_5, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:29,942 mps_preprocess.py:115] Visiting: aten_permute_copy_default_6, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,942 mps_preprocess.py:115] Visiting: aten_mul_tensor_3, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,943 mps_preprocess.py:115] Visiting: aten_view_copy_default_23, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,943 mps_preprocess.py:115] Visiting: aten_expand_copy_default_3, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:29,943 mps_preprocess.py:115] Visiting: aten_view_copy_default_6, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,943 mps_preprocess.py:115] Visiting: aten_view_copy_default_20, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,944 mps_preprocess.py:115] Visiting: aten_view_copy_default_9, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,944 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:29,944 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_1, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:29,944 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:29,944 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_1, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:29,944 mps_preprocess.py:115] Visiting: aten_mul_tensor_6, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,945 mps_preprocess.py:115] Visiting: aten_mul_tensor_8, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,945 mps_preprocess.py:115] Visiting: aten_mul_tensor_7, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,945 mps_preprocess.py:115] Visiting: aten_mul_tensor_9, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,945 mps_preprocess.py:115] Visiting: aten_sub_tensor, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:29,945 mps_preprocess.py:115] Visiting: aten_add_tensor_1, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:29,946 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:29,946 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_1, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:29,946 mps_preprocess.py:115] Visiting: aten_cat_default, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:29,946 mps_preprocess.py:115] Visiting: aten_view_copy_default_13, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,947 mps_preprocess.py:115] Visiting: aten_permute_copy_default_3, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,947 mps_preprocess.py:115] Visiting: aten_expand_copy_default_2, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:29,947 mps_preprocess.py:115] Visiting: aten_view_copy_default_19, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,947 mps_preprocess.py:115] Visiting: aten_bmm_default, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:29,948 mps_preprocess.py:115] Visiting: aten_view_copy_default_21, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,948 mps_preprocess.py:115] Visiting: aten_mul_tensor_14, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,948 mps_preprocess.py:115] Visiting: aten_add_tensor_3, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:29,948 mps_preprocess.py:115] Visiting: aten__softmax_default, aten._softmax.default\n",
      "[INFO 2024-05-08 14:39:29,948 mps_preprocess.py:115] Visiting: aten_expand_copy_default_4, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:29,949 mps_preprocess.py:115] Visiting: aten_view_copy_default_22, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,949 mps_preprocess.py:115] Visiting: aten_bmm_default_1, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:29,949 mps_preprocess.py:115] Visiting: aten_view_copy_default_24, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,949 mps_preprocess.py:115] Visiting: aten_permute_copy_default_7, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,949 mps_preprocess.py:115] Visiting: aten_view_copy_default_25, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,950 mps_preprocess.py:115] Visiting: aten_expand_copy_default_6, aten.expand_copy.default\n",
      "[INFO 2024-05-08 14:39:29,950 mps_preprocess.py:115] Visiting: aten_view_copy_default_26, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,950 mps_preprocess.py:115] Visiting: aten_bmm_default_2, aten.bmm.default\n",
      "[INFO 2024-05-08 14:39:29,950 mps_preprocess.py:115] Visiting: aten_view_copy_default_28, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,950 mps_preprocess.py:115] Visiting: aten_mul_tensor_15, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,951 mps_preprocess.py:115] Visiting: aten_add_tensor_4, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:29,951 mps_preprocess.py:115] Visiting: aten_mul_tensor_16, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,951 mps_preprocess.py:115] Visiting: aten_mean_dim_1, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:29,951 mps_preprocess.py:115] Visiting: aten_add_tensor_5, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:29,951 mps_preprocess.py:115] Visiting: aten_rsqrt_default_1, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:29,952 mps_preprocess.py:115] Visiting: aten_mul_tensor_17, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,952 mps_preprocess.py:115] Visiting: aten_mul_tensor_18, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,952 mps_preprocess.py:115] Visiting: aten_view_copy_default_29, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,952 mps_preprocess.py:115] Visiting: aten_view_copy_default_31, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,952 mps_preprocess.py:115] Visiting: aten_mm_default_3, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:29,953 mps_preprocess.py:115] Visiting: aten_mm_default_4, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:29,953 mps_preprocess.py:115] Visiting: aten_view_copy_default_30, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,953 mps_preprocess.py:115] Visiting: aten_view_copy_default_32, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,953 mps_preprocess.py:115] Visiting: aten_mul_tensor_19, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,954 mps_preprocess.py:115] Visiting: aten_mul_tensor_21, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,954 mps_preprocess.py:115] Visiting: aten_sigmoid_default, aten.sigmoid.default\n",
      "[INFO 2024-05-08 14:39:29,954 mps_preprocess.py:115] Visiting: aten_mul_tensor_20, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,954 mps_preprocess.py:115] Visiting: aten_mul_tensor_22, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,954 mps_preprocess.py:115] Visiting: aten_view_copy_default_33, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,955 mps_preprocess.py:115] Visiting: aten_mm_default_5, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:29,955 mps_preprocess.py:115] Visiting: aten_view_copy_default_34, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,955 mps_preprocess.py:115] Visiting: aten_mul_tensor_23, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,955 mps_preprocess.py:115] Visiting: aten_add_tensor_6, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:29,956 mps_preprocess.py:115] Visiting: aten_mul_tensor_24, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,956 mps_preprocess.py:115] Visiting: aten_mean_dim_2, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:29,956 mps_preprocess.py:115] Visiting: aten_add_tensor_7, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:29,956 mps_preprocess.py:115] Visiting: aten_rsqrt_default_2, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:29,957 mps_preprocess.py:115] Visiting: aten_mul_tensor_25, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,957 mps_preprocess.py:115] Visiting: aten_mul_tensor_26, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,957 mps_preprocess.py:115] Visiting: aten_view_copy_default_37, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,957 mps_preprocess.py:115] Visiting: aten_view_copy_default_39, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,957 mps_preprocess.py:115] Visiting: aten_mm_default_7, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:29,958 mps_preprocess.py:115] Visiting: aten_mm_default_8, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:29,958 mps_preprocess.py:115] Visiting: aten_view_copy_default_38, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,958 mps_preprocess.py:115] Visiting: aten_view_copy_default_40, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,958 mps_preprocess.py:115] Visiting: aten_mul_tensor_28, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,959 mps_preprocess.py:115] Visiting: aten_mul_tensor_29, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,959 mps_preprocess.py:115] Visiting: aten_view_copy_default_42, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,959 mps_preprocess.py:115] Visiting: aten_view_copy_default_43, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,960 mps_preprocess.py:115] Visiting: aten_view_copy_default_45, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,960 mps_preprocess.py:115] Visiting: aten_permute_copy_default_17, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,960 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_6, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:29,960 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_7, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:29,961 mps_preprocess.py:115] Visiting: aten_view_copy_default_51, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,961 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_6, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:29,961 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_7, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:29,961 mps_preprocess.py:115] Visiting: aten_mul_tensor_34, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,961 mps_preprocess.py:115] Visiting: aten_mul_tensor_36, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,961 mps_preprocess.py:115] Visiting: aten_mul_tensor_35, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,962 mps_preprocess.py:115] Visiting: aten_mul_tensor_37, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:29,962 mps_preprocess.py:115] Visiting: aten_sub_tensor_3, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:29,962 mps_preprocess.py:115] Visiting: aten_add_tensor_9, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:29,963 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_10, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:29,963 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_11, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:29,963 mps_preprocess.py:115] Visiting: aten_cat_default_3, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:29,963 mps_preprocess.py:115] Visiting: aten_view_copy_default_49, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:29,963 mps_preprocess.py:115] Visiting: aten_permute_copy_default_16, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:29,964 mps_preprocess.py:115] Visiting: aten_view_copy_default_50, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,023 mps_preprocess.py:115] Visiting: aten_embedding_default, aten.embedding.default\n",
      "[INFO 2024-05-08 14:39:31,024 mps_preprocess.py:115] Visiting: aten_index_tensor, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:31,024 mps_preprocess.py:115] Visiting: aten_index_tensor_1, aten.index.Tensor\n",
      "[INFO 2024-05-08 14:39:31,025 mps_preprocess.py:115] Visiting: aten__to_copy_default_1, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:31,025 mps_preprocess.py:115] Visiting: aten__to_copy_default_2, aten._to_copy.default\n",
      "[INFO 2024-05-08 14:39:31,025 mps_preprocess.py:115] Visiting: aten_mul_tensor, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,025 mps_preprocess.py:115] Visiting: aten_view_copy_default_11, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,025 mps_preprocess.py:115] Visiting: aten_view_copy_default_12, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,026 mps_preprocess.py:115] Visiting: aten_permute_copy_default_1, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:31,026 mps_preprocess.py:115] Visiting: aten_permute_copy_default_2, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:31,026 mps_preprocess.py:115] Visiting: aten_mean_dim, aten.mean.dim\n",
      "[INFO 2024-05-08 14:39:31,027 mps_preprocess.py:115] Visiting: aten_add_tensor, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:31,027 mps_preprocess.py:115] Visiting: aten_rsqrt_default, aten.rsqrt.default\n",
      "[INFO 2024-05-08 14:39:31,027 mps_preprocess.py:115] Visiting: aten_mul_tensor_1, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,027 mps_preprocess.py:115] Visiting: aten_mul_tensor_2, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,028 mps_preprocess.py:115] Visiting: aten_view_copy_default_2, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,028 mps_preprocess.py:115] Visiting: aten_view_copy_default_4, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,028 mps_preprocess.py:115] Visiting: aten_mm_default_1, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:31,028 mps_preprocess.py:115] Visiting: aten_mm_default_2, aten.mm.default\n",
      "[INFO 2024-05-08 14:39:31,028 mps_preprocess.py:115] Visiting: aten_view_copy_default_3, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,029 mps_preprocess.py:115] Visiting: aten_view_copy_default_5, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,029 mps_preprocess.py:115] Visiting: aten_mul_tensor_4, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,029 mps_preprocess.py:115] Visiting: aten_mul_tensor_5, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,029 mps_preprocess.py:115] Visiting: aten_view_copy_default_7, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,029 mps_preprocess.py:115] Visiting: aten_view_copy_default_8, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,029 mps_preprocess.py:115] Visiting: aten_view_copy_default_10, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,030 mps_preprocess.py:115] Visiting: aten_permute_copy_default_5, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:31,030 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_2, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:31,030 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_3, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 14:39:31,030 mps_preprocess.py:115] Visiting: aten_view_copy_default_16, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,031 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_2, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:31,031 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_3, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 14:39:31,031 mps_preprocess.py:115] Visiting: aten_mul_tensor_10, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,031 mps_preprocess.py:115] Visiting: aten_mul_tensor_12, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,031 mps_preprocess.py:115] Visiting: aten_mul_tensor_11, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,032 mps_preprocess.py:115] Visiting: aten_mul_tensor_13, aten.mul.Tensor\n",
      "[INFO 2024-05-08 14:39:31,032 mps_preprocess.py:115] Visiting: aten_sub_tensor_1, aten.sub.Tensor\n",
      "[INFO 2024-05-08 14:39:31,032 mps_preprocess.py:115] Visiting: aten_add_tensor_2, aten.add.Tensor\n",
      "[INFO 2024-05-08 14:39:31,032 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_2, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:31,033 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_3, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 14:39:31,033 mps_preprocess.py:115] Visiting: aten_cat_default_1, aten.cat.default\n",
      "[INFO 2024-05-08 14:39:31,033 mps_preprocess.py:115] Visiting: aten_view_copy_default_14, aten.view_copy.default\n",
      "[INFO 2024-05-08 14:39:31,033 mps_preprocess.py:115] Visiting: aten_permute_copy_default_4, aten.permute_copy.default\n",
      "[INFO 2024-05-08 14:39:31,033 mps_preprocess.py:115] Visiting: aten_view_copy_default_15, aten.view_copy.default\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/emit/_emitter.py:1474: UserWarning: Mutation on a buffer in the model is detected. ExecuTorch assumes buffers that are mutated in the graph have a meaningless initial state, only the shape and dtype will be serialized.\n",
      "  warnings.warn(\n",
      "[INFO 2024-05-08 14:39:40,094 builder.py:341] Required memory for activation in bytes: [0, 19816448]\n"
     ]
    }
   ],
   "source": [
    "builder = model.export_to_edge(None).to_backend(partitioners).to_executorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %b_layers_0_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_0_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_1_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_1_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_2_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_2_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_3_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_3_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_4_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_4_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_5_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_5_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_6_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_6_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_7_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_7_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_8_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_8_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_9_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_9_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_10_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_10_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_11_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_11_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_v_cache]\n",
      "    %tokens : [num_users=1] = placeholder[target=tokens]\n",
      "    %input_pos : [num_users=37] = placeholder[target=input_pos]\n",
      "    %lowered_module_0 : [num_users=1] = get_attr[target=lowered_module_0]\n",
      "    %executorch_call_delegate : [num_users=8] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_0, %tokens, %input_pos), kwargs = {})\n",
      "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 0), kwargs = {})\n",
      "    %getitem_1 : [num_users=11] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 1), kwargs = {})\n",
      "    %getitem_2 : [num_users=11] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 2), kwargs = {})\n",
      "    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 3), kwargs = {})\n",
      "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 4), kwargs = {})\n",
      "    %getitem_5 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 5), kwargs = {})\n",
      "    %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 6), kwargs = {})\n",
      "    %getitem_7 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 7), kwargs = {})\n",
      "    %alloc : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_6), kwargs = {out: %alloc})\n",
      "    %alloc_1 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_1 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_7), kwargs = {out: %alloc_1})\n",
      "    %alloc_2 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_index_put_default, 1, 0, 9223372036854775807), kwargs = {out: %alloc_2})\n",
      "    %alloc_3 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_1, 1, 0, 9223372036854775807), kwargs = {out: %alloc_3})\n",
      "    %alloc_4 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default, 0, 0, 9223372036854775807), kwargs = {out: %alloc_4})\n",
      "    %alloc_5 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_3 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_1, 0, 0, 9223372036854775807), kwargs = {out: %alloc_5})\n",
      "    %lowered_module_1 : [num_users=1] = get_attr[target=lowered_module_1]\n",
      "    %executorch_call_delegate_1 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_1, %getitem_1, %getitem_2, %getitem_5, %aten_slice_scatter_default_2, %aten_slice_scatter_default_3, %input_pos, %getitem_3, %getitem_4, %getitem), kwargs = {})\n",
      "    %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 0), kwargs = {})\n",
      "    %getitem_9 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 1), kwargs = {})\n",
      "    %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 2), kwargs = {})\n",
      "    %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 3), kwargs = {})\n",
      "    %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 4), kwargs = {})\n",
      "    %getitem_13 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 5), kwargs = {})\n",
      "    %alloc_6 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_2 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_12), kwargs = {out: %alloc_6})\n",
      "    %alloc_7 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_3 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_13), kwargs = {out: %alloc_7})\n",
      "    %alloc_8 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_4 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_2, 1, 0, 9223372036854775807), kwargs = {out: %alloc_8})\n",
      "    %alloc_9 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_3, 1, 0, 9223372036854775807), kwargs = {out: %alloc_9})\n",
      "    %alloc_10 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_6 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_4, 0, 0, 9223372036854775807), kwargs = {out: %alloc_10})\n",
      "    %alloc_11 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_7 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_5, 0, 0, 9223372036854775807), kwargs = {out: %alloc_11})\n",
      "    %lowered_module_2 : [num_users=1] = get_attr[target=lowered_module_2]\n",
      "    %executorch_call_delegate_2 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_2, %getitem_1, %getitem_2, %getitem_11, %aten_slice_scatter_default_6, %aten_slice_scatter_default_7, %input_pos, %getitem_8, %getitem_9, %getitem_10), kwargs = {})\n",
      "    %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 0), kwargs = {})\n",
      "    %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 1), kwargs = {})\n",
      "    %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 2), kwargs = {})\n",
      "    %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 3), kwargs = {})\n",
      "    %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 4), kwargs = {})\n",
      "    %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 5), kwargs = {})\n",
      "    %alloc_12 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_4 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_18), kwargs = {out: %alloc_12})\n",
      "    %alloc_13 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_5 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_19), kwargs = {out: %alloc_13})\n",
      "    %alloc_14 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_4, 1, 0, 9223372036854775807), kwargs = {out: %alloc_14})\n",
      "    %alloc_15 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_9 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_5, 1, 0, 9223372036854775807), kwargs = {out: %alloc_15})\n",
      "    %alloc_16 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_10 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_8, 0, 0, 9223372036854775807), kwargs = {out: %alloc_16})\n",
      "    %alloc_17 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_11 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_9, 0, 0, 9223372036854775807), kwargs = {out: %alloc_17})\n",
      "    %lowered_module_3 : [num_users=1] = get_attr[target=lowered_module_3]\n",
      "    %executorch_call_delegate_3 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_3, %getitem_1, %getitem_2, %getitem_17, %aten_slice_scatter_default_10, %aten_slice_scatter_default_11, %input_pos, %getitem_14, %getitem_15, %getitem_16), kwargs = {})\n",
      "    %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 0), kwargs = {})\n",
      "    %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 1), kwargs = {})\n",
      "    %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 2), kwargs = {})\n",
      "    %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 3), kwargs = {})\n",
      "    %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 4), kwargs = {})\n",
      "    %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 5), kwargs = {})\n",
      "    %alloc_18 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_6 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_24), kwargs = {out: %alloc_18})\n",
      "    %alloc_19 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_7 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_25), kwargs = {out: %alloc_19})\n",
      "    %alloc_20 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_12 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_6, 1, 0, 9223372036854775807), kwargs = {out: %alloc_20})\n",
      "    %alloc_21 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_13 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_7, 1, 0, 9223372036854775807), kwargs = {out: %alloc_21})\n",
      "    %alloc_22 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_14 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_12, 0, 0, 9223372036854775807), kwargs = {out: %alloc_22})\n",
      "    %alloc_23 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_15 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_13, 0, 0, 9223372036854775807), kwargs = {out: %alloc_23})\n",
      "    %lowered_module_4 : [num_users=1] = get_attr[target=lowered_module_4]\n",
      "    %executorch_call_delegate_4 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_4, %getitem_1, %getitem_2, %getitem_23, %aten_slice_scatter_default_14, %aten_slice_scatter_default_15, %input_pos, %getitem_20, %getitem_21, %getitem_22), kwargs = {})\n",
      "    %getitem_26 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 0), kwargs = {})\n",
      "    %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 1), kwargs = {})\n",
      "    %getitem_28 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 2), kwargs = {})\n",
      "    %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 3), kwargs = {})\n",
      "    %getitem_30 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 4), kwargs = {})\n",
      "    %getitem_31 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 5), kwargs = {})\n",
      "    %alloc_24 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_8 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_30), kwargs = {out: %alloc_24})\n",
      "    %alloc_25 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_9 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_31), kwargs = {out: %alloc_25})\n",
      "    %alloc_26 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_16 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_8, 1, 0, 9223372036854775807), kwargs = {out: %alloc_26})\n",
      "    %alloc_27 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_17 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_9, 1, 0, 9223372036854775807), kwargs = {out: %alloc_27})\n",
      "    %alloc_28 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_18 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_16, 0, 0, 9223372036854775807), kwargs = {out: %alloc_28})\n",
      "    %alloc_29 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_19 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_17, 0, 0, 9223372036854775807), kwargs = {out: %alloc_29})\n",
      "    %lowered_module_5 : [num_users=1] = get_attr[target=lowered_module_5]\n",
      "    %executorch_call_delegate_5 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_5, %getitem_1, %getitem_2, %getitem_29, %aten_slice_scatter_default_18, %aten_slice_scatter_default_19, %input_pos, %getitem_26, %getitem_27, %getitem_28), kwargs = {})\n",
      "    %getitem_32 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 0), kwargs = {})\n",
      "    %getitem_33 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 1), kwargs = {})\n",
      "    %getitem_34 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 2), kwargs = {})\n",
      "    %getitem_35 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 3), kwargs = {})\n",
      "    %getitem_36 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 4), kwargs = {})\n",
      "    %getitem_37 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 5), kwargs = {})\n",
      "    %alloc_30 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_10 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_36), kwargs = {out: %alloc_30})\n",
      "    %alloc_31 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_11 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_37), kwargs = {out: %alloc_31})\n",
      "    %alloc_32 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_20 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_10, 1, 0, 9223372036854775807), kwargs = {out: %alloc_32})\n",
      "    %alloc_33 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_21 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_11, 1, 0, 9223372036854775807), kwargs = {out: %alloc_33})\n",
      "    %alloc_34 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_22 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_20, 0, 0, 9223372036854775807), kwargs = {out: %alloc_34})\n",
      "    %alloc_35 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_23 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_21, 0, 0, 9223372036854775807), kwargs = {out: %alloc_35})\n",
      "    %lowered_module_6 : [num_users=1] = get_attr[target=lowered_module_6]\n",
      "    %executorch_call_delegate_6 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_6, %getitem_1, %getitem_2, %getitem_35, %aten_slice_scatter_default_22, %aten_slice_scatter_default_23, %input_pos, %getitem_32, %getitem_33, %getitem_34), kwargs = {})\n",
      "    %getitem_38 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 0), kwargs = {})\n",
      "    %getitem_39 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 1), kwargs = {})\n",
      "    %getitem_40 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 2), kwargs = {})\n",
      "    %getitem_41 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 3), kwargs = {})\n",
      "    %getitem_42 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 4), kwargs = {})\n",
      "    %getitem_43 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 5), kwargs = {})\n",
      "    %alloc_36 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_12 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_42), kwargs = {out: %alloc_36})\n",
      "    %alloc_37 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_13 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_43), kwargs = {out: %alloc_37})\n",
      "    %alloc_38 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_24 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_12, 1, 0, 9223372036854775807), kwargs = {out: %alloc_38})\n",
      "    %alloc_39 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_25 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_13, 1, 0, 9223372036854775807), kwargs = {out: %alloc_39})\n",
      "    %alloc_40 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_26 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_24, 0, 0, 9223372036854775807), kwargs = {out: %alloc_40})\n",
      "    %alloc_41 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_27 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_25, 0, 0, 9223372036854775807), kwargs = {out: %alloc_41})\n",
      "    %lowered_module_7 : [num_users=1] = get_attr[target=lowered_module_7]\n",
      "    %executorch_call_delegate_7 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_7, %getitem_1, %getitem_2, %getitem_41, %aten_slice_scatter_default_26, %aten_slice_scatter_default_27, %input_pos, %getitem_38, %getitem_39, %getitem_40), kwargs = {})\n",
      "    %getitem_44 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 0), kwargs = {})\n",
      "    %getitem_45 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 1), kwargs = {})\n",
      "    %getitem_46 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 2), kwargs = {})\n",
      "    %getitem_47 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 3), kwargs = {})\n",
      "    %getitem_48 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 4), kwargs = {})\n",
      "    %getitem_49 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 5), kwargs = {})\n",
      "    %alloc_42 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_14 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_48), kwargs = {out: %alloc_42})\n",
      "    %alloc_43 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_15 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_49), kwargs = {out: %alloc_43})\n",
      "    %alloc_44 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_28 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_14, 1, 0, 9223372036854775807), kwargs = {out: %alloc_44})\n",
      "    %alloc_45 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_29 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_15, 1, 0, 9223372036854775807), kwargs = {out: %alloc_45})\n",
      "    %alloc_46 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_30 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_28, 0, 0, 9223372036854775807), kwargs = {out: %alloc_46})\n",
      "    %alloc_47 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_31 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_29, 0, 0, 9223372036854775807), kwargs = {out: %alloc_47})\n",
      "    %lowered_module_8 : [num_users=1] = get_attr[target=lowered_module_8]\n",
      "    %executorch_call_delegate_8 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_8, %getitem_1, %getitem_2, %getitem_47, %aten_slice_scatter_default_30, %aten_slice_scatter_default_31, %input_pos, %getitem_44, %getitem_45, %getitem_46), kwargs = {})\n",
      "    %getitem_50 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 0), kwargs = {})\n",
      "    %getitem_51 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 1), kwargs = {})\n",
      "    %getitem_52 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 2), kwargs = {})\n",
      "    %getitem_53 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 3), kwargs = {})\n",
      "    %getitem_54 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 4), kwargs = {})\n",
      "    %getitem_55 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 5), kwargs = {})\n",
      "    %alloc_48 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_16 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_54), kwargs = {out: %alloc_48})\n",
      "    %alloc_49 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_17 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_55), kwargs = {out: %alloc_49})\n",
      "    %alloc_50 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_32 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_16, 1, 0, 9223372036854775807), kwargs = {out: %alloc_50})\n",
      "    %alloc_51 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_33 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_17, 1, 0, 9223372036854775807), kwargs = {out: %alloc_51})\n",
      "    %alloc_52 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_34 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_32, 0, 0, 9223372036854775807), kwargs = {out: %alloc_52})\n",
      "    %alloc_53 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_35 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_33, 0, 0, 9223372036854775807), kwargs = {out: %alloc_53})\n",
      "    %lowered_module_9 : [num_users=1] = get_attr[target=lowered_module_9]\n",
      "    %executorch_call_delegate_9 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_9, %getitem_1, %getitem_2, %getitem_53, %aten_slice_scatter_default_34, %aten_slice_scatter_default_35, %input_pos, %getitem_50, %getitem_51, %getitem_52), kwargs = {})\n",
      "    %getitem_56 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 0), kwargs = {})\n",
      "    %getitem_57 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 1), kwargs = {})\n",
      "    %getitem_58 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 2), kwargs = {})\n",
      "    %getitem_59 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 3), kwargs = {})\n",
      "    %getitem_60 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 4), kwargs = {})\n",
      "    %getitem_61 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 5), kwargs = {})\n",
      "    %alloc_54 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_18 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_60), kwargs = {out: %alloc_54})\n",
      "    %alloc_55 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_19 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_61), kwargs = {out: %alloc_55})\n",
      "    %alloc_56 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_36 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_18, 1, 0, 9223372036854775807), kwargs = {out: %alloc_56})\n",
      "    %alloc_57 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_37 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_19, 1, 0, 9223372036854775807), kwargs = {out: %alloc_57})\n",
      "    %alloc_58 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_38 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_36, 0, 0, 9223372036854775807), kwargs = {out: %alloc_58})\n",
      "    %alloc_59 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_39 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_37, 0, 0, 9223372036854775807), kwargs = {out: %alloc_59})\n",
      "    %lowered_module_10 : [num_users=1] = get_attr[target=lowered_module_10]\n",
      "    %executorch_call_delegate_10 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_10, %getitem_1, %getitem_2, %getitem_59, %aten_slice_scatter_default_38, %aten_slice_scatter_default_39, %input_pos, %getitem_56, %getitem_57, %getitem_58), kwargs = {})\n",
      "    %getitem_62 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 0), kwargs = {})\n",
      "    %getitem_63 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 1), kwargs = {})\n",
      "    %getitem_64 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 2), kwargs = {})\n",
      "    %getitem_65 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 3), kwargs = {})\n",
      "    %getitem_66 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 4), kwargs = {})\n",
      "    %getitem_67 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 5), kwargs = {})\n",
      "    %alloc_60 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_20 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_66), kwargs = {out: %alloc_60})\n",
      "    %alloc_61 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_21 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_67), kwargs = {out: %alloc_61})\n",
      "    %alloc_62 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_40 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_20, 1, 0, 9223372036854775807), kwargs = {out: %alloc_62})\n",
      "    %alloc_63 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_41 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_21, 1, 0, 9223372036854775807), kwargs = {out: %alloc_63})\n",
      "    %alloc_64 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_42 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_40, 0, 0, 9223372036854775807), kwargs = {out: %alloc_64})\n",
      "    %alloc_65 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_43 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_41, 0, 0, 9223372036854775807), kwargs = {out: %alloc_65})\n",
      "    %lowered_module_11 : [num_users=1] = get_attr[target=lowered_module_11]\n",
      "    %executorch_call_delegate_11 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_11, %getitem_1, %getitem_2, %getitem_65, %aten_slice_scatter_default_42, %aten_slice_scatter_default_43, %input_pos, %getitem_62, %getitem_63, %getitem_64), kwargs = {})\n",
      "    %getitem_68 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 0), kwargs = {})\n",
      "    %getitem_69 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 1), kwargs = {})\n",
      "    %getitem_70 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 2), kwargs = {})\n",
      "    %getitem_71 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 3), kwargs = {})\n",
      "    %getitem_72 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 4), kwargs = {})\n",
      "    %getitem_73 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 5), kwargs = {})\n",
      "    %alloc_66 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_22 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_72), kwargs = {out: %alloc_66})\n",
      "    %alloc_67 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_23 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_73), kwargs = {out: %alloc_67})\n",
      "    %alloc_68 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_44 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_22, 1, 0, 9223372036854775807), kwargs = {out: %alloc_68})\n",
      "    %alloc_69 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_45 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_23, 1, 0, 9223372036854775807), kwargs = {out: %alloc_69})\n",
      "    %alloc_70 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_46 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_44, 0, 0, 9223372036854775807), kwargs = {out: %alloc_70})\n",
      "    %alloc_71 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_47 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_45, 0, 0, 9223372036854775807), kwargs = {out: %alloc_71})\n",
      "    %lowered_module_12 : [num_users=1] = get_attr[target=lowered_module_12]\n",
      "    %executorch_call_delegate_12 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_12, %getitem_71, %aten_slice_scatter_default_47, %aten_slice_scatter_default_46, %input_pos, %getitem_68, %getitem_69, %getitem_70), kwargs = {})\n",
      "    %getitem_74 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_12, 0), kwargs = {})\n",
      "    %copy_ : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_3), kwargs = {})\n",
      "    %copy__1 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_2), kwargs = {})\n",
      "    %copy__2 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_7), kwargs = {})\n",
      "    %copy__3 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_6), kwargs = {})\n",
      "    %copy__4 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_11), kwargs = {})\n",
      "    %copy__5 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_10), kwargs = {})\n",
      "    %copy__6 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_15), kwargs = {})\n",
      "    %copy__7 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_14), kwargs = {})\n",
      "    %copy__8 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_19), kwargs = {})\n",
      "    %copy__9 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_18), kwargs = {})\n",
      "    %copy__10 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_23), kwargs = {})\n",
      "    %copy__11 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_22), kwargs = {})\n",
      "    %copy__12 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_27), kwargs = {})\n",
      "    %copy__13 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_26), kwargs = {})\n",
      "    %copy__14 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_31), kwargs = {})\n",
      "    %copy__15 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_30), kwargs = {})\n",
      "    %copy__16 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_35), kwargs = {})\n",
      "    %copy__17 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_34), kwargs = {})\n",
      "    %copy__18 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_39), kwargs = {})\n",
      "    %copy__19 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_38), kwargs = {})\n",
      "    %copy__20 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_43), kwargs = {})\n",
      "    %copy__21 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_42), kwargs = {})\n",
      "    %copy__22 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_47), kwargs = {})\n",
      "    %copy__23 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_46), kwargs = {})\n",
      "    return (getitem_74,)\n"
     ]
    }
   ],
   "source": [
    "print(model.edge_manager._edge_programs['forward'].graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "  %b_layers_0_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_0_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_1_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_1_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_2_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_2_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_3_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_3_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_4_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_4_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_5_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_5_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_6_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_6_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_7_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_7_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_8_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_8_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_9_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_9_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_10_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_10_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_11_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_11_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_v_cache]\n",
      "  %tokens : [num_users=1] = placeholder[target=tokens]\n",
      "  %input_pos : [num_users=37] = placeholder[target=input_pos]\n",
      "  %lowered_module_0 : [num_users=1] = get_attr[target=lowered_module_0]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_tok_embeddings_weight : [num_users=1] = placeholder[target=p_tok_embeddings_weight]\n",
      "      %p_layers_0_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_0_attention_norm_weight]\n",
      "      %b_freqs_cos : [num_users=1] = placeholder[target=b_freqs_cos]\n",
      "      %b_freqs_sin : [num_users=1] = placeholder[target=b_freqs_sin]\n",
      "      %b_layers_0_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_0_attention_wk_weight]\n",
      "      %b_layers_0_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_0_attention_wk_scales]\n",
      "      %b_layers_0_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_0_attention_wv_weight]\n",
      "      %b_layers_0_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_0_attention_wv_scales]\n",
      "      %_lifted_tensor_constant208 : [num_users=1] = placeholder[target=_lifted_tensor_constant208]\n",
      "      %tokens : [num_users=1] = placeholder[target=tokens]\n",
      "      %input_pos : [num_users=2] = placeholder[target=input_pos]\n",
      "      %aten_embedding_default : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.embedding.default](args = (%p_tok_embeddings_weight, %tokens), kwargs = {})\n",
      "      %aten_index_tensor : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%b_freqs_cos, [%input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_1 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%b_freqs_sin, [%input_pos]), kwargs = {})\n",
      "      %aten__to_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_0_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_0_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_mul_tensor : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_embedding_default, %aten_embedding_default), kwargs = {})\n",
      "      %aten_view_copy_default_5 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_6 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_permute_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_1, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_2, [1, 0]), kwargs = {})\n",
      "      %aten_mean_dim : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim, %_lifted_tensor_constant208), kwargs = {})\n",
      "      %aten_rsqrt_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor,), kwargs = {})\n",
      "      %aten_mul_tensor_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_embedding_default, %aten_rsqrt_default), kwargs = {})\n",
      "      %aten_mul_tensor_2 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_1, %p_layers_0_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_2, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_2, [0]), kwargs = {})\n",
      "      %aten_mm_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_1, %aten_permute_copy_default_1), kwargs = {})\n",
      "      %aten_mm_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_2, %aten_permute_copy_default_2), kwargs = {})\n",
      "      %aten_mul_tensor_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_1, %b_layers_0_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_2, %b_layers_0_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_4, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_5, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_4 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_1, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_2, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_4, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_4, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_5, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_5 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_2, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_6 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_3, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_5, %aten_view_copy_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_5, %aten_view_copy_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_6, %aten_view_copy_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_6, %aten_view_copy_default_5), kwargs = {})\n",
      "      %aten_sub_tensor_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_10, %aten_mul_tensor_11), kwargs = {})\n",
      "      %aten_add_tensor_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_12, %aten_mul_tensor_13), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_1, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_2, 4), kwargs = {})\n",
      "      %aten_cat_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_2, %aten_unsqueeze_copy_default_3], -1), kwargs = {})\n",
      "      %aten_view_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_1, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_8, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_4, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_embedding_default, aten_index_tensor, aten_index_tensor_1, aten_view_copy_default_5, aten_view_copy_default_6, aten_mul_tensor_2, aten_view_copy_default_10, aten_view_copy_default_9)\n",
      "  %executorch_call_delegate : [num_users=8] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_0, %tokens, %input_pos), kwargs = {})\n",
      "  %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 0), kwargs = {})\n",
      "  %getitem_1 : [num_users=11] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 1), kwargs = {})\n",
      "  %getitem_2 : [num_users=11] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 2), kwargs = {})\n",
      "  %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 3), kwargs = {})\n",
      "  %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 4), kwargs = {})\n",
      "  %getitem_5 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 5), kwargs = {})\n",
      "  %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 6), kwargs = {})\n",
      "  %getitem_7 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 7), kwargs = {})\n",
      "  %alloc : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_6), kwargs = {out: %alloc})\n",
      "  %alloc_1 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_1 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_7), kwargs = {out: %alloc_1})\n",
      "  %alloc_2 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_index_put_default, 1, 0, 9223372036854775807), kwargs = {out: %alloc_2})\n",
      "  %alloc_3 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_1, 1, 0, 9223372036854775807), kwargs = {out: %alloc_3})\n",
      "  %alloc_4 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default, 0, 0, 9223372036854775807), kwargs = {out: %alloc_4})\n",
      "  %alloc_5 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_3 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_1, 0, 0, 9223372036854775807), kwargs = {out: %alloc_5})\n",
      "  %lowered_module_1 : [num_users=1] = get_attr[target=lowered_module_1]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_0_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_0_ffn_norm_weight]\n",
      "      %p_layers_1_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_1_attention_norm_weight]\n",
      "      %b_layers_0_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_0_attention_wq_weight]\n",
      "      %b_layers_0_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_0_attention_wq_scales]\n",
      "      %b_layers_0_attention_mask : [num_users=1] = placeholder[target=b_layers_0_attention_mask]\n",
      "      %b_layers_0_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_0_attention_wo_weight]\n",
      "      %b_layers_0_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_0_attention_wo_scales]\n",
      "      %b_layers_0_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w1_weight]\n",
      "      %b_layers_0_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w1_scales]\n",
      "      %b_layers_0_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w3_weight]\n",
      "      %b_layers_0_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w3_scales]\n",
      "      %b_layers_0_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w2_weight]\n",
      "      %b_layers_0_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w2_scales]\n",
      "      %b_layers_1_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_1_attention_wk_weight]\n",
      "      %b_layers_1_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_1_attention_wk_scales]\n",
      "      %b_layers_1_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_1_attention_wv_weight]\n",
      "      %b_layers_1_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_1_attention_wv_scales]\n",
      "      %_lifted_tensor_constant209 : [num_users=1] = placeholder[target=_lifted_tensor_constant209]\n",
      "      %_lifted_tensor_constant210 : [num_users=1] = placeholder[target=_lifted_tensor_constant210]\n",
      "      %_lifted_tensor_constant211 : [num_users=1] = placeholder[target=_lifted_tensor_constant211]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_2 : [num_users=1] = placeholder[target=aten_mul_tensor_2]\n",
      "      %aten_slice_scatter_default_3 : [num_users=1] = placeholder[target=aten_slice_scatter_default_3]\n",
      "      %aten_slice_scatter_default_1 : [num_users=1] = placeholder[target=aten_slice_scatter_default_1]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_5 : [num_users=2] = placeholder[target=aten_view_copy_default_5]\n",
      "      %aten_view_copy_default_6 : [num_users=2] = placeholder[target=aten_view_copy_default_6]\n",
      "      %aten_embedding_default : [num_users=1] = placeholder[target=aten_embedding_default]\n",
      "      %aten_view_copy_default_25 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_26 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_2, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_3, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_1, 2), kwargs = {})\n",
      "      %aten__to_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_0_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_0_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_0_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_0_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_0_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_0_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_1_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_1_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_7, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_6, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_4, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_4, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_5, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_6, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_7, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_9, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_10, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_1,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims, %aten_permute_copy_default), kwargs = {})\n",
      "      %aten_index_tensor_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_5, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_1, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default, %b_layers_0_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_2,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_12, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_11, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_3, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_5, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_6, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_3 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_3, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_3, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_3, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_3 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_4 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_1, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_3, %aten_view_copy_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_3, %aten_view_copy_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_4, %aten_view_copy_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_4, %aten_view_copy_default_5), kwargs = {})\n",
      "      %aten_sub_tensor : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_6, %aten_mul_tensor_7), kwargs = {})\n",
      "      %aten_add_tensor_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_8, %aten_mul_tensor_9), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_1, 4), kwargs = {})\n",
      "      %aten_cat_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default, %aten_unsqueeze_copy_default_1], -1), kwargs = {})\n",
      "      %aten_view_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_7, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_3, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_2, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_13, %aten_view_copy_default_14), kwargs = {})\n",
      "      %aten_view_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_15, %_lifted_tensor_constant209), kwargs = {})\n",
      "      %aten_add_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_14, %aten__to_copy_default_3), kwargs = {})\n",
      "      %aten__softmax_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_3, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_4, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_16, %aten_view_copy_default_17), kwargs = {})\n",
      "      %aten_view_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_1, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_18, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_7, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_19, [0]), kwargs = {})\n",
      "      %aten_mm_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_7, %aten_permute_copy_default_8), kwargs = {})\n",
      "      %aten_mul_tensor_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_3, %b_layers_0_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_4 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_embedding_default, %aten_mul_tensor_15), kwargs = {})\n",
      "      %aten_mul_tensor_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_4, %aten_add_tensor_4), kwargs = {})\n",
      "      %aten_mean_dim_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_16, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_1, %_lifted_tensor_constant210), kwargs = {})\n",
      "      %aten_rsqrt_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_5,), kwargs = {})\n",
      "      %aten_mul_tensor_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_4, %aten_rsqrt_default_1), kwargs = {})\n",
      "      %aten_mul_tensor_18 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_17, %p_layers_0_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_18, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_18, [0]), kwargs = {})\n",
      "      %aten_mm_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_8, %aten_permute_copy_default_9), kwargs = {})\n",
      "      %aten_mm_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_9, %aten_permute_copy_default_10), kwargs = {})\n",
      "      %aten_mul_tensor_19 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_4, %b_layers_0_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_5, %b_layers_0_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_19,), kwargs = {})\n",
      "      %aten_mul_tensor_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_19, %aten_sigmoid_default), kwargs = {})\n",
      "      %aten_mul_tensor_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_20, %aten_mul_tensor_21), kwargs = {})\n",
      "      %aten_mm_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_22, %aten_permute_copy_default_11), kwargs = {})\n",
      "      %aten_mul_tensor_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_6, %b_layers_0_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_6 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_4, %aten_mul_tensor_23), kwargs = {})\n",
      "      %aten_mul_tensor_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_6, %aten_add_tensor_6), kwargs = {})\n",
      "      %aten_mean_dim_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_24, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_2, %_lifted_tensor_constant211), kwargs = {})\n",
      "      %aten_rsqrt_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_7,), kwargs = {})\n",
      "      %aten_mul_tensor_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_6, %aten_rsqrt_default_2), kwargs = {})\n",
      "      %aten_mul_tensor_26 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_25, %p_layers_1_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_26, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_26, [0]), kwargs = {})\n",
      "      %aten_mm_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_11, %aten_permute_copy_default_13), kwargs = {})\n",
      "      %aten_mm_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_12, %aten_permute_copy_default_14), kwargs = {})\n",
      "      %aten_mul_tensor_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_8, %b_layers_1_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_9, %b_layers_1_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_28, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_29, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_24 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_21, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_22, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_24, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_24, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_17, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_15 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_6, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_16 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_7, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_15, %aten_view_copy_default_25), kwargs = {})\n",
      "      %aten_mul_tensor_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_15, %aten_view_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_16, %aten_view_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_16, %aten_view_copy_default_25), kwargs = {})\n",
      "      %aten_sub_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_34, %aten_mul_tensor_35), kwargs = {})\n",
      "      %aten_add_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_36, %aten_mul_tensor_37), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_3, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_9, 4), kwargs = {})\n",
      "      %aten_cat_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_10, %aten_unsqueeze_copy_default_11], -1), kwargs = {})\n",
      "      %aten_view_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_3, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_28, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_16, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_25, aten_view_copy_default_26, aten_add_tensor_6, aten_mul_tensor_26, aten_view_copy_default_30, aten_view_copy_default_29)\n",
      "  %executorch_call_delegate_1 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_1, %getitem_1, %getitem_2, %getitem_5, %aten_slice_scatter_default_2, %aten_slice_scatter_default_3, %input_pos, %getitem_3, %getitem_4, %getitem), kwargs = {})\n",
      "  %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 0), kwargs = {})\n",
      "  %getitem_9 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 1), kwargs = {})\n",
      "  %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 2), kwargs = {})\n",
      "  %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 3), kwargs = {})\n",
      "  %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 4), kwargs = {})\n",
      "  %getitem_13 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 5), kwargs = {})\n",
      "  %alloc_6 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_2 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_12), kwargs = {out: %alloc_6})\n",
      "  %alloc_7 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_3 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_13), kwargs = {out: %alloc_7})\n",
      "  %alloc_8 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_4 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_2, 1, 0, 9223372036854775807), kwargs = {out: %alloc_8})\n",
      "  %alloc_9 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_3, 1, 0, 9223372036854775807), kwargs = {out: %alloc_9})\n",
      "  %alloc_10 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_6 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_4, 0, 0, 9223372036854775807), kwargs = {out: %alloc_10})\n",
      "  %alloc_11 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_7 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_5, 0, 0, 9223372036854775807), kwargs = {out: %alloc_11})\n",
      "  %lowered_module_2 : [num_users=1] = get_attr[target=lowered_module_2]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_1_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_1_ffn_norm_weight]\n",
      "      %p_layers_2_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_2_attention_norm_weight]\n",
      "      %b_layers_1_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_1_attention_wq_weight]\n",
      "      %b_layers_1_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_1_attention_wq_scales]\n",
      "      %b_layers_1_attention_mask : [num_users=1] = placeholder[target=b_layers_1_attention_mask]\n",
      "      %b_layers_1_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_1_attention_wo_weight]\n",
      "      %b_layers_1_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_1_attention_wo_scales]\n",
      "      %b_layers_1_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w1_weight]\n",
      "      %b_layers_1_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w1_scales]\n",
      "      %b_layers_1_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w3_weight]\n",
      "      %b_layers_1_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w3_scales]\n",
      "      %b_layers_1_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w2_weight]\n",
      "      %b_layers_1_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w2_scales]\n",
      "      %b_layers_2_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_2_attention_wk_weight]\n",
      "      %b_layers_2_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_2_attention_wk_scales]\n",
      "      %b_layers_2_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_2_attention_wv_weight]\n",
      "      %b_layers_2_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_2_attention_wv_scales]\n",
      "      %_lifted_tensor_constant212 : [num_users=1] = placeholder[target=_lifted_tensor_constant212]\n",
      "      %_lifted_tensor_constant213 : [num_users=1] = placeholder[target=_lifted_tensor_constant213]\n",
      "      %_lifted_tensor_constant214 : [num_users=1] = placeholder[target=_lifted_tensor_constant214]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_26 : [num_users=1] = placeholder[target=aten_mul_tensor_26]\n",
      "      %aten_slice_scatter_default_7 : [num_users=1] = placeholder[target=aten_slice_scatter_default_7]\n",
      "      %aten_slice_scatter_default_5 : [num_users=1] = placeholder[target=aten_slice_scatter_default_5]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_25 : [num_users=2] = placeholder[target=aten_view_copy_default_25]\n",
      "      %aten_view_copy_default_26 : [num_users=2] = placeholder[target=aten_view_copy_default_26]\n",
      "      %aten_add_tensor_6 : [num_users=1] = placeholder[target=aten_add_tensor_6]\n",
      "      %aten_view_copy_default_45 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_46 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_26, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_7, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_5, 2), kwargs = {})\n",
      "      %aten__to_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_1_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_1_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_1_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_1_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_1_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_1_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_2_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_2_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_15, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_14, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_8, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_12, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_12, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_13, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_14, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_15, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_17, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_18, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_7,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_6,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_10, %aten_permute_copy_default_12), kwargs = {})\n",
      "      %aten_index_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_13, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_3, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_2, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_7, %b_layers_1_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_3,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_32, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_31, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_27, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_11, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_18, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_23 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_20, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_9, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_23, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_23, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_13 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_4, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_14 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_5, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_13, %aten_view_copy_default_25), kwargs = {})\n",
      "      %aten_mul_tensor_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_13, %aten_view_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_14, %aten_view_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_14, %aten_view_copy_default_25), kwargs = {})\n",
      "      %aten_sub_tensor_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_30, %aten_mul_tensor_31), kwargs = {})\n",
      "      %aten_add_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_32, %aten_mul_tensor_33), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_2, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_8, 4), kwargs = {})\n",
      "      %aten_cat_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_8, %aten_unsqueeze_copy_default_9], -1), kwargs = {})\n",
      "      %aten_view_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_2, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_27, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_15, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_8, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_33, %aten_view_copy_default_34), kwargs = {})\n",
      "      %aten_view_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_2, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_35, %_lifted_tensor_constant212), kwargs = {})\n",
      "      %aten_add_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_38, %aten__to_copy_default_11), kwargs = {})\n",
      "      %aten__softmax_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_10, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_1, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_10, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_36, %aten_view_copy_default_37), kwargs = {})\n",
      "      %aten_view_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_3, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_38, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_19, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_39, [0]), kwargs = {})\n",
      "      %aten_mm_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_17, %aten_permute_copy_default_20), kwargs = {})\n",
      "      %aten_mul_tensor_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_10, %b_layers_1_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_11 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_6, %aten_mul_tensor_39), kwargs = {})\n",
      "      %aten_mul_tensor_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_11, %aten_add_tensor_11), kwargs = {})\n",
      "      %aten_mean_dim_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_40, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_3, %_lifted_tensor_constant213), kwargs = {})\n",
      "      %aten_rsqrt_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_12,), kwargs = {})\n",
      "      %aten_mul_tensor_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_11, %aten_rsqrt_default_3), kwargs = {})\n",
      "      %aten_mul_tensor_42 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_41, %p_layers_1_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_42, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_42, [0]), kwargs = {})\n",
      "      %aten_mm_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_18, %aten_permute_copy_default_21), kwargs = {})\n",
      "      %aten_mm_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_19, %aten_permute_copy_default_22), kwargs = {})\n",
      "      %aten_mul_tensor_43 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_11, %b_layers_1_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_12, %b_layers_1_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_43,), kwargs = {})\n",
      "      %aten_mul_tensor_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_43, %aten_sigmoid_default_1), kwargs = {})\n",
      "      %aten_mul_tensor_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_44, %aten_mul_tensor_45), kwargs = {})\n",
      "      %aten_mm_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_46, %aten_permute_copy_default_23), kwargs = {})\n",
      "      %aten_mul_tensor_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_13, %b_layers_1_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_13 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_11, %aten_mul_tensor_47), kwargs = {})\n",
      "      %aten_mul_tensor_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_13, %aten_add_tensor_13), kwargs = {})\n",
      "      %aten_mean_dim_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_48, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_4, %_lifted_tensor_constant214), kwargs = {})\n",
      "      %aten_rsqrt_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_14,), kwargs = {})\n",
      "      %aten_mul_tensor_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_13, %aten_rsqrt_default_4), kwargs = {})\n",
      "      %aten_mul_tensor_50 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_49, %p_layers_2_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_50, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_50, [0]), kwargs = {})\n",
      "      %aten_mm_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_21, %aten_permute_copy_default_25), kwargs = {})\n",
      "      %aten_mm_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_22, %aten_permute_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_15, %b_layers_2_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_16, %b_layers_2_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_52, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_53, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_44 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_41, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_42, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_44, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_44, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_29, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_25 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_10, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_26 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_11, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_25, %aten_view_copy_default_45), kwargs = {})\n",
      "      %aten_mul_tensor_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_25, %aten_view_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_26, %aten_view_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_26, %aten_view_copy_default_45), kwargs = {})\n",
      "      %aten_sub_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_58, %aten_mul_tensor_59), kwargs = {})\n",
      "      %aten_add_tensor_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_60, %aten_mul_tensor_61), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_5, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_16, 4), kwargs = {})\n",
      "      %aten_cat_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_18, %aten_unsqueeze_copy_default_19], -1), kwargs = {})\n",
      "      %aten_view_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_5, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_48, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_28, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_45, aten_view_copy_default_46, aten_add_tensor_13, aten_mul_tensor_50, aten_view_copy_default_50, aten_view_copy_default_49)\n",
      "  %executorch_call_delegate_2 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_2, %getitem_1, %getitem_2, %getitem_11, %aten_slice_scatter_default_6, %aten_slice_scatter_default_7, %input_pos, %getitem_8, %getitem_9, %getitem_10), kwargs = {})\n",
      "  %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 0), kwargs = {})\n",
      "  %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 1), kwargs = {})\n",
      "  %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 2), kwargs = {})\n",
      "  %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 3), kwargs = {})\n",
      "  %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 4), kwargs = {})\n",
      "  %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 5), kwargs = {})\n",
      "  %alloc_12 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_4 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_18), kwargs = {out: %alloc_12})\n",
      "  %alloc_13 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_5 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_19), kwargs = {out: %alloc_13})\n",
      "  %alloc_14 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_4, 1, 0, 9223372036854775807), kwargs = {out: %alloc_14})\n",
      "  %alloc_15 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_9 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_5, 1, 0, 9223372036854775807), kwargs = {out: %alloc_15})\n",
      "  %alloc_16 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_10 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_8, 0, 0, 9223372036854775807), kwargs = {out: %alloc_16})\n",
      "  %alloc_17 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_11 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_9, 0, 0, 9223372036854775807), kwargs = {out: %alloc_17})\n",
      "  %lowered_module_3 : [num_users=1] = get_attr[target=lowered_module_3]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_2_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_2_ffn_norm_weight]\n",
      "      %p_layers_3_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_3_attention_norm_weight]\n",
      "      %b_layers_2_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_2_attention_wq_weight]\n",
      "      %b_layers_2_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_2_attention_wq_scales]\n",
      "      %b_layers_2_attention_mask : [num_users=1] = placeholder[target=b_layers_2_attention_mask]\n",
      "      %b_layers_2_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_2_attention_wo_weight]\n",
      "      %b_layers_2_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_2_attention_wo_scales]\n",
      "      %b_layers_2_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w1_weight]\n",
      "      %b_layers_2_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w1_scales]\n",
      "      %b_layers_2_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w3_weight]\n",
      "      %b_layers_2_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w3_scales]\n",
      "      %b_layers_2_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w2_weight]\n",
      "      %b_layers_2_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w2_scales]\n",
      "      %b_layers_3_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_3_attention_wk_weight]\n",
      "      %b_layers_3_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_3_attention_wk_scales]\n",
      "      %b_layers_3_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_3_attention_wv_weight]\n",
      "      %b_layers_3_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_3_attention_wv_scales]\n",
      "      %_lifted_tensor_constant215 : [num_users=1] = placeholder[target=_lifted_tensor_constant215]\n",
      "      %_lifted_tensor_constant216 : [num_users=1] = placeholder[target=_lifted_tensor_constant216]\n",
      "      %_lifted_tensor_constant217 : [num_users=1] = placeholder[target=_lifted_tensor_constant217]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_50 : [num_users=1] = placeholder[target=aten_mul_tensor_50]\n",
      "      %aten_slice_scatter_default_11 : [num_users=1] = placeholder[target=aten_slice_scatter_default_11]\n",
      "      %aten_slice_scatter_default_9 : [num_users=1] = placeholder[target=aten_slice_scatter_default_9]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_45 : [num_users=2] = placeholder[target=aten_view_copy_default_45]\n",
      "      %aten_view_copy_default_46 : [num_users=2] = placeholder[target=aten_view_copy_default_46]\n",
      "      %aten_add_tensor_13 : [num_users=1] = placeholder[target=aten_add_tensor_13]\n",
      "      %aten_view_copy_default_65 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_66 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_50, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_11, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_9, 2), kwargs = {})\n",
      "      %aten__to_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_2_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_2_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_2_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_2_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_2_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_2_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_3_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_3_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_23, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_22, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_16, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_20, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_20, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_21, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_22, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_23, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_25, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_26, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_13,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_12,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_20, %aten_permute_copy_default_24), kwargs = {})\n",
      "      %aten_index_tensor_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_21, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_5, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_4, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_14, %b_layers_2_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_4,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_52, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_51, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_51, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_17, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_30, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_43 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_40, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_15, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_43, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_43, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_23 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_8, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_24 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_9, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_23, %aten_view_copy_default_45), kwargs = {})\n",
      "      %aten_mul_tensor_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_23, %aten_view_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_24, %aten_view_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_24, %aten_view_copy_default_45), kwargs = {})\n",
      "      %aten_sub_tensor_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_54, %aten_mul_tensor_55), kwargs = {})\n",
      "      %aten_add_tensor_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_56, %aten_mul_tensor_57), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_4, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_15, 4), kwargs = {})\n",
      "      %aten_cat_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_16, %aten_unsqueeze_copy_default_17], -1), kwargs = {})\n",
      "      %aten_view_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_4, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_47, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_27, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_14, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_53, %aten_view_copy_default_54), kwargs = {})\n",
      "      %aten_view_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_4, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_55, %_lifted_tensor_constant215), kwargs = {})\n",
      "      %aten_add_tensor_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_62, %aten__to_copy_default_19), kwargs = {})\n",
      "      %aten__softmax_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_17, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_2, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_16, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_56, %aten_view_copy_default_57), kwargs = {})\n",
      "      %aten_view_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_5, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_58, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_31, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_59, [0]), kwargs = {})\n",
      "      %aten_mm_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_27, %aten_permute_copy_default_32), kwargs = {})\n",
      "      %aten_mul_tensor_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_17, %b_layers_2_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_18 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_13, %aten_mul_tensor_63), kwargs = {})\n",
      "      %aten_mul_tensor_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_18, %aten_add_tensor_18), kwargs = {})\n",
      "      %aten_mean_dim_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_64, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_5, %_lifted_tensor_constant216), kwargs = {})\n",
      "      %aten_rsqrt_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_19,), kwargs = {})\n",
      "      %aten_mul_tensor_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_18, %aten_rsqrt_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_66 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_65, %p_layers_2_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_66, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_66, [0]), kwargs = {})\n",
      "      %aten_mm_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_28, %aten_permute_copy_default_33), kwargs = {})\n",
      "      %aten_mm_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_29, %aten_permute_copy_default_34), kwargs = {})\n",
      "      %aten_mul_tensor_67 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_18, %b_layers_2_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_19, %b_layers_2_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_67,), kwargs = {})\n",
      "      %aten_mul_tensor_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_67, %aten_sigmoid_default_2), kwargs = {})\n",
      "      %aten_mul_tensor_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_68, %aten_mul_tensor_69), kwargs = {})\n",
      "      %aten_mm_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_70, %aten_permute_copy_default_35), kwargs = {})\n",
      "      %aten_mul_tensor_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_20, %b_layers_2_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_20 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_18, %aten_mul_tensor_71), kwargs = {})\n",
      "      %aten_mul_tensor_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_20, %aten_add_tensor_20), kwargs = {})\n",
      "      %aten_mean_dim_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_72, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_6, %_lifted_tensor_constant217), kwargs = {})\n",
      "      %aten_rsqrt_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_21,), kwargs = {})\n",
      "      %aten_mul_tensor_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_20, %aten_rsqrt_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_74 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_73, %p_layers_3_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_74, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_74, [0]), kwargs = {})\n",
      "      %aten_mm_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_31, %aten_permute_copy_default_37), kwargs = {})\n",
      "      %aten_mm_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_32, %aten_permute_copy_default_38), kwargs = {})\n",
      "      %aten_mul_tensor_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_22, %b_layers_3_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_23, %b_layers_3_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_76, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_77, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_64 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_61, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_62, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_64, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_64, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_41, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_35 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_14, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_36 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_15, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_35, %aten_view_copy_default_65), kwargs = {})\n",
      "      %aten_mul_tensor_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_35, %aten_view_copy_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_36, %aten_view_copy_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_85 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_36, %aten_view_copy_default_65), kwargs = {})\n",
      "      %aten_sub_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_82, %aten_mul_tensor_83), kwargs = {})\n",
      "      %aten_add_tensor_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_84, %aten_mul_tensor_85), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_7, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_23, 4), kwargs = {})\n",
      "      %aten_cat_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_26, %aten_unsqueeze_copy_default_27], -1), kwargs = {})\n",
      "      %aten_view_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_7, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_68, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_40, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_65, aten_view_copy_default_66, aten_add_tensor_20, aten_mul_tensor_74, aten_view_copy_default_70, aten_view_copy_default_69)\n",
      "  %executorch_call_delegate_3 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_3, %getitem_1, %getitem_2, %getitem_17, %aten_slice_scatter_default_10, %aten_slice_scatter_default_11, %input_pos, %getitem_14, %getitem_15, %getitem_16), kwargs = {})\n",
      "  %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 0), kwargs = {})\n",
      "  %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 1), kwargs = {})\n",
      "  %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 2), kwargs = {})\n",
      "  %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 3), kwargs = {})\n",
      "  %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 4), kwargs = {})\n",
      "  %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 5), kwargs = {})\n",
      "  %alloc_18 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_6 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_24), kwargs = {out: %alloc_18})\n",
      "  %alloc_19 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_7 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_25), kwargs = {out: %alloc_19})\n",
      "  %alloc_20 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_12 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_6, 1, 0, 9223372036854775807), kwargs = {out: %alloc_20})\n",
      "  %alloc_21 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_13 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_7, 1, 0, 9223372036854775807), kwargs = {out: %alloc_21})\n",
      "  %alloc_22 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_14 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_12, 0, 0, 9223372036854775807), kwargs = {out: %alloc_22})\n",
      "  %alloc_23 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_15 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_13, 0, 0, 9223372036854775807), kwargs = {out: %alloc_23})\n",
      "  %lowered_module_4 : [num_users=1] = get_attr[target=lowered_module_4]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_3_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_3_ffn_norm_weight]\n",
      "      %p_layers_4_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_4_attention_norm_weight]\n",
      "      %b_layers_3_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_3_attention_wq_weight]\n",
      "      %b_layers_3_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_3_attention_wq_scales]\n",
      "      %b_layers_3_attention_mask : [num_users=1] = placeholder[target=b_layers_3_attention_mask]\n",
      "      %b_layers_3_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_3_attention_wo_weight]\n",
      "      %b_layers_3_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_3_attention_wo_scales]\n",
      "      %b_layers_3_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w1_weight]\n",
      "      %b_layers_3_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w1_scales]\n",
      "      %b_layers_3_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w3_weight]\n",
      "      %b_layers_3_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w3_scales]\n",
      "      %b_layers_3_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w2_weight]\n",
      "      %b_layers_3_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w2_scales]\n",
      "      %b_layers_4_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_4_attention_wk_weight]\n",
      "      %b_layers_4_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_4_attention_wk_scales]\n",
      "      %b_layers_4_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_4_attention_wv_weight]\n",
      "      %b_layers_4_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_4_attention_wv_scales]\n",
      "      %_lifted_tensor_constant218 : [num_users=1] = placeholder[target=_lifted_tensor_constant218]\n",
      "      %_lifted_tensor_constant219 : [num_users=1] = placeholder[target=_lifted_tensor_constant219]\n",
      "      %_lifted_tensor_constant220 : [num_users=1] = placeholder[target=_lifted_tensor_constant220]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_74 : [num_users=1] = placeholder[target=aten_mul_tensor_74]\n",
      "      %aten_slice_scatter_default_15 : [num_users=1] = placeholder[target=aten_slice_scatter_default_15]\n",
      "      %aten_slice_scatter_default_13 : [num_users=1] = placeholder[target=aten_slice_scatter_default_13]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_65 : [num_users=2] = placeholder[target=aten_view_copy_default_65]\n",
      "      %aten_view_copy_default_66 : [num_users=2] = placeholder[target=aten_view_copy_default_66]\n",
      "      %aten_add_tensor_20 : [num_users=1] = placeholder[target=aten_add_tensor_20]\n",
      "      %aten_view_copy_default_85 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_86 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_74, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_15, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_13, 2), kwargs = {})\n",
      "      %aten__to_copy_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_3_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_3_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_3_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_3_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_3_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_3_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_4_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_4_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_31, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_30, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_24, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_28, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_28, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_29, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_30, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_31, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_33, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_34, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_19,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_18,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_30, %aten_permute_copy_default_36), kwargs = {})\n",
      "      %aten_index_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_29, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_7, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_6, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_21, %b_layers_3_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_5,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_72, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_71, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_75, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_23, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_42, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_63 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_60, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_21, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_63, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_63, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_33 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_12, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_34 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_13, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_33, %aten_view_copy_default_65), kwargs = {})\n",
      "      %aten_mul_tensor_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_33, %aten_view_copy_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_34, %aten_view_copy_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_34, %aten_view_copy_default_65), kwargs = {})\n",
      "      %aten_sub_tensor_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_78, %aten_mul_tensor_79), kwargs = {})\n",
      "      %aten_add_tensor_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_80, %aten_mul_tensor_81), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_6, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_22, 4), kwargs = {})\n",
      "      %aten_cat_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_24, %aten_unsqueeze_copy_default_25], -1), kwargs = {})\n",
      "      %aten_view_copy_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_6, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_67, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_39, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_20, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_73, %aten_view_copy_default_74), kwargs = {})\n",
      "      %aten_view_copy_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_6, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_86 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_75, %_lifted_tensor_constant218), kwargs = {})\n",
      "      %aten_add_tensor_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_86, %aten__to_copy_default_27), kwargs = {})\n",
      "      %aten__softmax_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_24, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_3, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_22, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_76, %aten_view_copy_default_77), kwargs = {})\n",
      "      %aten_view_copy_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_7, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_78, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_43, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_79, [0]), kwargs = {})\n",
      "      %aten_mm_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_37, %aten_permute_copy_default_44), kwargs = {})\n",
      "      %aten_mul_tensor_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_24, %b_layers_3_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_25 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_20, %aten_mul_tensor_87), kwargs = {})\n",
      "      %aten_mul_tensor_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_25, %aten_add_tensor_25), kwargs = {})\n",
      "      %aten_mean_dim_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_88, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_7, %_lifted_tensor_constant219), kwargs = {})\n",
      "      %aten_rsqrt_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_26,), kwargs = {})\n",
      "      %aten_mul_tensor_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_25, %aten_rsqrt_default_7), kwargs = {})\n",
      "      %aten_mul_tensor_90 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_89, %p_layers_3_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_90, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_90, [0]), kwargs = {})\n",
      "      %aten_mm_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_38, %aten_permute_copy_default_45), kwargs = {})\n",
      "      %aten_mm_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_39, %aten_permute_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_91 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_25, %b_layers_3_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_26, %b_layers_3_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_91,), kwargs = {})\n",
      "      %aten_mul_tensor_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_91, %aten_sigmoid_default_3), kwargs = {})\n",
      "      %aten_mul_tensor_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_92, %aten_mul_tensor_93), kwargs = {})\n",
      "      %aten_mm_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_94, %aten_permute_copy_default_47), kwargs = {})\n",
      "      %aten_mul_tensor_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_27, %b_layers_3_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_27 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_25, %aten_mul_tensor_95), kwargs = {})\n",
      "      %aten_mul_tensor_96 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_27, %aten_add_tensor_27), kwargs = {})\n",
      "      %aten_mean_dim_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_96, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_8, %_lifted_tensor_constant220), kwargs = {})\n",
      "      %aten_rsqrt_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_28,), kwargs = {})\n",
      "      %aten_mul_tensor_97 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_27, %aten_rsqrt_default_8), kwargs = {})\n",
      "      %aten_mul_tensor_98 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_97, %p_layers_4_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_98, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_98, [0]), kwargs = {})\n",
      "      %aten_mm_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_41, %aten_permute_copy_default_49), kwargs = {})\n",
      "      %aten_mm_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_42, %aten_permute_copy_default_50), kwargs = {})\n",
      "      %aten_mul_tensor_100 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_29, %b_layers_4_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_101 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_30, %b_layers_4_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_100, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_101, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_84 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_81, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_82, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_84, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_84, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_53, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_45 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_18, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_46 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_19, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_106 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_45, %aten_view_copy_default_85), kwargs = {})\n",
      "      %aten_mul_tensor_108 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_45, %aten_view_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_107 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_46, %aten_view_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_109 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_46, %aten_view_copy_default_85), kwargs = {})\n",
      "      %aten_sub_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_106, %aten_mul_tensor_107), kwargs = {})\n",
      "      %aten_add_tensor_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_108, %aten_mul_tensor_109), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_9, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_30, 4), kwargs = {})\n",
      "      %aten_cat_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_34, %aten_unsqueeze_copy_default_35], -1), kwargs = {})\n",
      "      %aten_view_copy_default_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_9, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_88, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_52, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_85, aten_view_copy_default_86, aten_add_tensor_27, aten_mul_tensor_98, aten_view_copy_default_90, aten_view_copy_default_89)\n",
      "  %executorch_call_delegate_4 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_4, %getitem_1, %getitem_2, %getitem_23, %aten_slice_scatter_default_14, %aten_slice_scatter_default_15, %input_pos, %getitem_20, %getitem_21, %getitem_22), kwargs = {})\n",
      "  %getitem_26 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 0), kwargs = {})\n",
      "  %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 1), kwargs = {})\n",
      "  %getitem_28 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 2), kwargs = {})\n",
      "  %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 3), kwargs = {})\n",
      "  %getitem_30 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 4), kwargs = {})\n",
      "  %getitem_31 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 5), kwargs = {})\n",
      "  %alloc_24 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_8 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_30), kwargs = {out: %alloc_24})\n",
      "  %alloc_25 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_9 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_31), kwargs = {out: %alloc_25})\n",
      "  %alloc_26 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_16 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_8, 1, 0, 9223372036854775807), kwargs = {out: %alloc_26})\n",
      "  %alloc_27 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_17 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_9, 1, 0, 9223372036854775807), kwargs = {out: %alloc_27})\n",
      "  %alloc_28 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_18 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_16, 0, 0, 9223372036854775807), kwargs = {out: %alloc_28})\n",
      "  %alloc_29 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_19 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_17, 0, 0, 9223372036854775807), kwargs = {out: %alloc_29})\n",
      "  %lowered_module_5 : [num_users=1] = get_attr[target=lowered_module_5]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_4_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_4_ffn_norm_weight]\n",
      "      %p_layers_5_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_5_attention_norm_weight]\n",
      "      %b_layers_4_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_4_attention_wq_weight]\n",
      "      %b_layers_4_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_4_attention_wq_scales]\n",
      "      %b_layers_4_attention_mask : [num_users=1] = placeholder[target=b_layers_4_attention_mask]\n",
      "      %b_layers_4_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_4_attention_wo_weight]\n",
      "      %b_layers_4_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_4_attention_wo_scales]\n",
      "      %b_layers_4_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w1_weight]\n",
      "      %b_layers_4_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w1_scales]\n",
      "      %b_layers_4_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w3_weight]\n",
      "      %b_layers_4_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w3_scales]\n",
      "      %b_layers_4_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w2_weight]\n",
      "      %b_layers_4_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w2_scales]\n",
      "      %b_layers_5_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_5_attention_wk_weight]\n",
      "      %b_layers_5_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_5_attention_wk_scales]\n",
      "      %b_layers_5_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_5_attention_wv_weight]\n",
      "      %b_layers_5_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_5_attention_wv_scales]\n",
      "      %_lifted_tensor_constant221 : [num_users=1] = placeholder[target=_lifted_tensor_constant221]\n",
      "      %_lifted_tensor_constant222 : [num_users=1] = placeholder[target=_lifted_tensor_constant222]\n",
      "      %_lifted_tensor_constant223 : [num_users=1] = placeholder[target=_lifted_tensor_constant223]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_98 : [num_users=1] = placeholder[target=aten_mul_tensor_98]\n",
      "      %aten_slice_scatter_default_19 : [num_users=1] = placeholder[target=aten_slice_scatter_default_19]\n",
      "      %aten_slice_scatter_default_17 : [num_users=1] = placeholder[target=aten_slice_scatter_default_17]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_85 : [num_users=2] = placeholder[target=aten_view_copy_default_85]\n",
      "      %aten_view_copy_default_86 : [num_users=2] = placeholder[target=aten_view_copy_default_86]\n",
      "      %aten_add_tensor_27 : [num_users=1] = placeholder[target=aten_add_tensor_27]\n",
      "      %aten_view_copy_default_105 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_106 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_98, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_19, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_17, 2), kwargs = {})\n",
      "      %aten__to_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_4_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_4_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_4_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_4_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_4_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_4_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_5_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_5_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_39, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_38, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_32, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_36, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_36, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_37, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_38, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_39, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_41, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_42, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_25,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_24,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_40, %aten_permute_copy_default_48), kwargs = {})\n",
      "      %aten_index_tensor_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_37, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_9, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_8, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_99 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_28, %b_layers_4_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_6,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_92, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_91, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_99, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_97 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_29, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_54, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_83 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_80, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_27, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_83, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_83, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_43 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_16, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_44 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_17, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_102 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_43, %aten_view_copy_default_85), kwargs = {})\n",
      "      %aten_mul_tensor_104 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_43, %aten_view_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_103 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_44, %aten_view_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_105 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_44, %aten_view_copy_default_85), kwargs = {})\n",
      "      %aten_sub_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_102, %aten_mul_tensor_103), kwargs = {})\n",
      "      %aten_add_tensor_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_104, %aten_mul_tensor_105), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_8, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_29, 4), kwargs = {})\n",
      "      %aten_cat_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_32, %aten_unsqueeze_copy_default_33], -1), kwargs = {})\n",
      "      %aten_view_copy_default_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_8, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_87, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_51, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_26, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_93, %aten_view_copy_default_94), kwargs = {})\n",
      "      %aten_view_copy_default_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_8, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_110 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_95, %_lifted_tensor_constant221), kwargs = {})\n",
      "      %aten_add_tensor_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_110, %aten__to_copy_default_35), kwargs = {})\n",
      "      %aten__softmax_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_31, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_4, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_96 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_28, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_96, %aten_view_copy_default_97), kwargs = {})\n",
      "      %aten_view_copy_default_98 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_9, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_98, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_99 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_55, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_99, [0]), kwargs = {})\n",
      "      %aten_mm_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_47, %aten_permute_copy_default_56), kwargs = {})\n",
      "      %aten_mul_tensor_111 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_31, %b_layers_4_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_32 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_27, %aten_mul_tensor_111), kwargs = {})\n",
      "      %aten_mul_tensor_112 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_32, %aten_add_tensor_32), kwargs = {})\n",
      "      %aten_mean_dim_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_112, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_9, %_lifted_tensor_constant222), kwargs = {})\n",
      "      %aten_rsqrt_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_33,), kwargs = {})\n",
      "      %aten_mul_tensor_113 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_32, %aten_rsqrt_default_9), kwargs = {})\n",
      "      %aten_mul_tensor_114 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_113, %p_layers_4_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_114, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_114, [0]), kwargs = {})\n",
      "      %aten_mm_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_48, %aten_permute_copy_default_57), kwargs = {})\n",
      "      %aten_mm_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_49, %aten_permute_copy_default_58), kwargs = {})\n",
      "      %aten_mul_tensor_115 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_32, %b_layers_4_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_117 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_33, %b_layers_4_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_115,), kwargs = {})\n",
      "      %aten_mul_tensor_116 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_115, %aten_sigmoid_default_4), kwargs = {})\n",
      "      %aten_mul_tensor_118 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_116, %aten_mul_tensor_117), kwargs = {})\n",
      "      %aten_mm_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_118, %aten_permute_copy_default_59), kwargs = {})\n",
      "      %aten_mul_tensor_119 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_34, %b_layers_4_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_34 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_32, %aten_mul_tensor_119), kwargs = {})\n",
      "      %aten_mul_tensor_120 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_34, %aten_add_tensor_34), kwargs = {})\n",
      "      %aten_mean_dim_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_120, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_10, %_lifted_tensor_constant223), kwargs = {})\n",
      "      %aten_rsqrt_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_35,), kwargs = {})\n",
      "      %aten_mul_tensor_121 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_34, %aten_rsqrt_default_10), kwargs = {})\n",
      "      %aten_mul_tensor_122 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_121, %p_layers_5_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_122, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_122, [0]), kwargs = {})\n",
      "      %aten_mm_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_51, %aten_permute_copy_default_61), kwargs = {})\n",
      "      %aten_mm_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_52, %aten_permute_copy_default_62), kwargs = {})\n",
      "      %aten_mul_tensor_124 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_36, %b_layers_5_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_125 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_37, %b_layers_5_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_101 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_124, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_102 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_125, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_104 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_101, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_102, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_104, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_104, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_110 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_65, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_55 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_22, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_56 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_23, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_130 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_55, %aten_view_copy_default_105), kwargs = {})\n",
      "      %aten_mul_tensor_132 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_55, %aten_view_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_131 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_56, %aten_view_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_133 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_56, %aten_view_copy_default_105), kwargs = {})\n",
      "      %aten_sub_tensor_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_130, %aten_mul_tensor_131), kwargs = {})\n",
      "      %aten_add_tensor_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_132, %aten_mul_tensor_133), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_11, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_37, 4), kwargs = {})\n",
      "      %aten_cat_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_42, %aten_unsqueeze_copy_default_43], -1), kwargs = {})\n",
      "      %aten_view_copy_default_108 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_11, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_108, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_109 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_64, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_105, aten_view_copy_default_106, aten_add_tensor_34, aten_mul_tensor_122, aten_view_copy_default_110, aten_view_copy_default_109)\n",
      "  %executorch_call_delegate_5 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_5, %getitem_1, %getitem_2, %getitem_29, %aten_slice_scatter_default_18, %aten_slice_scatter_default_19, %input_pos, %getitem_26, %getitem_27, %getitem_28), kwargs = {})\n",
      "  %getitem_32 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 0), kwargs = {})\n",
      "  %getitem_33 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 1), kwargs = {})\n",
      "  %getitem_34 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 2), kwargs = {})\n",
      "  %getitem_35 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 3), kwargs = {})\n",
      "  %getitem_36 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 4), kwargs = {})\n",
      "  %getitem_37 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 5), kwargs = {})\n",
      "  %alloc_30 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_10 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_36), kwargs = {out: %alloc_30})\n",
      "  %alloc_31 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_11 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_37), kwargs = {out: %alloc_31})\n",
      "  %alloc_32 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_20 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_10, 1, 0, 9223372036854775807), kwargs = {out: %alloc_32})\n",
      "  %alloc_33 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_21 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_11, 1, 0, 9223372036854775807), kwargs = {out: %alloc_33})\n",
      "  %alloc_34 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_22 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_20, 0, 0, 9223372036854775807), kwargs = {out: %alloc_34})\n",
      "  %alloc_35 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_23 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_21, 0, 0, 9223372036854775807), kwargs = {out: %alloc_35})\n",
      "  %lowered_module_6 : [num_users=1] = get_attr[target=lowered_module_6]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_5_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_5_ffn_norm_weight]\n",
      "      %p_layers_6_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_6_attention_norm_weight]\n",
      "      %b_layers_5_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_5_attention_wq_weight]\n",
      "      %b_layers_5_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_5_attention_wq_scales]\n",
      "      %b_layers_5_attention_mask : [num_users=1] = placeholder[target=b_layers_5_attention_mask]\n",
      "      %b_layers_5_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_5_attention_wo_weight]\n",
      "      %b_layers_5_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_5_attention_wo_scales]\n",
      "      %b_layers_5_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w1_weight]\n",
      "      %b_layers_5_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w1_scales]\n",
      "      %b_layers_5_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w3_weight]\n",
      "      %b_layers_5_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w3_scales]\n",
      "      %b_layers_5_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w2_weight]\n",
      "      %b_layers_5_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w2_scales]\n",
      "      %b_layers_6_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_6_attention_wk_weight]\n",
      "      %b_layers_6_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_6_attention_wk_scales]\n",
      "      %b_layers_6_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_6_attention_wv_weight]\n",
      "      %b_layers_6_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_6_attention_wv_scales]\n",
      "      %_lifted_tensor_constant224 : [num_users=1] = placeholder[target=_lifted_tensor_constant224]\n",
      "      %_lifted_tensor_constant225 : [num_users=1] = placeholder[target=_lifted_tensor_constant225]\n",
      "      %_lifted_tensor_constant226 : [num_users=1] = placeholder[target=_lifted_tensor_constant226]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_122 : [num_users=1] = placeholder[target=aten_mul_tensor_122]\n",
      "      %aten_slice_scatter_default_23 : [num_users=1] = placeholder[target=aten_slice_scatter_default_23]\n",
      "      %aten_slice_scatter_default_21 : [num_users=1] = placeholder[target=aten_slice_scatter_default_21]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_105 : [num_users=2] = placeholder[target=aten_view_copy_default_105]\n",
      "      %aten_view_copy_default_106 : [num_users=2] = placeholder[target=aten_view_copy_default_106]\n",
      "      %aten_add_tensor_34 : [num_users=1] = placeholder[target=aten_add_tensor_34]\n",
      "      %aten_view_copy_default_125 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_126 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_122, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_23, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_21, 2), kwargs = {})\n",
      "      %aten__to_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_5_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_5_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_5_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_5_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_5_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_5_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_6_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_6_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_47, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_46, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_40, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_44, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_44, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_45, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_46, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_47, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_49, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_50, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_31,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_30,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_50, %aten_permute_copy_default_60), kwargs = {})\n",
      "      %aten_index_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_45, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_112 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_11, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_111 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_10, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_123 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_35, %b_layers_5_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_7,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_112, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_111, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_100 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_123, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_117 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_35, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_66, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_103 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_100, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_114 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_33, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_103, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_103, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_53 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_20, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_54 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_21, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_126 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_53, %aten_view_copy_default_105), kwargs = {})\n",
      "      %aten_mul_tensor_128 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_53, %aten_view_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_127 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_54, %aten_view_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_129 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_54, %aten_view_copy_default_105), kwargs = {})\n",
      "      %aten_sub_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_126, %aten_mul_tensor_127), kwargs = {})\n",
      "      %aten_add_tensor_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_128, %aten_mul_tensor_129), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_10, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_36, 4), kwargs = {})\n",
      "      %aten_cat_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_40, %aten_unsqueeze_copy_default_41], -1), kwargs = {})\n",
      "      %aten_view_copy_default_107 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_10, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_107, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_63, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_113 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_32, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_113, %aten_view_copy_default_114), kwargs = {})\n",
      "      %aten_view_copy_default_115 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_10, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_134 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_115, %_lifted_tensor_constant224), kwargs = {})\n",
      "      %aten_add_tensor_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_134, %aten__to_copy_default_43), kwargs = {})\n",
      "      %aten__softmax_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_38, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_5, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_116 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_34, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_116, %aten_view_copy_default_117), kwargs = {})\n",
      "      %aten_view_copy_default_118 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_11, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_118, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_119 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_67, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_119, [0]), kwargs = {})\n",
      "      %aten_mm_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_57, %aten_permute_copy_default_68), kwargs = {})\n",
      "      %aten_mul_tensor_135 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_38, %b_layers_5_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_39 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_34, %aten_mul_tensor_135), kwargs = {})\n",
      "      %aten_mul_tensor_136 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_39, %aten_add_tensor_39), kwargs = {})\n",
      "      %aten_mean_dim_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_136, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_11, %_lifted_tensor_constant225), kwargs = {})\n",
      "      %aten_rsqrt_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_40,), kwargs = {})\n",
      "      %aten_mul_tensor_137 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_39, %aten_rsqrt_default_11), kwargs = {})\n",
      "      %aten_mul_tensor_138 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_137, %p_layers_5_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_138, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_138, [0]), kwargs = {})\n",
      "      %aten_mm_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_58, %aten_permute_copy_default_69), kwargs = {})\n",
      "      %aten_mm_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_59, %aten_permute_copy_default_70), kwargs = {})\n",
      "      %aten_mul_tensor_139 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_39, %b_layers_5_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_141 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_40, %b_layers_5_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_139,), kwargs = {})\n",
      "      %aten_mul_tensor_140 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_139, %aten_sigmoid_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_142 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_140, %aten_mul_tensor_141), kwargs = {})\n",
      "      %aten_mm_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_142, %aten_permute_copy_default_71), kwargs = {})\n",
      "      %aten_mul_tensor_143 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_41, %b_layers_5_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_41 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_39, %aten_mul_tensor_143), kwargs = {})\n",
      "      %aten_mul_tensor_144 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_41, %aten_add_tensor_41), kwargs = {})\n",
      "      %aten_mean_dim_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_144, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_12, %_lifted_tensor_constant226), kwargs = {})\n",
      "      %aten_rsqrt_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_42,), kwargs = {})\n",
      "      %aten_mul_tensor_145 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_41, %aten_rsqrt_default_12), kwargs = {})\n",
      "      %aten_mul_tensor_146 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_145, %p_layers_6_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_146, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_146, [0]), kwargs = {})\n",
      "      %aten_mm_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_61, %aten_permute_copy_default_73), kwargs = {})\n",
      "      %aten_mm_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_62, %aten_permute_copy_default_74), kwargs = {})\n",
      "      %aten_mul_tensor_148 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_43, %b_layers_6_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_149 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_44, %b_layers_6_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_121 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_148, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_122 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_149, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_124 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_121, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_122, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_124, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_124, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_130 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_77, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_65 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_26, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_66 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_27, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_154 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_65, %aten_view_copy_default_125), kwargs = {})\n",
      "      %aten_mul_tensor_156 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_65, %aten_view_copy_default_126), kwargs = {})\n",
      "      %aten_mul_tensor_155 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_66, %aten_view_copy_default_126), kwargs = {})\n",
      "      %aten_mul_tensor_157 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_66, %aten_view_copy_default_125), kwargs = {})\n",
      "      %aten_sub_tensor_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_154, %aten_mul_tensor_155), kwargs = {})\n",
      "      %aten_add_tensor_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_156, %aten_mul_tensor_157), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_13, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_44, 4), kwargs = {})\n",
      "      %aten_cat_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_50, %aten_unsqueeze_copy_default_51], -1), kwargs = {})\n",
      "      %aten_view_copy_default_128 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_13, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_128, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_129 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_76, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_125, aten_view_copy_default_126, aten_add_tensor_41, aten_mul_tensor_146, aten_view_copy_default_130, aten_view_copy_default_129)\n",
      "  %executorch_call_delegate_6 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_6, %getitem_1, %getitem_2, %getitem_35, %aten_slice_scatter_default_22, %aten_slice_scatter_default_23, %input_pos, %getitem_32, %getitem_33, %getitem_34), kwargs = {})\n",
      "  %getitem_38 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 0), kwargs = {})\n",
      "  %getitem_39 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 1), kwargs = {})\n",
      "  %getitem_40 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 2), kwargs = {})\n",
      "  %getitem_41 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 3), kwargs = {})\n",
      "  %getitem_42 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 4), kwargs = {})\n",
      "  %getitem_43 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 5), kwargs = {})\n",
      "  %alloc_36 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_12 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_42), kwargs = {out: %alloc_36})\n",
      "  %alloc_37 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_13 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_43), kwargs = {out: %alloc_37})\n",
      "  %alloc_38 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_24 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_12, 1, 0, 9223372036854775807), kwargs = {out: %alloc_38})\n",
      "  %alloc_39 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_25 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_13, 1, 0, 9223372036854775807), kwargs = {out: %alloc_39})\n",
      "  %alloc_40 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_26 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_24, 0, 0, 9223372036854775807), kwargs = {out: %alloc_40})\n",
      "  %alloc_41 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_27 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_25, 0, 0, 9223372036854775807), kwargs = {out: %alloc_41})\n",
      "  %lowered_module_7 : [num_users=1] = get_attr[target=lowered_module_7]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_6_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_6_ffn_norm_weight]\n",
      "      %p_layers_7_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_7_attention_norm_weight]\n",
      "      %b_layers_6_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_6_attention_wq_weight]\n",
      "      %b_layers_6_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_6_attention_wq_scales]\n",
      "      %b_layers_6_attention_mask : [num_users=1] = placeholder[target=b_layers_6_attention_mask]\n",
      "      %b_layers_6_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_6_attention_wo_weight]\n",
      "      %b_layers_6_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_6_attention_wo_scales]\n",
      "      %b_layers_6_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w1_weight]\n",
      "      %b_layers_6_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w1_scales]\n",
      "      %b_layers_6_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w3_weight]\n",
      "      %b_layers_6_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w3_scales]\n",
      "      %b_layers_6_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w2_weight]\n",
      "      %b_layers_6_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w2_scales]\n",
      "      %b_layers_7_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_7_attention_wk_weight]\n",
      "      %b_layers_7_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_7_attention_wk_scales]\n",
      "      %b_layers_7_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_7_attention_wv_weight]\n",
      "      %b_layers_7_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_7_attention_wv_scales]\n",
      "      %_lifted_tensor_constant227 : [num_users=1] = placeholder[target=_lifted_tensor_constant227]\n",
      "      %_lifted_tensor_constant228 : [num_users=1] = placeholder[target=_lifted_tensor_constant228]\n",
      "      %_lifted_tensor_constant229 : [num_users=1] = placeholder[target=_lifted_tensor_constant229]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_146 : [num_users=1] = placeholder[target=aten_mul_tensor_146]\n",
      "      %aten_slice_scatter_default_27 : [num_users=1] = placeholder[target=aten_slice_scatter_default_27]\n",
      "      %aten_slice_scatter_default_25 : [num_users=1] = placeholder[target=aten_slice_scatter_default_25]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_125 : [num_users=2] = placeholder[target=aten_view_copy_default_125]\n",
      "      %aten_view_copy_default_126 : [num_users=2] = placeholder[target=aten_view_copy_default_126]\n",
      "      %aten_add_tensor_41 : [num_users=1] = placeholder[target=aten_add_tensor_41]\n",
      "      %aten_view_copy_default_145 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_146 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_146, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_27, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_25, 2), kwargs = {})\n",
      "      %aten__to_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_6_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_6_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_6_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_6_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_6_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_6_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_7_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_7_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_55, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_54, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_48, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_52, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_52, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_53, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_54, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_55, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_85 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_57, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_86 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_58, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_37,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_36,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_60, %aten_permute_copy_default_72), kwargs = {})\n",
      "      %aten_index_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_53, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_132 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_13, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_131 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_12, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_147 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_42, %b_layers_6_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_8,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_132, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_131, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_120 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_147, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_137 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_41, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_78, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_123 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_120, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_134 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_39, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_123, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_123, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_63 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_24, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_64 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_25, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_150 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_63, %aten_view_copy_default_125), kwargs = {})\n",
      "      %aten_mul_tensor_152 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_63, %aten_view_copy_default_126), kwargs = {})\n",
      "      %aten_mul_tensor_151 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_64, %aten_view_copy_default_126), kwargs = {})\n",
      "      %aten_mul_tensor_153 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_64, %aten_view_copy_default_125), kwargs = {})\n",
      "      %aten_sub_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_150, %aten_mul_tensor_151), kwargs = {})\n",
      "      %aten_add_tensor_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_152, %aten_mul_tensor_153), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_12, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_43, 4), kwargs = {})\n",
      "      %aten_cat_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_48, %aten_unsqueeze_copy_default_49], -1), kwargs = {})\n",
      "      %aten_view_copy_default_127 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_12, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_127, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_75, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_133 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_38, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_133, %aten_view_copy_default_134), kwargs = {})\n",
      "      %aten_view_copy_default_135 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_12, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_158 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_135, %_lifted_tensor_constant227), kwargs = {})\n",
      "      %aten_add_tensor_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_158, %aten__to_copy_default_51), kwargs = {})\n",
      "      %aten__softmax_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_45, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_6, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_136 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_40, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_136, %aten_view_copy_default_137), kwargs = {})\n",
      "      %aten_view_copy_default_138 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_13, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_138, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_139 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_79, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_139, [0]), kwargs = {})\n",
      "      %aten_mm_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_67, %aten_permute_copy_default_80), kwargs = {})\n",
      "      %aten_mul_tensor_159 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_45, %b_layers_6_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_46 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_41, %aten_mul_tensor_159), kwargs = {})\n",
      "      %aten_mul_tensor_160 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_46, %aten_add_tensor_46), kwargs = {})\n",
      "      %aten_mean_dim_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_160, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_13, %_lifted_tensor_constant228), kwargs = {})\n",
      "      %aten_rsqrt_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_47,), kwargs = {})\n",
      "      %aten_mul_tensor_161 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_46, %aten_rsqrt_default_13), kwargs = {})\n",
      "      %aten_mul_tensor_162 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_161, %p_layers_6_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_162, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_162, [0]), kwargs = {})\n",
      "      %aten_mm_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_68, %aten_permute_copy_default_81), kwargs = {})\n",
      "      %aten_mm_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_69, %aten_permute_copy_default_82), kwargs = {})\n",
      "      %aten_mul_tensor_163 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_46, %b_layers_6_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_165 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_47, %b_layers_6_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_163,), kwargs = {})\n",
      "      %aten_mul_tensor_164 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_163, %aten_sigmoid_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_166 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_164, %aten_mul_tensor_165), kwargs = {})\n",
      "      %aten_mm_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_166, %aten_permute_copy_default_83), kwargs = {})\n",
      "      %aten_mul_tensor_167 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_48, %b_layers_6_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_48 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_46, %aten_mul_tensor_167), kwargs = {})\n",
      "      %aten_mul_tensor_168 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_48, %aten_add_tensor_48), kwargs = {})\n",
      "      %aten_mean_dim_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_168, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_14, %_lifted_tensor_constant229), kwargs = {})\n",
      "      %aten_rsqrt_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_49,), kwargs = {})\n",
      "      %aten_mul_tensor_169 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_48, %aten_rsqrt_default_14), kwargs = {})\n",
      "      %aten_mul_tensor_170 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_169, %p_layers_7_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_170, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_170, [0]), kwargs = {})\n",
      "      %aten_mm_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_71, %aten_permute_copy_default_85), kwargs = {})\n",
      "      %aten_mm_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_72, %aten_permute_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_172 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_50, %b_layers_7_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_173 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_51, %b_layers_7_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_141 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_172, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_142 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_173, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_144 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_141, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_142, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_144, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_144, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_150 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_89, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_75 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_30, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_76 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_31, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_178 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_75, %aten_view_copy_default_145), kwargs = {})\n",
      "      %aten_mul_tensor_180 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_75, %aten_view_copy_default_146), kwargs = {})\n",
      "      %aten_mul_tensor_179 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_76, %aten_view_copy_default_146), kwargs = {})\n",
      "      %aten_mul_tensor_181 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_76, %aten_view_copy_default_145), kwargs = {})\n",
      "      %aten_sub_tensor_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_178, %aten_mul_tensor_179), kwargs = {})\n",
      "      %aten_add_tensor_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_180, %aten_mul_tensor_181), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_15, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_51, 4), kwargs = {})\n",
      "      %aten_cat_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_58, %aten_unsqueeze_copy_default_59], -1), kwargs = {})\n",
      "      %aten_view_copy_default_148 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_15, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_148, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_149 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_88, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_145, aten_view_copy_default_146, aten_add_tensor_48, aten_mul_tensor_170, aten_view_copy_default_150, aten_view_copy_default_149)\n",
      "  %executorch_call_delegate_7 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_7, %getitem_1, %getitem_2, %getitem_41, %aten_slice_scatter_default_26, %aten_slice_scatter_default_27, %input_pos, %getitem_38, %getitem_39, %getitem_40), kwargs = {})\n",
      "  %getitem_44 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 0), kwargs = {})\n",
      "  %getitem_45 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 1), kwargs = {})\n",
      "  %getitem_46 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 2), kwargs = {})\n",
      "  %getitem_47 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 3), kwargs = {})\n",
      "  %getitem_48 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 4), kwargs = {})\n",
      "  %getitem_49 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 5), kwargs = {})\n",
      "  %alloc_42 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_14 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_48), kwargs = {out: %alloc_42})\n",
      "  %alloc_43 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_15 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_49), kwargs = {out: %alloc_43})\n",
      "  %alloc_44 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_28 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_14, 1, 0, 9223372036854775807), kwargs = {out: %alloc_44})\n",
      "  %alloc_45 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_29 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_15, 1, 0, 9223372036854775807), kwargs = {out: %alloc_45})\n",
      "  %alloc_46 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_30 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_28, 0, 0, 9223372036854775807), kwargs = {out: %alloc_46})\n",
      "  %alloc_47 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_31 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_29, 0, 0, 9223372036854775807), kwargs = {out: %alloc_47})\n",
      "  %lowered_module_8 : [num_users=1] = get_attr[target=lowered_module_8]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_7_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_7_ffn_norm_weight]\n",
      "      %p_layers_8_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_8_attention_norm_weight]\n",
      "      %b_layers_7_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_7_attention_wq_weight]\n",
      "      %b_layers_7_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_7_attention_wq_scales]\n",
      "      %b_layers_7_attention_mask : [num_users=1] = placeholder[target=b_layers_7_attention_mask]\n",
      "      %b_layers_7_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_7_attention_wo_weight]\n",
      "      %b_layers_7_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_7_attention_wo_scales]\n",
      "      %b_layers_7_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w1_weight]\n",
      "      %b_layers_7_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w1_scales]\n",
      "      %b_layers_7_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w3_weight]\n",
      "      %b_layers_7_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w3_scales]\n",
      "      %b_layers_7_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w2_weight]\n",
      "      %b_layers_7_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w2_scales]\n",
      "      %b_layers_8_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_8_attention_wk_weight]\n",
      "      %b_layers_8_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_8_attention_wk_scales]\n",
      "      %b_layers_8_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_8_attention_wv_weight]\n",
      "      %b_layers_8_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_8_attention_wv_scales]\n",
      "      %_lifted_tensor_constant230 : [num_users=1] = placeholder[target=_lifted_tensor_constant230]\n",
      "      %_lifted_tensor_constant231 : [num_users=1] = placeholder[target=_lifted_tensor_constant231]\n",
      "      %_lifted_tensor_constant232 : [num_users=1] = placeholder[target=_lifted_tensor_constant232]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_170 : [num_users=1] = placeholder[target=aten_mul_tensor_170]\n",
      "      %aten_slice_scatter_default_31 : [num_users=1] = placeholder[target=aten_slice_scatter_default_31]\n",
      "      %aten_slice_scatter_default_29 : [num_users=1] = placeholder[target=aten_slice_scatter_default_29]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_145 : [num_users=2] = placeholder[target=aten_view_copy_default_145]\n",
      "      %aten_view_copy_default_146 : [num_users=2] = placeholder[target=aten_view_copy_default_146]\n",
      "      %aten_add_tensor_48 : [num_users=1] = placeholder[target=aten_add_tensor_48]\n",
      "      %aten_view_copy_default_165 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_166 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_170, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_31, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_29, 2), kwargs = {})\n",
      "      %aten__to_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_7_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_7_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_7_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_7_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_7_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_7_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_8_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_8_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_63, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_62, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_56, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_60, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_60, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_61, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_62, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_63, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_97 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_65, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_98 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_66, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_43,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_42,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_70, %aten_permute_copy_default_84), kwargs = {})\n",
      "      %aten_index_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_61, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_152 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_15, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_151 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_14, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_171 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_49, %b_layers_7_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_9,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_152, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_151, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_140 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_171, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_157 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_47, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_90, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_143 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_140, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_154 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_45, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_143, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_143, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_73 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_28, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_74 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_29, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_174 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_73, %aten_view_copy_default_145), kwargs = {})\n",
      "      %aten_mul_tensor_176 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_73, %aten_view_copy_default_146), kwargs = {})\n",
      "      %aten_mul_tensor_175 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_74, %aten_view_copy_default_146), kwargs = {})\n",
      "      %aten_mul_tensor_177 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_74, %aten_view_copy_default_145), kwargs = {})\n",
      "      %aten_sub_tensor_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_174, %aten_mul_tensor_175), kwargs = {})\n",
      "      %aten_add_tensor_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_176, %aten_mul_tensor_177), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_14, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_50, 4), kwargs = {})\n",
      "      %aten_cat_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_56, %aten_unsqueeze_copy_default_57], -1), kwargs = {})\n",
      "      %aten_view_copy_default_147 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_14, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_147, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_87, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_153 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_44, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_153, %aten_view_copy_default_154), kwargs = {})\n",
      "      %aten_view_copy_default_155 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_14, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_182 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_155, %_lifted_tensor_constant230), kwargs = {})\n",
      "      %aten_add_tensor_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_182, %aten__to_copy_default_59), kwargs = {})\n",
      "      %aten__softmax_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_52, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_7, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_156 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_46, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_156, %aten_view_copy_default_157), kwargs = {})\n",
      "      %aten_view_copy_default_158 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_15, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_158, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_159 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_91, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_159, [0]), kwargs = {})\n",
      "      %aten_mm_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_77, %aten_permute_copy_default_92), kwargs = {})\n",
      "      %aten_mul_tensor_183 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_52, %b_layers_7_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_53 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_48, %aten_mul_tensor_183), kwargs = {})\n",
      "      %aten_mul_tensor_184 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_53, %aten_add_tensor_53), kwargs = {})\n",
      "      %aten_mean_dim_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_184, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_15, %_lifted_tensor_constant231), kwargs = {})\n",
      "      %aten_rsqrt_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_54,), kwargs = {})\n",
      "      %aten_mul_tensor_185 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_53, %aten_rsqrt_default_15), kwargs = {})\n",
      "      %aten_mul_tensor_186 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_185, %p_layers_7_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_186, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_186, [0]), kwargs = {})\n",
      "      %aten_mm_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_78, %aten_permute_copy_default_93), kwargs = {})\n",
      "      %aten_mm_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_79, %aten_permute_copy_default_94), kwargs = {})\n",
      "      %aten_mul_tensor_187 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_53, %b_layers_7_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_189 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_54, %b_layers_7_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_187,), kwargs = {})\n",
      "      %aten_mul_tensor_188 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_187, %aten_sigmoid_default_7), kwargs = {})\n",
      "      %aten_mul_tensor_190 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_188, %aten_mul_tensor_189), kwargs = {})\n",
      "      %aten_mm_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_190, %aten_permute_copy_default_95), kwargs = {})\n",
      "      %aten_mul_tensor_191 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_55, %b_layers_7_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_55 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_53, %aten_mul_tensor_191), kwargs = {})\n",
      "      %aten_mul_tensor_192 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_55, %aten_add_tensor_55), kwargs = {})\n",
      "      %aten_mean_dim_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_192, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_16, %_lifted_tensor_constant232), kwargs = {})\n",
      "      %aten_rsqrt_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_56,), kwargs = {})\n",
      "      %aten_mul_tensor_193 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_55, %aten_rsqrt_default_16), kwargs = {})\n",
      "      %aten_mul_tensor_194 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_193, %p_layers_8_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_194, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_194, [0]), kwargs = {})\n",
      "      %aten_mm_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_81, %aten_permute_copy_default_97), kwargs = {})\n",
      "      %aten_mm_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_82, %aten_permute_copy_default_98), kwargs = {})\n",
      "      %aten_mul_tensor_196 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_57, %b_layers_8_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_197 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_58, %b_layers_8_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_161 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_196, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_162 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_197, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_164 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_161, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_101 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_162, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_164, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_164, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_170 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_101, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_85 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_34, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_86 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_35, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_202 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_85, %aten_view_copy_default_165), kwargs = {})\n",
      "      %aten_mul_tensor_204 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_85, %aten_view_copy_default_166), kwargs = {})\n",
      "      %aten_mul_tensor_203 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_86, %aten_view_copy_default_166), kwargs = {})\n",
      "      %aten_mul_tensor_205 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_86, %aten_view_copy_default_165), kwargs = {})\n",
      "      %aten_sub_tensor_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_202, %aten_mul_tensor_203), kwargs = {})\n",
      "      %aten_add_tensor_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_204, %aten_mul_tensor_205), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_17, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_58, 4), kwargs = {})\n",
      "      %aten_cat_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_66, %aten_unsqueeze_copy_default_67], -1), kwargs = {})\n",
      "      %aten_view_copy_default_168 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_17, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_100 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_168, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_169 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_100, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_165, aten_view_copy_default_166, aten_add_tensor_55, aten_mul_tensor_194, aten_view_copy_default_170, aten_view_copy_default_169)\n",
      "  %executorch_call_delegate_8 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_8, %getitem_1, %getitem_2, %getitem_47, %aten_slice_scatter_default_30, %aten_slice_scatter_default_31, %input_pos, %getitem_44, %getitem_45, %getitem_46), kwargs = {})\n",
      "  %getitem_50 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 0), kwargs = {})\n",
      "  %getitem_51 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 1), kwargs = {})\n",
      "  %getitem_52 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 2), kwargs = {})\n",
      "  %getitem_53 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 3), kwargs = {})\n",
      "  %getitem_54 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 4), kwargs = {})\n",
      "  %getitem_55 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 5), kwargs = {})\n",
      "  %alloc_48 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_16 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_54), kwargs = {out: %alloc_48})\n",
      "  %alloc_49 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_17 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_55), kwargs = {out: %alloc_49})\n",
      "  %alloc_50 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_32 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_16, 1, 0, 9223372036854775807), kwargs = {out: %alloc_50})\n",
      "  %alloc_51 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_33 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_17, 1, 0, 9223372036854775807), kwargs = {out: %alloc_51})\n",
      "  %alloc_52 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_34 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_32, 0, 0, 9223372036854775807), kwargs = {out: %alloc_52})\n",
      "  %alloc_53 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_35 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_33, 0, 0, 9223372036854775807), kwargs = {out: %alloc_53})\n",
      "  %lowered_module_9 : [num_users=1] = get_attr[target=lowered_module_9]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_8_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_8_ffn_norm_weight]\n",
      "      %p_layers_9_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_9_attention_norm_weight]\n",
      "      %b_layers_8_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_8_attention_wq_weight]\n",
      "      %b_layers_8_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_8_attention_wq_scales]\n",
      "      %b_layers_8_attention_mask : [num_users=1] = placeholder[target=b_layers_8_attention_mask]\n",
      "      %b_layers_8_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_8_attention_wo_weight]\n",
      "      %b_layers_8_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_8_attention_wo_scales]\n",
      "      %b_layers_8_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w1_weight]\n",
      "      %b_layers_8_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w1_scales]\n",
      "      %b_layers_8_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w3_weight]\n",
      "      %b_layers_8_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w3_scales]\n",
      "      %b_layers_8_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w2_weight]\n",
      "      %b_layers_8_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w2_scales]\n",
      "      %b_layers_9_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_9_attention_wk_weight]\n",
      "      %b_layers_9_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_9_attention_wk_scales]\n",
      "      %b_layers_9_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_9_attention_wv_weight]\n",
      "      %b_layers_9_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_9_attention_wv_scales]\n",
      "      %_lifted_tensor_constant233 : [num_users=1] = placeholder[target=_lifted_tensor_constant233]\n",
      "      %_lifted_tensor_constant234 : [num_users=1] = placeholder[target=_lifted_tensor_constant234]\n",
      "      %_lifted_tensor_constant235 : [num_users=1] = placeholder[target=_lifted_tensor_constant235]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_194 : [num_users=1] = placeholder[target=aten_mul_tensor_194]\n",
      "      %aten_slice_scatter_default_35 : [num_users=1] = placeholder[target=aten_slice_scatter_default_35]\n",
      "      %aten_slice_scatter_default_33 : [num_users=1] = placeholder[target=aten_slice_scatter_default_33]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_165 : [num_users=2] = placeholder[target=aten_view_copy_default_165]\n",
      "      %aten_view_copy_default_166 : [num_users=2] = placeholder[target=aten_view_copy_default_166]\n",
      "      %aten_add_tensor_55 : [num_users=1] = placeholder[target=aten_add_tensor_55]\n",
      "      %aten_view_copy_default_185 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_186 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_194, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_35, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_33, 2), kwargs = {})\n",
      "      %aten__to_copy_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_8_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_8_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_8_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_8_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_8_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_8_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_9_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_9_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_71, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_70, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_96 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_64, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_68, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_104 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_68, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_105 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_69, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_106 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_70, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_107 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_71, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_109 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_73, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_110 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_74, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_49,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_48,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_80, %aten_permute_copy_default_96), kwargs = {})\n",
      "      %aten_index_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_69, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_172 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_17, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_171 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_16, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_195 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_56, %b_layers_8_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_10,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_172, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_102 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_171, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_160 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_195, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_177 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_53, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_102, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_163 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_160, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_174 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_51, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_163, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_163, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_83 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_32, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_84 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_33, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_198 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_83, %aten_view_copy_default_165), kwargs = {})\n",
      "      %aten_mul_tensor_200 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_83, %aten_view_copy_default_166), kwargs = {})\n",
      "      %aten_mul_tensor_199 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_84, %aten_view_copy_default_166), kwargs = {})\n",
      "      %aten_mul_tensor_201 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_84, %aten_view_copy_default_165), kwargs = {})\n",
      "      %aten_sub_tensor_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_198, %aten_mul_tensor_199), kwargs = {})\n",
      "      %aten_add_tensor_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_200, %aten_mul_tensor_201), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_16, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_57, 4), kwargs = {})\n",
      "      %aten_cat_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_64, %aten_unsqueeze_copy_default_65], -1), kwargs = {})\n",
      "      %aten_view_copy_default_167 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_16, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_99 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_167, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_99, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_173 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_50, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_173, %aten_view_copy_default_174), kwargs = {})\n",
      "      %aten_view_copy_default_175 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_16, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_206 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_175, %_lifted_tensor_constant233), kwargs = {})\n",
      "      %aten_add_tensor_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_206, %aten__to_copy_default_67), kwargs = {})\n",
      "      %aten__softmax_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_59, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_8, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_176 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_52, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_176, %aten_view_copy_default_177), kwargs = {})\n",
      "      %aten_view_copy_default_178 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_17, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_103 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_178, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_179 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_103, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_179, [0]), kwargs = {})\n",
      "      %aten_mm_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_87, %aten_permute_copy_default_104), kwargs = {})\n",
      "      %aten_mul_tensor_207 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_59, %b_layers_8_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_60 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_55, %aten_mul_tensor_207), kwargs = {})\n",
      "      %aten_mul_tensor_208 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_60, %aten_add_tensor_60), kwargs = {})\n",
      "      %aten_mean_dim_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_208, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_17, %_lifted_tensor_constant234), kwargs = {})\n",
      "      %aten_rsqrt_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_61,), kwargs = {})\n",
      "      %aten_mul_tensor_209 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_60, %aten_rsqrt_default_17), kwargs = {})\n",
      "      %aten_mul_tensor_210 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_209, %p_layers_8_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_210, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_210, [0]), kwargs = {})\n",
      "      %aten_mm_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_88, %aten_permute_copy_default_105), kwargs = {})\n",
      "      %aten_mm_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_89, %aten_permute_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_211 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_60, %b_layers_8_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_213 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_61, %b_layers_8_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_211,), kwargs = {})\n",
      "      %aten_mul_tensor_212 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_211, %aten_sigmoid_default_8), kwargs = {})\n",
      "      %aten_mul_tensor_214 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_212, %aten_mul_tensor_213), kwargs = {})\n",
      "      %aten_mm_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_214, %aten_permute_copy_default_107), kwargs = {})\n",
      "      %aten_mul_tensor_215 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_62, %b_layers_8_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_62 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_60, %aten_mul_tensor_215), kwargs = {})\n",
      "      %aten_mul_tensor_216 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_62, %aten_add_tensor_62), kwargs = {})\n",
      "      %aten_mean_dim_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_216, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_18, %_lifted_tensor_constant235), kwargs = {})\n",
      "      %aten_rsqrt_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_63,), kwargs = {})\n",
      "      %aten_mul_tensor_217 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_62, %aten_rsqrt_default_18), kwargs = {})\n",
      "      %aten_mul_tensor_218 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_217, %p_layers_9_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_218, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_218, [0]), kwargs = {})\n",
      "      %aten_mm_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_91, %aten_permute_copy_default_109), kwargs = {})\n",
      "      %aten_mm_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_92, %aten_permute_copy_default_110), kwargs = {})\n",
      "      %aten_mul_tensor_220 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_64, %b_layers_9_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_221 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_65, %b_layers_9_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_181 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_220, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_182 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_221, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_184 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_181, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_113 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_182, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_184, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_184, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_190 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_113, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_95 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_38, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_96 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_39, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_226 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_95, %aten_view_copy_default_185), kwargs = {})\n",
      "      %aten_mul_tensor_228 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_95, %aten_view_copy_default_186), kwargs = {})\n",
      "      %aten_mul_tensor_227 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_96, %aten_view_copy_default_186), kwargs = {})\n",
      "      %aten_mul_tensor_229 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_96, %aten_view_copy_default_185), kwargs = {})\n",
      "      %aten_sub_tensor_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_226, %aten_mul_tensor_227), kwargs = {})\n",
      "      %aten_add_tensor_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_228, %aten_mul_tensor_229), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_19, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_65, 4), kwargs = {})\n",
      "      %aten_cat_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_74, %aten_unsqueeze_copy_default_75], -1), kwargs = {})\n",
      "      %aten_view_copy_default_188 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_19, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_112 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_188, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_189 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_112, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_185, aten_view_copy_default_186, aten_add_tensor_62, aten_mul_tensor_218, aten_view_copy_default_190, aten_view_copy_default_189)\n",
      "  %executorch_call_delegate_9 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_9, %getitem_1, %getitem_2, %getitem_53, %aten_slice_scatter_default_34, %aten_slice_scatter_default_35, %input_pos, %getitem_50, %getitem_51, %getitem_52), kwargs = {})\n",
      "  %getitem_56 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 0), kwargs = {})\n",
      "  %getitem_57 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 1), kwargs = {})\n",
      "  %getitem_58 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 2), kwargs = {})\n",
      "  %getitem_59 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 3), kwargs = {})\n",
      "  %getitem_60 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 4), kwargs = {})\n",
      "  %getitem_61 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 5), kwargs = {})\n",
      "  %alloc_54 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_18 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_60), kwargs = {out: %alloc_54})\n",
      "  %alloc_55 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_19 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_61), kwargs = {out: %alloc_55})\n",
      "  %alloc_56 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_36 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_18, 1, 0, 9223372036854775807), kwargs = {out: %alloc_56})\n",
      "  %alloc_57 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_37 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_19, 1, 0, 9223372036854775807), kwargs = {out: %alloc_57})\n",
      "  %alloc_58 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_38 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_36, 0, 0, 9223372036854775807), kwargs = {out: %alloc_58})\n",
      "  %alloc_59 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_39 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_37, 0, 0, 9223372036854775807), kwargs = {out: %alloc_59})\n",
      "  %lowered_module_10 : [num_users=1] = get_attr[target=lowered_module_10]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_9_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_9_ffn_norm_weight]\n",
      "      %p_layers_10_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_10_attention_norm_weight]\n",
      "      %b_layers_9_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_9_attention_wq_weight]\n",
      "      %b_layers_9_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_9_attention_wq_scales]\n",
      "      %b_layers_9_attention_mask : [num_users=1] = placeholder[target=b_layers_9_attention_mask]\n",
      "      %b_layers_9_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_9_attention_wo_weight]\n",
      "      %b_layers_9_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_9_attention_wo_scales]\n",
      "      %b_layers_9_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w1_weight]\n",
      "      %b_layers_9_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w1_scales]\n",
      "      %b_layers_9_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w3_weight]\n",
      "      %b_layers_9_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w3_scales]\n",
      "      %b_layers_9_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w2_weight]\n",
      "      %b_layers_9_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w2_scales]\n",
      "      %b_layers_10_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_10_attention_wk_weight]\n",
      "      %b_layers_10_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_10_attention_wk_scales]\n",
      "      %b_layers_10_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_10_attention_wv_weight]\n",
      "      %b_layers_10_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_10_attention_wv_scales]\n",
      "      %_lifted_tensor_constant236 : [num_users=1] = placeholder[target=_lifted_tensor_constant236]\n",
      "      %_lifted_tensor_constant237 : [num_users=1] = placeholder[target=_lifted_tensor_constant237]\n",
      "      %_lifted_tensor_constant238 : [num_users=1] = placeholder[target=_lifted_tensor_constant238]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_218 : [num_users=1] = placeholder[target=aten_mul_tensor_218]\n",
      "      %aten_slice_scatter_default_39 : [num_users=1] = placeholder[target=aten_slice_scatter_default_39]\n",
      "      %aten_slice_scatter_default_37 : [num_users=1] = placeholder[target=aten_slice_scatter_default_37]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_185 : [num_users=2] = placeholder[target=aten_view_copy_default_185]\n",
      "      %aten_view_copy_default_186 : [num_users=2] = placeholder[target=aten_view_copy_default_186]\n",
      "      %aten_add_tensor_62 : [num_users=1] = placeholder[target=aten_add_tensor_62]\n",
      "      %aten_view_copy_default_205 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_206 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_218, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_39, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_37, 2), kwargs = {})\n",
      "      %aten__to_copy_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_9_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_9_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_9_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_9_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_9_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_9_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_10_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_10_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_79, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_78, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_108 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_72, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_76, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_116 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_76, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_117 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_77, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_118 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_78, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_119 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_79, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_121 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_81, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_122 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_82, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_55,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_54,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_90, %aten_permute_copy_default_108), kwargs = {})\n",
      "      %aten_index_tensor_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_77, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_192 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_19, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_191 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_18, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_219 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_63, %b_layers_9_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_11,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_192, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_114 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_191, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_180 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_219, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_197 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_59, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_114, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_183 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_180, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_194 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_57, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_183, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_183, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_93 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_36, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_94 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_37, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_222 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_93, %aten_view_copy_default_185), kwargs = {})\n",
      "      %aten_mul_tensor_224 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_93, %aten_view_copy_default_186), kwargs = {})\n",
      "      %aten_mul_tensor_223 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_94, %aten_view_copy_default_186), kwargs = {})\n",
      "      %aten_mul_tensor_225 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_94, %aten_view_copy_default_185), kwargs = {})\n",
      "      %aten_sub_tensor_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_222, %aten_mul_tensor_223), kwargs = {})\n",
      "      %aten_add_tensor_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_224, %aten_mul_tensor_225), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_18, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_64, 4), kwargs = {})\n",
      "      %aten_cat_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_72, %aten_unsqueeze_copy_default_73], -1), kwargs = {})\n",
      "      %aten_view_copy_default_187 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_18, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_111 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_187, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_111, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_193 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_56, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_193, %aten_view_copy_default_194), kwargs = {})\n",
      "      %aten_view_copy_default_195 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_18, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_230 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_195, %_lifted_tensor_constant236), kwargs = {})\n",
      "      %aten_add_tensor_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_230, %aten__to_copy_default_75), kwargs = {})\n",
      "      %aten__softmax_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_66, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_9, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_196 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_58, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_196, %aten_view_copy_default_197), kwargs = {})\n",
      "      %aten_view_copy_default_198 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_19, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_115 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_198, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_199 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_115, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_97 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_199, [0]), kwargs = {})\n",
      "      %aten_mm_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_97, %aten_permute_copy_default_116), kwargs = {})\n",
      "      %aten_mul_tensor_231 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_66, %b_layers_9_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_67 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_62, %aten_mul_tensor_231), kwargs = {})\n",
      "      %aten_mul_tensor_232 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_67, %aten_add_tensor_67), kwargs = {})\n",
      "      %aten_mean_dim_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_232, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_19, %_lifted_tensor_constant237), kwargs = {})\n",
      "      %aten_rsqrt_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_68,), kwargs = {})\n",
      "      %aten_mul_tensor_233 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_67, %aten_rsqrt_default_19), kwargs = {})\n",
      "      %aten_mul_tensor_234 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_233, %p_layers_9_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_98 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_234, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_99 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_234, [0]), kwargs = {})\n",
      "      %aten_mm_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_98, %aten_permute_copy_default_117), kwargs = {})\n",
      "      %aten_mm_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_99, %aten_permute_copy_default_118), kwargs = {})\n",
      "      %aten_mul_tensor_235 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_67, %b_layers_9_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_237 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_68, %b_layers_9_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_235,), kwargs = {})\n",
      "      %aten_mul_tensor_236 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_235, %aten_sigmoid_default_9), kwargs = {})\n",
      "      %aten_mul_tensor_238 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_236, %aten_mul_tensor_237), kwargs = {})\n",
      "      %aten_mm_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_238, %aten_permute_copy_default_119), kwargs = {})\n",
      "      %aten_mul_tensor_239 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_69, %b_layers_9_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_69 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_67, %aten_mul_tensor_239), kwargs = {})\n",
      "      %aten_mul_tensor_240 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_69, %aten_add_tensor_69), kwargs = {})\n",
      "      %aten_mean_dim_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_240, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_20, %_lifted_tensor_constant238), kwargs = {})\n",
      "      %aten_rsqrt_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_70,), kwargs = {})\n",
      "      %aten_mul_tensor_241 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_69, %aten_rsqrt_default_20), kwargs = {})\n",
      "      %aten_mul_tensor_242 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_241, %p_layers_10_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_101 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_242, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_102 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_242, [0]), kwargs = {})\n",
      "      %aten_mm_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_101, %aten_permute_copy_default_121), kwargs = {})\n",
      "      %aten_mm_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_102, %aten_permute_copy_default_122), kwargs = {})\n",
      "      %aten_mul_tensor_244 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_71, %b_layers_10_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_245 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_72, %b_layers_10_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_201 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_244, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_202 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_245, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_204 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_201, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_125 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_202, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_204, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_204, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_210 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_125, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_105 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_42, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_106 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_43, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_250 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_105, %aten_view_copy_default_205), kwargs = {})\n",
      "      %aten_mul_tensor_252 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_105, %aten_view_copy_default_206), kwargs = {})\n",
      "      %aten_mul_tensor_251 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_106, %aten_view_copy_default_206), kwargs = {})\n",
      "      %aten_mul_tensor_253 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_106, %aten_view_copy_default_205), kwargs = {})\n",
      "      %aten_sub_tensor_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_250, %aten_mul_tensor_251), kwargs = {})\n",
      "      %aten_add_tensor_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_252, %aten_mul_tensor_253), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_21, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_72, 4), kwargs = {})\n",
      "      %aten_cat_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_82, %aten_unsqueeze_copy_default_83], -1), kwargs = {})\n",
      "      %aten_view_copy_default_208 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_21, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_124 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_208, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_209 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_124, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_205, aten_view_copy_default_206, aten_add_tensor_69, aten_mul_tensor_242, aten_view_copy_default_210, aten_view_copy_default_209)\n",
      "  %executorch_call_delegate_10 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_10, %getitem_1, %getitem_2, %getitem_59, %aten_slice_scatter_default_38, %aten_slice_scatter_default_39, %input_pos, %getitem_56, %getitem_57, %getitem_58), kwargs = {})\n",
      "  %getitem_62 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 0), kwargs = {})\n",
      "  %getitem_63 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 1), kwargs = {})\n",
      "  %getitem_64 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 2), kwargs = {})\n",
      "  %getitem_65 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 3), kwargs = {})\n",
      "  %getitem_66 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 4), kwargs = {})\n",
      "  %getitem_67 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 5), kwargs = {})\n",
      "  %alloc_60 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_20 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_66), kwargs = {out: %alloc_60})\n",
      "  %alloc_61 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_21 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_67), kwargs = {out: %alloc_61})\n",
      "  %alloc_62 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_40 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_20, 1, 0, 9223372036854775807), kwargs = {out: %alloc_62})\n",
      "  %alloc_63 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_41 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_21, 1, 0, 9223372036854775807), kwargs = {out: %alloc_63})\n",
      "  %alloc_64 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_42 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_40, 0, 0, 9223372036854775807), kwargs = {out: %alloc_64})\n",
      "  %alloc_65 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_43 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_41, 0, 0, 9223372036854775807), kwargs = {out: %alloc_65})\n",
      "  %lowered_module_11 : [num_users=1] = get_attr[target=lowered_module_11]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_10_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_10_ffn_norm_weight]\n",
      "      %p_layers_11_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_11_attention_norm_weight]\n",
      "      %b_layers_10_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_10_attention_wq_weight]\n",
      "      %b_layers_10_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_10_attention_wq_scales]\n",
      "      %b_layers_10_attention_mask : [num_users=1] = placeholder[target=b_layers_10_attention_mask]\n",
      "      %b_layers_10_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_10_attention_wo_weight]\n",
      "      %b_layers_10_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_10_attention_wo_scales]\n",
      "      %b_layers_10_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w1_weight]\n",
      "      %b_layers_10_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w1_scales]\n",
      "      %b_layers_10_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w3_weight]\n",
      "      %b_layers_10_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w3_scales]\n",
      "      %b_layers_10_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w2_weight]\n",
      "      %b_layers_10_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w2_scales]\n",
      "      %b_layers_11_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_11_attention_wk_weight]\n",
      "      %b_layers_11_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_11_attention_wk_scales]\n",
      "      %b_layers_11_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_11_attention_wv_weight]\n",
      "      %b_layers_11_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_11_attention_wv_scales]\n",
      "      %_lifted_tensor_constant239 : [num_users=1] = placeholder[target=_lifted_tensor_constant239]\n",
      "      %_lifted_tensor_constant240 : [num_users=1] = placeholder[target=_lifted_tensor_constant240]\n",
      "      %_lifted_tensor_constant241 : [num_users=1] = placeholder[target=_lifted_tensor_constant241]\n",
      "      %aten_index_tensor : [num_users=1] = placeholder[target=aten_index_tensor]\n",
      "      %aten_index_tensor_1 : [num_users=1] = placeholder[target=aten_index_tensor_1]\n",
      "      %aten_mul_tensor_242 : [num_users=1] = placeholder[target=aten_mul_tensor_242]\n",
      "      %aten_slice_scatter_default_43 : [num_users=1] = placeholder[target=aten_slice_scatter_default_43]\n",
      "      %aten_slice_scatter_default_41 : [num_users=1] = placeholder[target=aten_slice_scatter_default_41]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_205 : [num_users=2] = placeholder[target=aten_view_copy_default_205]\n",
      "      %aten_view_copy_default_206 : [num_users=2] = placeholder[target=aten_view_copy_default_206]\n",
      "      %aten_add_tensor_69 : [num_users=1] = placeholder[target=aten_add_tensor_69]\n",
      "      %aten_view_copy_default_225 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_226 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_100 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_242, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_43, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_86 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_41, 2), kwargs = {})\n",
      "      %aten__to_copy_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_10_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_10_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_10_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_85 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_10_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_86 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_10_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_10_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_11_attention_wk_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_11_attention_wv_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_87, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_86, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_120 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_80, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_85 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_84, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_128 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_84, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_129 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_85, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_130 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_86, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_131 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_87, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_133 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_89, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_134 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_90, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_61,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_60,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_100, %aten_permute_copy_default_120), kwargs = {})\n",
      "      %aten_index_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_85, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_212 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_21, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_211 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_20, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_243 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_70, %b_layers_10_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_12,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_212, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_126 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_211, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_200 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_243, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_217 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_65, [12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_126, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_203 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_200, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_214 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_63, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_203, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_203, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_103 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_40, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_104 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_41, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_246 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_103, %aten_view_copy_default_205), kwargs = {})\n",
      "      %aten_mul_tensor_248 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_103, %aten_view_copy_default_206), kwargs = {})\n",
      "      %aten_mul_tensor_247 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_104, %aten_view_copy_default_206), kwargs = {})\n",
      "      %aten_mul_tensor_249 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_104, %aten_view_copy_default_205), kwargs = {})\n",
      "      %aten_sub_tensor_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_246, %aten_mul_tensor_247), kwargs = {})\n",
      "      %aten_add_tensor_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_248, %aten_mul_tensor_249), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_20, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_71, 4), kwargs = {})\n",
      "      %aten_cat_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_80, %aten_unsqueeze_copy_default_81], -1), kwargs = {})\n",
      "      %aten_view_copy_default_207 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_20, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_123 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_207, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_123, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_213 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_62, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_213, %aten_view_copy_default_214), kwargs = {})\n",
      "      %aten_view_copy_default_215 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_20, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_254 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_215, %_lifted_tensor_constant239), kwargs = {})\n",
      "      %aten_add_tensor_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_254, %aten__to_copy_default_83), kwargs = {})\n",
      "      %aten__softmax_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_73, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_10, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_216 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_64, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_216, %aten_view_copy_default_217), kwargs = {})\n",
      "      %aten_view_copy_default_218 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_21, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_127 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_218, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_219 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_127, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_107 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_219, [0]), kwargs = {})\n",
      "      %aten_mm_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_107, %aten_permute_copy_default_128), kwargs = {})\n",
      "      %aten_mul_tensor_255 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_73, %b_layers_10_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_74 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_69, %aten_mul_tensor_255), kwargs = {})\n",
      "      %aten_mul_tensor_256 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_74, %aten_add_tensor_74), kwargs = {})\n",
      "      %aten_mean_dim_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_256, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_21, %_lifted_tensor_constant240), kwargs = {})\n",
      "      %aten_rsqrt_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_75,), kwargs = {})\n",
      "      %aten_mul_tensor_257 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_74, %aten_rsqrt_default_21), kwargs = {})\n",
      "      %aten_mul_tensor_258 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_257, %p_layers_10_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_108 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_258, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_109 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_258, [0]), kwargs = {})\n",
      "      %aten_mm_default_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_108, %aten_permute_copy_default_129), kwargs = {})\n",
      "      %aten_mm_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_109, %aten_permute_copy_default_130), kwargs = {})\n",
      "      %aten_mul_tensor_259 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_74, %b_layers_10_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_261 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_75, %b_layers_10_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_259,), kwargs = {})\n",
      "      %aten_mul_tensor_260 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_259, %aten_sigmoid_default_10), kwargs = {})\n",
      "      %aten_mul_tensor_262 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_260, %aten_mul_tensor_261), kwargs = {})\n",
      "      %aten_mm_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_262, %aten_permute_copy_default_131), kwargs = {})\n",
      "      %aten_mul_tensor_263 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_76, %b_layers_10_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_76 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_74, %aten_mul_tensor_263), kwargs = {})\n",
      "      %aten_mul_tensor_264 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_76, %aten_add_tensor_76), kwargs = {})\n",
      "      %aten_mean_dim_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_264, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_22, %_lifted_tensor_constant241), kwargs = {})\n",
      "      %aten_rsqrt_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_77,), kwargs = {})\n",
      "      %aten_mul_tensor_265 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_76, %aten_rsqrt_default_22), kwargs = {})\n",
      "      %aten_mul_tensor_266 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_265, %p_layers_11_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_111 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_266, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_112 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_266, [0]), kwargs = {})\n",
      "      %aten_mm_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_111, %aten_permute_copy_default_133), kwargs = {})\n",
      "      %aten_mm_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_112, %aten_permute_copy_default_134), kwargs = {})\n",
      "      %aten_mul_tensor_268 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_78, %b_layers_11_attention_wk_scales), kwargs = {})\n",
      "      %aten_mul_tensor_269 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_79, %b_layers_11_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_221 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_268, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_222 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_269, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_224 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_221, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_137 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_222, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_224, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_224, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_230 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_137, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_115 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_46, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_116 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_47, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_274 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_115, %aten_view_copy_default_225), kwargs = {})\n",
      "      %aten_mul_tensor_276 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_115, %aten_view_copy_default_226), kwargs = {})\n",
      "      %aten_mul_tensor_275 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_116, %aten_view_copy_default_226), kwargs = {})\n",
      "      %aten_mul_tensor_277 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_116, %aten_view_copy_default_225), kwargs = {})\n",
      "      %aten_sub_tensor_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_274, %aten_mul_tensor_275), kwargs = {})\n",
      "      %aten_add_tensor_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_276, %aten_mul_tensor_277), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_23, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_79, 4), kwargs = {})\n",
      "      %aten_cat_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_90, %aten_unsqueeze_copy_default_91], -1), kwargs = {})\n",
      "      %aten_view_copy_default_228 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_23, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_136 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_228, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_229 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_136, [12, 1, 64]), kwargs = {})\n",
      "      return (aten_view_copy_default_225, aten_view_copy_default_226, aten_add_tensor_76, aten_mul_tensor_266, aten_view_copy_default_230, aten_view_copy_default_229)\n",
      "  %executorch_call_delegate_11 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_11, %getitem_1, %getitem_2, %getitem_65, %aten_slice_scatter_default_42, %aten_slice_scatter_default_43, %input_pos, %getitem_62, %getitem_63, %getitem_64), kwargs = {})\n",
      "  %getitem_68 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 0), kwargs = {})\n",
      "  %getitem_69 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 1), kwargs = {})\n",
      "  %getitem_70 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 2), kwargs = {})\n",
      "  %getitem_71 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 3), kwargs = {})\n",
      "  %getitem_72 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 4), kwargs = {})\n",
      "  %getitem_73 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 5), kwargs = {})\n",
      "  %alloc_66 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_22 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_72), kwargs = {out: %alloc_66})\n",
      "  %alloc_67 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_index_put_default_23 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_73), kwargs = {out: %alloc_67})\n",
      "  %alloc_68 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_44 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_22, 1, 0, 9223372036854775807), kwargs = {out: %alloc_68})\n",
      "  %alloc_69 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_45 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_23, 1, 0, 9223372036854775807), kwargs = {out: %alloc_69})\n",
      "  %alloc_70 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_46 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_44, 0, 0, 9223372036854775807), kwargs = {out: %alloc_70})\n",
      "  %alloc_71 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "  %aten_slice_scatter_default_47 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_45, 0, 0, 9223372036854775807), kwargs = {out: %alloc_71})\n",
      "  %lowered_module_12 : [num_users=1] = get_attr[target=lowered_module_12]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_layers_11_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_11_ffn_norm_weight]\n",
      "      %p_norm_weight : [num_users=1] = placeholder[target=p_norm_weight]\n",
      "      %b_layers_11_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_11_attention_wq_weight]\n",
      "      %b_layers_11_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_11_attention_wq_scales]\n",
      "      %b_layers_11_attention_mask : [num_users=1] = placeholder[target=b_layers_11_attention_mask]\n",
      "      %b_layers_11_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_11_attention_wo_weight]\n",
      "      %b_layers_11_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_11_attention_wo_scales]\n",
      "      %b_layers_11_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w1_weight]\n",
      "      %b_layers_11_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w1_scales]\n",
      "      %b_layers_11_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w3_weight]\n",
      "      %b_layers_11_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w3_scales]\n",
      "      %b_layers_11_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w2_weight]\n",
      "      %b_layers_11_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w2_scales]\n",
      "      %b_output_weight : [num_users=1] = placeholder[target=b_output_weight]\n",
      "      %b_output_scales : [num_users=1] = placeholder[target=b_output_scales]\n",
      "      %_lifted_tensor_constant242 : [num_users=1] = placeholder[target=_lifted_tensor_constant242]\n",
      "      %_lifted_tensor_constant243 : [num_users=1] = placeholder[target=_lifted_tensor_constant243]\n",
      "      %_lifted_tensor_constant244 : [num_users=1] = placeholder[target=_lifted_tensor_constant244]\n",
      "      %aten_mul_tensor_266 : [num_users=1] = placeholder[target=aten_mul_tensor_266]\n",
      "      %aten_slice_scatter_default_45 : [num_users=1] = placeholder[target=aten_slice_scatter_default_45]\n",
      "      %aten_slice_scatter_default_47 : [num_users=1] = placeholder[target=aten_slice_scatter_default_47]\n",
      "      %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "      %aten_view_copy_default_225 : [num_users=2] = placeholder[target=aten_view_copy_default_225]\n",
      "      %aten_view_copy_default_226 : [num_users=2] = placeholder[target=aten_view_copy_default_226]\n",
      "      %aten_add_tensor_76 : [num_users=1] = placeholder[target=aten_add_tensor_76]\n",
      "      %aten_squeeze_copy_dims_110 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_266, [0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_45, 2), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_47, 2), kwargs = {})\n",
      "      %aten__to_copy_default_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_11_attention_wq_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_unsqueeze_copy_default_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_11_attention_mask, 0), kwargs = {})\n",
      "      %aten__to_copy_default_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_11_attention_wo_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_11_feed_forward_w1_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_11_feed_forward_w3_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_layers_11_feed_forward_w2_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_96 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%b_output_weight,), kwargs = {dtype: torch.float32})\n",
      "      %aten_expand_copy_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_94, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_95, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_132 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_88, [1, 0]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_92, 1), kwargs = {})\n",
      "      %aten_permute_copy_default_140 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_92, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_141 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_93, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_142 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_94, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_143 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_95, [1, 0]), kwargs = {})\n",
      "      %aten_permute_copy_default_144 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten__to_copy_default_96, [1, 0]), kwargs = {})\n",
      "      %aten_clone_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_66,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_clone_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_67,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_mm_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_110, %aten_permute_copy_default_132), kwargs = {})\n",
      "      %aten_index_tensor_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_93, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_view_copy_default_231 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_22, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_232 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_23, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_mul_tensor_267 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_77, %b_layers_11_attention_wq_scales), kwargs = {})\n",
      "      %aten__to_copy_default_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_13,), kwargs = {dtype: torch.float32})\n",
      "      %aten_permute_copy_default_138 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_231, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_232, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_220 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_mul_tensor_267, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_138, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_237 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_71, [12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_223 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_220, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_234 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_69, [12, 64, 128]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_223, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_223, 4, 1, 2), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_113 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_44, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_114 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_45, [4]), kwargs = {})\n",
      "      %aten_mul_tensor_270 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_113, %aten_view_copy_default_225), kwargs = {})\n",
      "      %aten_mul_tensor_272 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_113, %aten_view_copy_default_226), kwargs = {})\n",
      "      %aten_mul_tensor_271 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_114, %aten_view_copy_default_226), kwargs = {})\n",
      "      %aten_mul_tensor_273 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_114, %aten_view_copy_default_225), kwargs = {})\n",
      "      %aten_sub_tensor_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_270, %aten_mul_tensor_271), kwargs = {})\n",
      "      %aten_add_tensor_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_272, %aten_mul_tensor_273), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_22, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_78, 4), kwargs = {})\n",
      "      %aten_cat_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_88, %aten_unsqueeze_copy_default_89], -1), kwargs = {})\n",
      "      %aten_view_copy_default_227 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_22, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_135 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_227, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_expand_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_135, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_233 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_68, [12, 1, 64]), kwargs = {})\n",
      "      %aten_bmm_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_233, %aten_view_copy_default_234), kwargs = {})\n",
      "      %aten_view_copy_default_235 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_22, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_278 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_235, %_lifted_tensor_constant242), kwargs = {})\n",
      "      %aten_add_tensor_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_278, %aten__to_copy_default_91), kwargs = {})\n",
      "      %aten__softmax_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_80, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_11, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_236 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_70, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_236, %aten_view_copy_default_237), kwargs = {})\n",
      "      %aten_view_copy_default_238 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_23, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_139 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_238, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_239 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_139, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_117 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_239, [0]), kwargs = {})\n",
      "      %aten_mm_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_117, %aten_permute_copy_default_140), kwargs = {})\n",
      "      %aten_mul_tensor_279 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_80, %b_layers_11_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_81 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_76, %aten_mul_tensor_279), kwargs = {})\n",
      "      %aten_mul_tensor_280 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_81, %aten_add_tensor_81), kwargs = {})\n",
      "      %aten_mean_dim_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_280, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_23, %_lifted_tensor_constant243), kwargs = {})\n",
      "      %aten_rsqrt_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_82,), kwargs = {})\n",
      "      %aten_mul_tensor_281 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_81, %aten_rsqrt_default_23), kwargs = {})\n",
      "      %aten_mul_tensor_282 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_281, %p_layers_11_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_118 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_282, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_119 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_282, [0]), kwargs = {})\n",
      "      %aten_mm_default_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_118, %aten_permute_copy_default_141), kwargs = {})\n",
      "      %aten_mm_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_119, %aten_permute_copy_default_142), kwargs = {})\n",
      "      %aten_mul_tensor_283 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_81, %b_layers_11_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten_mul_tensor_285 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_82, %b_layers_11_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten_mul_tensor_283,), kwargs = {})\n",
      "      %aten_mul_tensor_284 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_283, %aten_sigmoid_default_11), kwargs = {})\n",
      "      %aten_mul_tensor_286 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_284, %aten_mul_tensor_285), kwargs = {})\n",
      "      %aten_mm_default_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_mul_tensor_286, %aten_permute_copy_default_143), kwargs = {})\n",
      "      %aten_mul_tensor_287 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_83, %b_layers_11_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_83 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_81, %aten_mul_tensor_287), kwargs = {})\n",
      "      %aten_mul_tensor_288 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_83, %aten_add_tensor_83), kwargs = {})\n",
      "      %aten_mean_dim_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_288, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_24, %_lifted_tensor_constant244), kwargs = {})\n",
      "      %aten_rsqrt_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_84,), kwargs = {})\n",
      "      %aten_mul_tensor_289 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_83, %aten_rsqrt_default_24), kwargs = {})\n",
      "      %aten_mul_tensor_290 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_289, %p_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_120 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_290, [0]), kwargs = {})\n",
      "      %aten_mm_default_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mm.default](args = (%aten_squeeze_copy_dims_120, %aten_permute_copy_default_144), kwargs = {})\n",
      "      %aten_mul_tensor_291 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mm_default_84, %b_output_scales), kwargs = {})\n",
      "      return (aten_mul_tensor_291,)\n",
      "  %executorch_call_delegate_12 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_12, %getitem_71, %aten_slice_scatter_default_47, %aten_slice_scatter_default_46, %input_pos, %getitem_68, %getitem_69, %getitem_70), kwargs = {})\n",
      "  %getitem_74 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_12, 0), kwargs = {})\n",
      "  %copy_ : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_3), kwargs = {})\n",
      "  %copy__1 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_2), kwargs = {})\n",
      "  %copy__2 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_7), kwargs = {})\n",
      "  %copy__3 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_6), kwargs = {})\n",
      "  %copy__4 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_11), kwargs = {})\n",
      "  %copy__5 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_10), kwargs = {})\n",
      "  %copy__6 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_15), kwargs = {})\n",
      "  %copy__7 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_14), kwargs = {})\n",
      "  %copy__8 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_19), kwargs = {})\n",
      "  %copy__9 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_18), kwargs = {})\n",
      "  %copy__10 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_23), kwargs = {})\n",
      "  %copy__11 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_22), kwargs = {})\n",
      "  %copy__12 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_27), kwargs = {})\n",
      "  %copy__13 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_26), kwargs = {})\n",
      "  %copy__14 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_31), kwargs = {})\n",
      "  %copy__15 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_30), kwargs = {})\n",
      "  %copy__16 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_35), kwargs = {})\n",
      "  %copy__17 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_34), kwargs = {})\n",
      "  %copy__18 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_39), kwargs = {})\n",
      "  %copy__19 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_38), kwargs = {})\n",
      "  %copy__20 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_43), kwargs = {})\n",
      "  %copy__21 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_42), kwargs = {})\n",
      "  %copy__22 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_47), kwargs = {})\n",
      "  %copy__23 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_46), kwargs = {})\n",
      "  return (getitem_74,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir.backend.utils import print_delegated_graph\n",
    "\n",
    "print_delegated_graph(builder.export_program.exported_program(\"forward\").graph_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 14:39:40,251 utils.py:112] Saved exported program to stories110M_int8.pte\n"
     ]
    }
   ],
   "source": [
    "builder.save_to_pte(\"stories110M_int8.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 09:47:28,356 utils.py:112] Saved exported program to stories110M_int8_mps.pte\n"
     ]
    }
   ],
   "source": [
    "builder.save_to_pte(\"stories110M_int8_mps.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[program.cpp:130] InternalConsistency verification requested but not available"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "m = _load_for_executorch(\"stories110M_int8.pte\")\n",
    "res = m.forward((torch.tensor([[1]], dtype=torch.long), torch.tensor(0, dtype=torch.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(res)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "files = [\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpp7jovcm9/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpn0uo5apz/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp0i_0v_b0/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpgjvbi4s1/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpt79bbpbt/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp6ychs24g/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpqawc68v7/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpt6sq63zo/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp9d080mdv/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp6jpstr7y/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpzutwk8fg/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpp1cerjiu/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpz4iu5_hx/schema.json\",\n",
    "]\n",
    "nodes = []\n",
    "for j in files:\n",
    "    with open(j) as f:\n",
    "        data = json.load(f)\n",
    "        for i, node in enumerate(data[\"mps_nodes\"]):\n",
    "            if node[\"mpsnode_union_type\"] == \"MPSIndexTensor\":\n",
    "                print(i)\n",
    "                nodes.append(node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['version', 'mps_nodes', 'mps_values', 'input_ids', 'output_ids', 'constant_ids', 'graph_type'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mpsnode_union': {'input1_id': 32, 'output_id': 34, 'indices_id': [-1, -1, 3]}, 'mpsnode_union_type': 'MPSIndexTensor', 'min_max': None}\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[-1, -1, 3]\n",
      "1\n",
      "[-1, -1, 5]\n",
      "2\n",
      "[-1, -1, 5]\n",
      "3\n",
      "[-1, -1, 5]\n",
      "4\n",
      "[-1, -1, 5]\n",
      "5\n",
      "[-1, -1, 5]\n",
      "6\n",
      "[-1, -1, 5]\n",
      "7\n",
      "[-1, -1, 5]\n",
      "8\n",
      "[-1, -1, 5]\n",
      "9\n",
      "[-1, -1, 5]\n",
      "10\n",
      "[-1, -1, 5]\n",
      "11\n",
      "[-1, -1, 5]\n",
      "12\n",
      "[1]\n",
      "13\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for i, n in enumerate(nodes):\n",
    "    print(i)\n",
    "    print(n[\"mpsnode_union\"][\"indices_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 15, 16, 21, 32, 46]\n"
     ]
    }
   ],
   "source": [
    "print(data[\"output_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for n in custom_nodes:\n",
    "    values.extend([data[\"mps_values\"][i] for i in n[\"mpsnode_union\"].values() if data[\"mps_values\"][i][\"datatype\"] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datatype': 3,\n",
       " 'num_dims': 1,\n",
       " 'dims': [768],\n",
       " 'constant_buffer_size': 1536,\n",
       " 'constant_buffer': {'storage': [20,\n",
       "   59,\n",
       "   34,\n",
       "   59,\n",
       "   21,\n",
       "   59,\n",
       "   43,\n",
       "   59,\n",
       "   161,\n",
       "   58,\n",
       "   232,\n",
       "   58,\n",
       "   165,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   205,\n",
       "   58,\n",
       "   10,\n",
       "   59,\n",
       "   186,\n",
       "   58,\n",
       "   195,\n",
       "   58,\n",
       "   215,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   177,\n",
       "   58,\n",
       "   226,\n",
       "   58,\n",
       "   239,\n",
       "   58,\n",
       "   162,\n",
       "   58,\n",
       "   164,\n",
       "   58,\n",
       "   137,\n",
       "   58,\n",
       "   217,\n",
       "   58,\n",
       "   4,\n",
       "   59,\n",
       "   245,\n",
       "   58,\n",
       "   153,\n",
       "   58,\n",
       "   229,\n",
       "   58,\n",
       "   148,\n",
       "   58,\n",
       "   198,\n",
       "   58,\n",
       "   15,\n",
       "   59,\n",
       "   143,\n",
       "   58,\n",
       "   148,\n",
       "   58,\n",
       "   221,\n",
       "   58,\n",
       "   56,\n",
       "   58,\n",
       "   86,\n",
       "   59,\n",
       "   30,\n",
       "   59,\n",
       "   93,\n",
       "   58,\n",
       "   72,\n",
       "   58,\n",
       "   2,\n",
       "   59,\n",
       "   90,\n",
       "   59,\n",
       "   76,\n",
       "   58,\n",
       "   20,\n",
       "   58,\n",
       "   4,\n",
       "   60,\n",
       "   149,\n",
       "   58,\n",
       "   150,\n",
       "   59,\n",
       "   255,\n",
       "   58,\n",
       "   186,\n",
       "   58,\n",
       "   185,\n",
       "   58,\n",
       "   185,\n",
       "   58,\n",
       "   54,\n",
       "   59,\n",
       "   158,\n",
       "   58,\n",
       "   131,\n",
       "   58,\n",
       "   53,\n",
       "   59,\n",
       "   132,\n",
       "   58,\n",
       "   31,\n",
       "   59,\n",
       "   225,\n",
       "   58,\n",
       "   206,\n",
       "   58,\n",
       "   241,\n",
       "   58,\n",
       "   197,\n",
       "   58,\n",
       "   221,\n",
       "   58,\n",
       "   228,\n",
       "   58,\n",
       "   219,\n",
       "   58,\n",
       "   236,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   177,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   244,\n",
       "   58,\n",
       "   153,\n",
       "   58,\n",
       "   160,\n",
       "   58,\n",
       "   219,\n",
       "   58,\n",
       "   160,\n",
       "   58,\n",
       "   185,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   203,\n",
       "   58,\n",
       "   191,\n",
       "   58,\n",
       "   146,\n",
       "   58,\n",
       "   201,\n",
       "   58,\n",
       "   163,\n",
       "   58,\n",
       "   184,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   187,\n",
       "   58,\n",
       "   198,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   182,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   142,\n",
       "   58,\n",
       "   160,\n",
       "   58,\n",
       "   174,\n",
       "   58,\n",
       "   188,\n",
       "   58,\n",
       "   164,\n",
       "   58,\n",
       "   172,\n",
       "   58,\n",
       "   181,\n",
       "   58,\n",
       "   162,\n",
       "   58,\n",
       "   137,\n",
       "   58,\n",
       "   202,\n",
       "   58,\n",
       "   143,\n",
       "   58,\n",
       "   213,\n",
       "   58,\n",
       "   154,\n",
       "   58,\n",
       "   169,\n",
       "   58,\n",
       "   174,\n",
       "   58,\n",
       "   211,\n",
       "   58,\n",
       "   150,\n",
       "   58,\n",
       "   225,\n",
       "   58,\n",
       "   18,\n",
       "   59,\n",
       "   130,\n",
       "   58,\n",
       "   253,\n",
       "   58,\n",
       "   136,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   6,\n",
       "   59,\n",
       "   153,\n",
       "   58,\n",
       "   51,\n",
       "   59,\n",
       "   218,\n",
       "   58,\n",
       "   137,\n",
       "   58,\n",
       "   134,\n",
       "   58,\n",
       "   183,\n",
       "   58,\n",
       "   226,\n",
       "   58,\n",
       "   253,\n",
       "   58,\n",
       "   4,\n",
       "   59,\n",
       "   251,\n",
       "   58,\n",
       "   172,\n",
       "   58,\n",
       "   213,\n",
       "   58,\n",
       "   243,\n",
       "   58,\n",
       "   217,\n",
       "   58,\n",
       "   221,\n",
       "   58,\n",
       "   220,\n",
       "   58,\n",
       "   16,\n",
       "   59,\n",
       "   213,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   248,\n",
       "   58,\n",
       "   186,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   206,\n",
       "   58,\n",
       "   240,\n",
       "   58,\n",
       "   240,\n",
       "   58,\n",
       "   217,\n",
       "   58,\n",
       "   223,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   11,\n",
       "   59,\n",
       "   189,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   213,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   231,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   192,\n",
       "   58,\n",
       "   159,\n",
       "   58,\n",
       "   212,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   186,\n",
       "   58,\n",
       "   177,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   181,\n",
       "   58,\n",
       "   242,\n",
       "   58,\n",
       "   200,\n",
       "   58,\n",
       "   187,\n",
       "   58,\n",
       "   182,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   182,\n",
       "   58,\n",
       "   187,\n",
       "   58,\n",
       "   208,\n",
       "   58,\n",
       "   217,\n",
       "   58,\n",
       "   189,\n",
       "   58,\n",
       "   242,\n",
       "   58,\n",
       "   4,\n",
       "   59,\n",
       "   7,\n",
       "   59,\n",
       "   13,\n",
       "   59,\n",
       "   168,\n",
       "   58,\n",
       "   15,\n",
       "   59,\n",
       "   215,\n",
       "   58,\n",
       "   204,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   244,\n",
       "   58,\n",
       "   175,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   208,\n",
       "   58,\n",
       "   212,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   13,\n",
       "   59,\n",
       "   192,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   206,\n",
       "   58,\n",
       "   11,\n",
       "   59,\n",
       "   229,\n",
       "   58,\n",
       "   247,\n",
       "   58,\n",
       "   196,\n",
       "   58,\n",
       "   245,\n",
       "   58,\n",
       "   13,\n",
       "   59,\n",
       "   60,\n",
       "   59,\n",
       "   208,\n",
       "   58,\n",
       "   242,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   212,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   173,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   207,\n",
       "   58,\n",
       "   237,\n",
       "   58,\n",
       "   236,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   236,\n",
       "   58,\n",
       "   196,\n",
       "   58,\n",
       "   197,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   199,\n",
       "   58,\n",
       "   234,\n",
       "   58,\n",
       "   246,\n",
       "   58,\n",
       "   9,\n",
       "   59,\n",
       "   191,\n",
       "   58,\n",
       "   181,\n",
       "   58,\n",
       "   202,\n",
       "   58,\n",
       "   28,\n",
       "   59,\n",
       "   195,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   233,\n",
       "   58,\n",
       "   16,\n",
       "   59,\n",
       "   180,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   226,\n",
       "   58,\n",
       "   145,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   116,\n",
       "   58,\n",
       "   226,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   123,\n",
       "   58,\n",
       "   73,\n",
       "   59,\n",
       "   52,\n",
       "   58,\n",
       "   31,\n",
       "   58,\n",
       "   206,\n",
       "   59,\n",
       "   54,\n",
       "   58,\n",
       "   184,\n",
       "   59,\n",
       "   167,\n",
       "   58,\n",
       "   90,\n",
       "   59,\n",
       "   219,\n",
       "   58,\n",
       "   249,\n",
       "   58,\n",
       "   17,\n",
       "   59,\n",
       "   197,\n",
       "   58,\n",
       "   204,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   11,\n",
       "   59,\n",
       "   223,\n",
       "   58,\n",
       "   248,\n",
       "   58,\n",
       "   15,\n",
       "   59,\n",
       "   6,\n",
       "   59,\n",
       "   244,\n",
       "   58,\n",
       "   190,\n",
       "   58,\n",
       "   229,\n",
       "   58,\n",
       "   10,\n",
       "   59,\n",
       "   232,\n",
       "   58,\n",
       "   14,\n",
       "   59,\n",
       "   1,\n",
       "   59,\n",
       "   68,\n",
       "   59,\n",
       "   38,\n",
       "   59,\n",
       "   48,\n",
       "   59,\n",
       "   17,\n",
       "   59,\n",
       "   16,\n",
       "   59,\n",
       "   12,\n",
       "   59,\n",
       "   244,\n",
       "   58,\n",
       "   246,\n",
       "   58,\n",
       "   195,\n",
       "   58,\n",
       "   9,\n",
       "   59,\n",
       "   205,\n",
       "   58,\n",
       "   35,\n",
       "   59,\n",
       "   216,\n",
       "   58,\n",
       "   30,\n",
       "   59,\n",
       "   198,\n",
       "   58,\n",
       "   13,\n",
       "   59,\n",
       "   162,\n",
       "   58,\n",
       "   231,\n",
       "   58,\n",
       "   158,\n",
       "   58,\n",
       "   10,\n",
       "   59,\n",
       "   239,\n",
       "   58,\n",
       "   166,\n",
       "   58,\n",
       "   201,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   122,\n",
       "   58,\n",
       "   3,\n",
       "   59,\n",
       "   116,\n",
       "   58,\n",
       "   13,\n",
       "   59,\n",
       "   81,\n",
       "   59,\n",
       "   89,\n",
       "   58,\n",
       "   102,\n",
       "   58,\n",
       "   228,\n",
       "   58,\n",
       "   90,\n",
       "   59,\n",
       "   76,\n",
       "   58,\n",
       "   56,\n",
       "   58,\n",
       "   33,\n",
       "   59,\n",
       "   221,\n",
       "   58,\n",
       "   95,\n",
       "   58,\n",
       "   117,\n",
       "   59,\n",
       "   12,\n",
       "   58,\n",
       "   26,\n",
       "   60,\n",
       "   180,\n",
       "   57,\n",
       "   227,\n",
       "   58,\n",
       "   237,\n",
       "   58,\n",
       "   20,\n",
       "   60,\n",
       "   115,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   230,\n",
       "   58,\n",
       "   247,\n",
       "   58,\n",
       "   151,\n",
       "   58,\n",
       "   20,\n",
       "   59,\n",
       "   247,\n",
       "   58,\n",
       "   12,\n",
       "   59,\n",
       "   4,\n",
       "   59,\n",
       "   213,\n",
       "   58,\n",
       "   248,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   45,\n",
       "   59,\n",
       "   7,\n",
       "   59,\n",
       "   227,\n",
       "   58,\n",
       "   177,\n",
       "   58,\n",
       "   24,\n",
       "   59,\n",
       "   232,\n",
       "   58,\n",
       "   247,\n",
       "   58,\n",
       "   214,\n",
       "   58,\n",
       "   233,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   173,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   6,\n",
       "   59,\n",
       "   182,\n",
       "   58,\n",
       "   220,\n",
       "   58,\n",
       "   14,\n",
       "   59,\n",
       "   212,\n",
       "   58,\n",
       "   227,\n",
       "   58,\n",
       "   21,\n",
       "   59,\n",
       "   150,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   243,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   211,\n",
       "   58,\n",
       "   7,\n",
       "   59,\n",
       "   186,\n",
       "   58,\n",
       "   187,\n",
       "   58,\n",
       "   162,\n",
       "   58,\n",
       "   214,\n",
       "   58,\n",
       "   3,\n",
       "   59,\n",
       "   19,\n",
       "   59,\n",
       "   4,\n",
       "   59,\n",
       "   224,\n",
       "   58,\n",
       "   188,\n",
       "   58,\n",
       "   200,\n",
       "   58,\n",
       "   225,\n",
       "   58,\n",
       "   242,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   238,\n",
       "   58,\n",
       "   251,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   194,\n",
       "   58,\n",
       "   181,\n",
       "   58,\n",
       "   204,\n",
       "   58,\n",
       "   213,\n",
       "   58,\n",
       "   158,\n",
       "   58,\n",
       "   255,\n",
       "   58,\n",
       "   33,\n",
       "   59,\n",
       "   133,\n",
       "   58,\n",
       "   255,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   187,\n",
       "   58,\n",
       "   36,\n",
       "   59,\n",
       "   190,\n",
       "   58,\n",
       "   169,\n",
       "   58,\n",
       "   195,\n",
       "   58,\n",
       "   250,\n",
       "   58,\n",
       "   182,\n",
       "   58,\n",
       "   205,\n",
       "   58,\n",
       "   35,\n",
       "   59,\n",
       "   217,\n",
       "   58,\n",
       "   200,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   211,\n",
       "   58,\n",
       "   36,\n",
       "   59,\n",
       "   47,\n",
       "   59,\n",
       "   29,\n",
       "   59,\n",
       "   23,\n",
       "   59,\n",
       "   224,\n",
       "   58,\n",
       "   82,\n",
       "   59,\n",
       "   228,\n",
       "   58,\n",
       "   92,\n",
       "   59,\n",
       "   88,\n",
       "   59,\n",
       "   12,\n",
       "   59,\n",
       "   116,\n",
       "   59,\n",
       "   1,\n",
       "   59,\n",
       "   70,\n",
       "   59,\n",
       "   70,\n",
       "   59,\n",
       "   250,\n",
       "   58,\n",
       "   45,\n",
       "   59,\n",
       "   23,\n",
       "   59,\n",
       "   15,\n",
       "   59,\n",
       "   231,\n",
       "   58,\n",
       "   240,\n",
       "   58,\n",
       "   35,\n",
       "   59,\n",
       "   249,\n",
       "   58,\n",
       "   22,\n",
       "   59,\n",
       "   35,\n",
       "   59,\n",
       "   6,\n",
       "   59,\n",
       "   180,\n",
       "   58,\n",
       "   12,\n",
       "   59,\n",
       "   182,\n",
       "   58,\n",
       "   157,\n",
       "   58,\n",
       "   28,\n",
       "   59,\n",
       "   171,\n",
       "   58,\n",
       "   241,\n",
       "   58,\n",
       "   234,\n",
       "   58,\n",
       "   219,\n",
       "   58,\n",
       "   155,\n",
       "   58,\n",
       "   147,\n",
       "   58,\n",
       "   239,\n",
       "   58,\n",
       "   18,\n",
       "   59,\n",
       "   225,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   7,\n",
       "   59,\n",
       "   129,\n",
       "   58,\n",
       "   248,\n",
       "   58,\n",
       "   163,\n",
       "   58,\n",
       "   147,\n",
       "   58,\n",
       "   135,\n",
       "   58,\n",
       "   247,\n",
       "   59,\n",
       "   68,\n",
       "   58,\n",
       "   108,\n",
       "   58,\n",
       "   200,\n",
       "   59,\n",
       "   150,\n",
       "   58,\n",
       "   79,\n",
       "   59,\n",
       "   86,\n",
       "   59,\n",
       "   193,\n",
       "   58,\n",
       "   52,\n",
       "   59,\n",
       "   163,\n",
       "   58,\n",
       "   31,\n",
       "   59,\n",
       "   188,\n",
       "   58,\n",
       "   223,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   169,\n",
       "   58,\n",
       "   239,\n",
       "   58,\n",
       "   198,\n",
       "   58,\n",
       "   174,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   8,\n",
       "   59,\n",
       "   0,\n",
       "   59,\n",
       "   150,\n",
       "   58,\n",
       "   233,\n",
       "   58,\n",
       "   244,\n",
       "   58,\n",
       "   43,\n",
       "   59,\n",
       "   1,\n",
       "   59,\n",
       "   243,\n",
       "   58,\n",
       "   68,\n",
       "   59,\n",
       "   29,\n",
       "   59,\n",
       "   46,\n",
       "   59,\n",
       "   184,\n",
       "   58,\n",
       "   54,\n",
       "   59,\n",
       "   244,\n",
       "   58,\n",
       "   12,\n",
       "   59,\n",
       "   4,\n",
       "   59,\n",
       "   8,\n",
       "   59,\n",
       "   194,\n",
       "   58,\n",
       "   7,\n",
       "   59,\n",
       "   7,\n",
       "   59,\n",
       "   223,\n",
       "   58,\n",
       "   11,\n",
       "   59,\n",
       "   25,\n",
       "   59,\n",
       "   197,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   13,\n",
       "   59,\n",
       "   183,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   29,\n",
       "   59,\n",
       "   24,\n",
       "   59,\n",
       "   30,\n",
       "   59,\n",
       "   18,\n",
       "   59,\n",
       "   173,\n",
       "   58,\n",
       "   39,\n",
       "   59,\n",
       "   16,\n",
       "   59,\n",
       "   208,\n",
       "   58,\n",
       "   249,\n",
       "   58,\n",
       "   8,\n",
       "   59,\n",
       "   245,\n",
       "   58,\n",
       "   171,\n",
       "   58,\n",
       "   180,\n",
       "   58,\n",
       "   71,\n",
       "   59,\n",
       "   129,\n",
       "   59,\n",
       "   199,\n",
       "   58,\n",
       "   55,\n",
       "   59,\n",
       "   130,\n",
       "   58,\n",
       "   184,\n",
       "   59,\n",
       "   112,\n",
       "   58,\n",
       "   158,\n",
       "   58,\n",
       "   148,\n",
       "   59,\n",
       "   179,\n",
       "   58,\n",
       "   127,\n",
       "   59,\n",
       "   215,\n",
       "   58,\n",
       "   65,\n",
       "   59,\n",
       "   185,\n",
       "   58,\n",
       "   43,\n",
       "   59,\n",
       "   ...]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"mps_values\"][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class WeightOnlyInt8QuantHandler(QuantHandler):\n",
      "    def __init__(\n",
      "        self,\n",
      "        mod,\n",
      "        device=\"cpu\",\n",
      "        *,\n",
      "        node_type: str = \"*\",\n",
      "        bitwidth: Optional[int] = None,\n",
      "        group_size: Optional[int] = None,\n",
      "    ):\n",
      "        self.mod = mod\n",
      "        self.group_size = group_size\n",
      "        self.node_type = node_type\n",
      "        if bitwidth is None:\n",
      "            self.bitwidth = 8\n",
      "        else:\n",
      "            self.bitwidth = bitwidth\n",
      "\n",
      "    @torch.no_grad()\n",
      "    def create_quantized_state_dict(self) -> Dict:\n",
      "        cur_state_dict = self.mod.state_dict()\n",
      "\n",
      "        if self.bitwidth == 4:\n",
      "            range_min = -8\n",
      "            range_max = 7\n",
      "        elif self.bitwidth == 8:\n",
      "            range_min = -128\n",
      "            range_max = 127\n",
      "        else:\n",
      "            raise ValueError(f\"Unsupported bitwidth {self.bitwidth}\")\n",
      "\n",
      "        for fqn, mod in self.mod.named_modules():\n",
      "            # print(f\"maybe? quantize {fqn}...{type(mod)}\")\n",
      "            if isinstance(mod, torch.nn.Linear) or isinstance(mod, fsLinear):\n",
      "                # print(f\"candidate {fqn}, nodetype {self.node_type}\")\n",
      "                if (\n",
      "                    (self.node_type == \"*\")\n",
      "                    or (self.node_type == \"output\" and fqn in [\"output\", \"final_proj\"])\n",
      "                    or (\n",
      "                        self.node_type == \"!output\"\n",
      "                        and fqn not in [\"output\", \"final_proj\"]\n",
      "                    )\n",
      "                ):\n",
      "                    print(\n",
      "                        f\"quantize {self.node_type} {fqn, mod} with group_size {self.group_size}, bitwidth {self.bitwidth}\"\n",
      "                    )\n",
      "\n",
      "                    # print(f\"initial weight shape {mod.weight.shape}\")\n",
      "                    input_weight = mod.weight.float()\n",
      "\n",
      "                    # print(f\"expanded weight shape {input_weight.shape}\")\n",
      "                    weight, scales, _ = dynamically_quantize_per_channel(\n",
      "                        input_weight,\n",
      "                        range_min,\n",
      "                        range_max,\n",
      "                        torch.int8,\n",
      "                        self.group_size,\n",
      "                        scales_dtype=input_weight.dtype,\n",
      "                    )\n",
      "\n",
      "                    cur_state_dict[f\"{fqn}.weight\"] = weight\n",
      "                    # squeeze makes group_size=rowsize unidimensional\n",
      "                    cur_state_dict[f\"{fqn}.scales\"] = scales.squeeze(dim=-1)\n",
      "\n",
      "        return cur_state_dict\n",
      "\n",
      "    def convert_for_runtime(self) -> nn.Module:\n",
      "        replace_linear_weight_only_int8_per_channel(self.mod, self.node_type)\n",
      "        return self.mod\n",
      "\n",
      "    def quantized_model(self) -> nn.Module:\n",
      "        model_updated_state_dict = self.create_quantized_state_dict()\n",
      "        self.convert_for_runtime()\n",
      "        self.mod.load_state_dict(model_updated_state_dict)\n",
      "        return self.mod\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(WeightOnlyInt8QuantHandler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatbuffers\n",
    "from mpsgraph.MPSGraph import MPSGraph\n",
    "from mpsgraph.MPSIndexTensor import MPSIndexTensor\n",
    "with open(\"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpudja56ka/schema.bin\", 'rb') as f:\n",
    "    g = MPSGraph.GetRootAsMPSGraph(f.read(), 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "nodes = []\n",
    "with open(\"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpudja56ka/schema.json\") as f:\n",
    "    data = json.load(f)\n",
    "    nodes = [node for node in data[\"mps_nodes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MPSCast\n",
      "1 MPSCast\n",
      "2 MPSCast\n",
      "3 MPSCast\n",
      "4 MPSCast\n",
      "5 MPSCast\n",
      "6 MPSSqueeze\n",
      "7 MPSUnsqueeze\n",
      "8 MPSUnsqueeze\n",
      "9 MPSUnsqueeze\n",
      "10 MPSExpand\n",
      "11 MPSExpand\n",
      "12 MPSPermute\n",
      "13 MPSUnsqueeze\n",
      "14 MPSPermute\n",
      "15 MPSPermute\n",
      "16 MPSPermute\n",
      "17 MPSPermute\n",
      "18 MPSPermute\n",
      "19 MPSMatMul\n",
      "20 MPSIndexTensor\n",
      "21 MPSView\n",
      "22 MPSView\n",
      "23 MPSMul\n",
      "24 MPSPermute\n",
      "25 MPSExpand\n",
      "26 MPSView\n",
      "27 MPSExpand\n",
      "28 MPSView\n",
      "29 MPSView\n",
      "30 MPSView\n",
      "31 MPSSlice\n",
      "32 MPSSlice\n",
      "33 MPSSqueeze\n",
      "34 MPSSqueeze\n",
      "35 MPSMul\n",
      "36 MPSMul\n",
      "37 MPSMul\n",
      "38 MPSMul\n",
      "39 MPSSub\n",
      "40 MPSAdd\n",
      "41 MPSUnsqueeze\n",
      "42 MPSUnsqueeze\n",
      "43 MPSCat\n",
      "44 MPSView\n",
      "45 MPSPermute\n",
      "46 MPSExpand\n",
      "47 MPSView\n",
      "48 MPSMatMul\n",
      "49 MPSView\n",
      "50 MPSMul\n",
      "51 MPSAdd\n",
      "52 MPSSoftmax\n",
      "53 MPSExpand\n",
      "54 MPSView\n",
      "55 MPSMatMul\n",
      "56 MPSView\n",
      "57 MPSPermute\n",
      "58 MPSView\n",
      "59 MPSSqueeze\n",
      "60 MPSMatMul\n",
      "61 MPSMul\n",
      "62 MPSAdd\n",
      "63 MPSMul\n",
      "64 MPSMean\n",
      "65 MPSAdd\n",
      "66 MPSRsqrt\n",
      "67 MPSMul\n",
      "68 MPSMul\n",
      "69 MPSSqueeze\n",
      "70 MPSSqueeze\n",
      "71 MPSMatMul\n",
      "72 MPSMatMul\n",
      "73 MPSMul\n",
      "74 MPSMul\n",
      "75 MPSSigmoid\n",
      "76 MPSMul\n",
      "77 MPSMul\n",
      "78 MPSMatMul\n",
      "79 MPSMul\n",
      "80 MPSAdd\n",
      "81 MPSMul\n",
      "82 MPSMean\n",
      "83 MPSAdd\n",
      "84 MPSRsqrt\n",
      "85 MPSMul\n",
      "86 MPSMul\n",
      "87 MPSSqueeze\n",
      "88 MPSMatMul\n",
      "89 MPSMul\n",
      "90 MPSCast\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(nodes):\n",
    "    print(i, node[\"mpsnode_union_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 75\n",
      "1 75\n",
      "2 75\n",
      "3 75\n",
      "4 75\n",
      "5 75\n",
      "6 69\n",
      "7 70\n",
      "8 70\n",
      "9 70\n",
      "10 67\n",
      "11 67\n",
      "12 65\n",
      "13 70\n",
      "14 65\n",
      "15 65\n",
      "16 65\n",
      "17 65\n",
      "18 65\n",
      "19 53\n",
      "20 62\n",
      "21 66\n",
      "22 66\n",
      "23 9\n",
      "24 65\n",
      "25 67\n",
      "26 66\n",
      "27 67\n",
      "28 66\n",
      "29 66\n",
      "30 66\n",
      "31 72\n",
      "32 72\n",
      "33 69\n",
      "34 69\n",
      "35 9\n",
      "36 9\n",
      "37 9\n",
      "38 9\n",
      "39 8\n",
      "40 7\n",
      "41 70\n",
      "42 70\n",
      "43 68\n",
      "44 66\n",
      "45 65\n",
      "46 67\n",
      "47 66\n",
      "48 53\n",
      "49 66\n",
      "50 9\n",
      "51 7\n",
      "52 5\n",
      "53 67\n",
      "54 66\n",
      "55 53\n",
      "56 66\n",
      "57 65\n",
      "58 66\n",
      "59 69\n",
      "60 53\n",
      "61 9\n",
      "62 7\n",
      "63 9\n",
      "64 64\n",
      "65 7\n",
      "66 32\n",
      "67 9\n",
      "68 9\n",
      "69 69\n",
      "70 69\n",
      "71 53\n",
      "72 53\n",
      "73 9\n",
      "74 9\n",
      "75 33\n",
      "76 9\n",
      "77 9\n",
      "78 53\n",
      "79 9\n",
      "80 7\n",
      "81 9\n",
      "82 64\n",
      "83 7\n",
      "84 32\n",
      "85 9\n",
      "86 9\n",
      "87 69\n",
      "88 53\n",
      "89 9\n",
      "90 75\n"
     ]
    }
   ],
   "source": [
    "for i in range(g.MpsNodesLength()):\n",
    "    print(i, g.MpsNodes(i).MpsnodeUnionType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[20][\"mpsnode_union\"][\"indices_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tensor = g.MpsNodes(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "print(index_tensor.MpsnodeUnionType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpsgraph.MPSIndexTensor import MPSIndexTensor\n",
    "\n",
    "t = MPSIndexTensor.GetRootAs(g._tab.Bytes, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad number -31589593 for type uint32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t\u001b[39m.\u001b[39;49mIndicesIdAsNumpy()\n",
      "File \u001b[0;32m~/CLionProjects/executorch/mpsgraph/MPSIndexTensor.py:48\u001b[0m, in \u001b[0;36mMPSIndexTensor.IndicesIdAsNumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mIndicesIdAsNumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     o \u001b[39m=\u001b[39m flatbuffers\u001b[39m.\u001b[39mnumber_types\u001b[39m.\u001b[39mUOffsetTFlags\u001b[39m.\u001b[39mpy_type(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tab\u001b[39m.\u001b[39;49mOffset(\u001b[39m6\u001b[39;49m))\n\u001b[1;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m o \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tab\u001b[39m.\u001b[39mGetVectorAsNumpy(flatbuffers\u001b[39m.\u001b[39mnumber_types\u001b[39m.\u001b[39mInt32Flags, o)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/flatbuffers/table.py:38\u001b[0m, in \u001b[0;36mTable.Offset\u001b[0;34m(self, vtableOffset)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Offset provides access into the Table's vtable.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[39mDeprecated fields are ignored by checking the vtable's length.\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m vtable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPos \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGet(N\u001b[39m.\u001b[39mSOffsetTFlags, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPos)\n\u001b[0;32m---> 38\u001b[0m vtableEnd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGet(N\u001b[39m.\u001b[39;49mVOffsetTFlags, vtable)\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m vtableOffset \u001b[39m<\u001b[39m vtableEnd:\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGet(N\u001b[39m.\u001b[39mVOffsetTFlags, vtable \u001b[39m+\u001b[39m vtableOffset)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/flatbuffers/table.py:92\u001b[0m, in \u001b[0;36mTable.Get\u001b[0;34m(self, flags, off)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGet\u001b[39m(\u001b[39mself\u001b[39m, flags, off):\n\u001b[1;32m     88\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m    Get retrieves a value of the type specified by `flags`  at the\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39m    given offset.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     N\u001b[39m.\u001b[39;49menforce_number(off, N\u001b[39m.\u001b[39;49mUOffsetTFlags)\n\u001b[1;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m flags\u001b[39m.\u001b[39mpy_type(encode\u001b[39m.\u001b[39mGet(flags\u001b[39m.\u001b[39mpacker_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mBytes, off))\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/flatbuffers/number_types.py:150\u001b[0m, in \u001b[0;36menforce_number\u001b[0;34m(n, flags)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m flags\u001b[39m.\u001b[39mmin_val \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m flags\u001b[39m.\u001b[39mmax_val:\n\u001b[0;32m--> 150\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbad number \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(n), flags\u001b[39m.\u001b[39mname))\n",
      "\u001b[0;31mTypeError\u001b[0m: bad number -31589593 for type uint32"
     ]
    }
   ],
   "source": [
    "t.IndicesIdAsNumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
